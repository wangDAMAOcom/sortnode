e_end_timing();
  LOG_DEBUG("MySQLClusterXATransactionNode %@ cost %d ms\n", this,
            node_cost_time);
#endif
  status = EXECUTE_STATUS_COMPLETE;
  return;
}
void MySQLClusterXATransactionNode::clean() {
  if (xa_conn) {
    if (!got_error || error_packet) {
      handler->put_back_connection(dataspace, xa_conn);
      xa_conn = NULL;
    } else {
      handler->clean_dead_conn(&xa_conn, dataspace);
    }
  }
  if (error_packet && error_packet != packet) {
    delete error_packet;
    error_packet = NULL;
  }
  if (packet) {
    delete packet;
    packet = NULL;
    error_packet = NULL;
  }
}

/* class MySQLLockNode */
MySQLLockNode::MySQLLockNode(
    ExecutePlan *plan,
    map<DataSpace *, list<lock_table_item *> *> *lock_table_list)
    : MySQLExecuteNode(plan), conn(NULL) {
  this->lock_table_list = lock_table_list;
  this->name = "MySQLLockNode";
  got_error = false;
  error_packet = NULL;
}
void MySQLLockNode::clean() {
  if (lock_table_list) {
    map<DataSpace *, list<lock_table_item *> *>::iterator it;
    while (!lock_table_list->empty()) {
      it = lock_table_list->begin();
      list<lock_table_item *> *table_list = it->second;
      lock_table_list->erase(it);
      table_list->clear();
      delete table_list;
    }
    delete lock_table_list;
    lock_table_list = NULL;
  }
  if (conn) {
    if (!got_error || error_packet) {
      handler->put_back_connection(dataspace, conn);
    } else {
      handler->clean_dead_conn(&conn, dataspace);
    }
    conn = NULL;
  }
  if (packet) {
    delete packet;
    packet = NULL;
    error_packet = NULL;
  }
}

string MySQLLockNode::adjust_table_name(string ori_name) {
  string ret;
  vector<string> split_name;
  boost::split(split_name, ori_name, boost::is_any_of("."));
  if (split_name.size() == 1) {
    ret.assign("`");
    ret.append(split_name.at(0));
    ret.append("`");
  } else if (split_name.size() == 2) {
    ret.assign("`");
    ret.append(split_name.at(0));
    ret.append("`.`");
    ret.append(split_name.at(1));
    ret.append("`");
  }
  return ret;
}

string MySQLLockNode::build_sql(DataSpace *space) {
  list<lock_table_item *> *table_list = (*lock_table_list)[space];
  list<lock_table_item *>::iterator lock_it;
  string str = "lock tables ";
  for (lock_it = table_list->begin(); lock_it != table_list->end(); lock_it++) {
    if (lock_it != table_list->begin()) {
      str += ",";
    }
    str += adjust_table_name((*lock_it)->name);
    str += " ";
    if ((*lock_it)->type == LOCK_TYPE_READ) {
      str += "read";
    } else {
      str += "write";
    }
  }
  LOG_DEBUG("lock sql [%s] for space %@\n", str.c_str(), space);
  lock_table_list->erase(space);
  table_list->clear();
  delete table_list;
  return str;
}

void MySQLLockNode::execute() {
#ifdef DEBUG
  node_start_timing();
#endif
  packet = Backend::instance()->get_new_packet();
  Packet exec_packet;
  MySQLQueryRequest query;
  query.set_sql_replace_char(plan->session->get_query_sql_replace_null_char());
  map<DataSpace *, list<lock_table_item *> *>::iterator it;
  DataSpace *space = NULL;
  while (!lock_table_list->empty()) {
    it = lock_table_list->begin();
    space = it->first;
    string str = build_sql(space);
    const char *sql = (const char *)str.c_str();
    query.set_query(sql);
    query.pack(&exec_packet);

    try {
      conn = handler->send_to_server_retry(
          space, &exec_packet, session->get_schema(), session->is_read_only());
      LOG_DEBUG("Receiving lock result from server\n");
      handler->receive_from_server(conn, packet);
      if (driver->is_error_packet(packet)) {
        status = EXECUTE_STATUS_COMPLETE;
        error_packet = packet;
        MySQLErrorResponse response(error_packet);
        if (response.is_shutdown()) {
          if (conn) {
            handler->clean_dead_conn(&conn, space);
          }
          session->set_server_shutdown(true);
          dataspace = space;
        }
        throw ErrorPacketException();
      }
      if (lock_table_list->size() == 0) {
        handler->record_affected_rows(packet);
        handler->send_to_client(packet);
      }

      if (conn) {
        handler->put_back_connection(space, conn);
        conn = NULL;
      }
    } catch (ErrorPacketException &e) {
      LOG_DEBUG("MySQLLockNode get an error packet when execute sql [%s].\n",
                sql);
      throw e;
    } catch (ExecuteNodeError &e) {
      if (conn) {
        handler->clean_dead_conn(&conn, space);
      }
      got_error = true;
      status = EXECUTE_STATUS_COMPLETE;
      throw e;
    } catch (exception &e) {
      got_error = true;
      status = EXECUTE_STATUS_COMPLETE;
      LOG_DEBUG("MySQLLockNode fail due to exception [%s].\n", e.what());
      string error_message("MySQLLockNode fail due to exception:");
      error_message.append(e.what());
      if (conn) {
        handler->clean_dead_conn(&conn, space);
      }
      throw ExecuteNodeError(error_message.c_str());
      ;
    }
  }
  status = EXECUTE_STATUS_COMPLETE;
  delete lock_table_list;
  lock_table_list = NULL;
#ifdef DEBUG
  node_end_timing();
#endif
#ifdef DEBUG
  LOG_DEBUG("MySQLLockNode %@ cost %d ms\n", this, node_cost_time);
#endif
}

/* class  MySQLTransactionUNLockNode */

MySQLTransactionUNLockNode::MySQLTransactionUNLockNode(ExecutePlan *plan,
                                                       const char *sql,
                                                       bool is_send_to_client)
    : MySQLExecuteNode(plan), conn(NULL) {
  this->name = "MySQLTransactionUNLockNode";
  this->sql = sql;
  this->is_send_to_client = is_send_to_client;
  got_error = false;
  packet = NULL;
  error_packet = NULL;
}

MySQLTransactionUNLockNode::~MySQLTransactionUNLockNode() {}

void MySQLTransactionUNLockNode::clean() {
  session->clear_running_xa_map();
  if (conn) {
    if (!got_error || error_packet) {
      handler->put_back_connection(dataspace, conn);
    } else {
      handler->clean_dead_conn(&conn, dataspace);
    }
    conn = NULL;
  }
  if (!handler->is_keep_conn()) {
    session->add_back_kept_cross_join_tmp_table();
    map<DataSpace *, Connection *> kept_connections =
        session->get_kept_connections();
    if (!kept_connections.empty()) {
      map<DataSpace *, Connection *>::iterator it;
      for (it = kept_connections.begin(); it != kept_connections.end(); it++) {
        handler->put_back_connection(it->first, it->second);
      }
    }
  }
  if (error_packet && error_packet != packet) {
    delete error_packet;
    error_packet = NULL;
  }
  if (packet) {
    delete packet;
    packet = NULL;
    error_packet = NULL;
  }
  if (optimize_xa_non_modified_sql) session->clean_xa_modified_conn_map();
  // session->clear_auto_increment_delete_values();
  LOG_DEBUG("Finish clean\n");
}

void MySQLTransactionUNLockNode::deal_savepoint() {
  // savepoint is not support for xa transaction
  // savepoint is not support for cluster xa transaction
  if ((!enable_xa_transaction ||
       session->get_session_option("close_session_xa").int_val != 0) &&
      session->check_for_transaction() &&
      !session->is_in_cluster_xa_transaction() &&
      plan->statement->get_stmt_node()->type == STMT_SAVEPOINT) {
    if (is_send_to_client) {
      LOG_DEBUG("deal_savepoint in TransactionUNLockNode %@\n", this);
      session->add_savepoint(
          plan->statement->get_stmt_node()->sql->savepoint_oper->point);
    }
  }
}

void MySQLTransactionUNLockNode::handle_if_no_kept_conn() {
  status = EXECUTE_STATUS_COMPLETE;
  deal_savepoint();
  if (!is_send_to_client || session->is_call_store_procedure()) return;

  bool has_dead_conn = false;
  vector<conn_result>::iterator it = commit_conn_result.begin();
  for (; it != commit_conn_result.end(); it++) {
    if (it->is_dead_conn) {
      has_dead_conn = true;
      break;
    }
  }

  if (has_dead_conn)
    throw ExecuteNodeError(
        "Get exception for commit with dead server connection.");

  send_ok_packet_to_client(handler, 0, 0);
  return;
}

void MySQLTransactionUNLockNode::handle_if_not_in_transaction() {
  status = EXECUTE_STATUS_COMPLETE;
  if (!is_send_to_client || session->is_call_store_procedure()) return;

  send_ok_packet_to_client(handler, 0, 0);
  return;
}

void MySQLTransactionUNLockNode::report_trans_end_for_consistence_point() {
  if (session->get_need_wait_for_consistence_point()) {
    session->end_commit_consistence_transaction();
  }
}
bool MySQLTransactionUNLockNode::execute_send_part() {
  map<DataSpace *, Connection *> kept_connections =
      session->get_kept_connections();
  if (kept_connections.empty()) {
    handle_if_no_kept_conn();
    return true;
  }
  if (!session->is_in_transaction() &&
      plan->statement->get_stmt_node()->type != STMT_UNLOCK_TB) {
    handle_if_not_in_transaction();
    return true;
  }

  stmt_type st_type = plan->statement->get_stmt_node()->type;
  if (st_type == STMT_COMMIT) {
    if (session->get_need_wait_for_consistence_point()) {
      session->start_commit_consistence_transaction();
    }
  }

  MySQLQueryRequest query(sql);
  query.set_sql_replace_char(plan->session->get_query_sql_replace_null_char());
  Packet exec_packet;
  query.pack(&exec_packet);

  map<DataSpace *, Connection *>::iterator it2;
  for (it2 = kept_connections.begin(); it2 != kept_connections.end();) {
    dataspace = it2->first;
    try {
#ifndef DBSCALE_TEST_DISABLE
      dbscale_test_info *test_info = plan->session->get_dbscale_test_info();
      if (!strcasecmp(test_info->test_case_name.c_str(),
                      "send_to_server_retry") &&
          !strcasecmp(test_info->test_case_operation.c_str(),
                      "throw_errors_commit") &&
          !strcasecmp(dataspace->get_name(), "tbl_bob")) {
        throw ExecuteNodeError("dbscale test execute node error.");
      }
#endif
      conn = handler->send_to_server_retry(dataspace, &exec_packet, "", false);
      it2++;
    } catch (...) {
      LOG_ERROR("TransactionUNLockNode fail send due to exception.\n");
      LOG_ERROR("Error dataspace name is [%s]\n", dataspace->get_name());
      list<string> *transaction_sqls = session->get_transaction_sqls();
      if (transaction_sqls->size()) {
        string error_massage("All SQLs related to this transaction are:\n");
        list<string>::iterator it_sql = transaction_sqls->begin();
        for (; it_sql != transaction_sqls->end(); it_sql++) {
          error_massage.append("SQL: ");
          error_massage.append(*it_sql);
          error_massage.append("\n");
        }
        LOG_ERROR("%s\n", error_massage.c_str());
      }
      conn_result con_ret;
      con_ret.is_dead_conn = true;
      con_ret.conn = NULL;
      con_ret.space = it2->first;
      con_ret.packet = NULL;
      commit_conn_result.push_back(con_ret);
      conn = it2->second;
      handler->clean_dead_conn(&conn, it2->first);
      kept_connections.erase(it2++);
    }

    conn = NULL;
  }

  /* Check if we can swap, the function is used in DirectExecutionNode.  If it
   * can swap, the state changes from SESSION_STATE_WORKING =>
   * SESSION_STATE_WAITING_SERVER. Otherwise, session state cahnge from
   * SESSION_STATE_WORKING => SESSION_STATE_HANDLING_RESULT */
  if (session->is_may_backend_exec_swap_able()) {
    map<DataSpace *, Connection *>::iterator it3;
    for (it3 = kept_connections.begin(); it3 != kept_connections.end(); it3++) {
      conn = it3->second;
      if (conn) {
        conn->set_session(session);
        struct event *conn_event = conn->get_conn_socket_event();
        evutil_socket_t conn_socket = conn->get_conn_socket();
        SocketEventBase *conn_base = conn->get_socket_base();
#ifdef DEBUG
        ACE_ASSERT(conn_base);
#endif
        session->add_server_base(conn_socket, conn_base, conn_event);
#ifdef DEBUG
        LOG_DEBUG(
            "Finish to prepare the conn socket session swap for conn %@ and "
            "session %@.\n",
            conn, session);
#endif
      }
    }
    conn = NULL;
    session->set_mul_connection_num(kept_connections.size());
    return true;
  }
  return false;
}
void MySQLTransactionUNLockNode::execute() {
#ifdef DEBUG
  node_start_timing();
#endif
  if (enable_cluster_xa_transaction &&
      session->is_in_cluster_xa_transaction()) {
    LOG_ERROR("is in xa transaction, cann't execute transaction sqls.\n");
    string err_message =
        "XAER_RMFAIL: The command cannot be executed when global transaction "
        "is in the  ";
    err_message.append(session
                           ->cluster_xa_transaction_to_string(
                               session->get_cluster_xa_transaction_state())
                           .c_str());
    err_message.append(" state");
    error_packet = Backend::instance()->get_new_packet();
    MySQLErrorResponse error(ERROR_XAER_RMFAIL_CODE, err_message.c_str(),
                             "XAE07");
    error.pack(error_packet);
    throw ErrorPacketException();
  }

  if (close_cross_node_transaction && session->session_modify_mul_server()) {
    LOG_ERROR(
        "Refuse to execute cross node transaction when "
        "close_cross_node_transaction != 0.\n");
    throw Error(
        "Refuse to execute cross node transaction when "
        "close_cross_node_transaction != 0.");
  }
  if (enable_xa_transaction &&
      plan->session->get_session_option("close_session_xa").int_val != 0 &&
      session->session_modify_mul_server()) {
    LOG_ERROR(
        "enable-xa-transaction =1 and current session close-session-xa !=0, so "
        "current session should not execute cross node transaction.\n");
    throw Error(
        "enable-xa-transaction =1 and current session close-session-xa !=0, so "
        "current session should not execute cross node transaction.");
  }

  if (session->get_session_state() == SESSION_STATE_WORKING) {
    if (execute_send_part()) return;
  }
  execute_receive_part();
}

bool MySQLTransactionUNLockNode::can_swap() {
  return session->is_may_backend_exec_swap_able();
}
void MySQLTransactionUNLockNode::execute_receive_part() {
  map<DataSpace *, Connection *> kept_connections =
      session->get_kept_connections();
  stmt_type st_type = plan->statement->get_stmt_node()->type;
  packet = Backend::instance()->get_new_packet();
  try {
    map<DataSpace *, Connection *>::iterator it;
    for (it = kept_connections.begin(); it != kept_connections.end(); it++) {
      try {
        conn = it->second;
        handler->receive_from_server(conn, packet);
        if (driver->is_error_packet(packet)) {
          conn_result con_ret;
          con_ret.conn = conn;
          con_ret.space = it->first;
          con_ret.is_dead_conn = false;

          MySQLErrorResponse response(packet);
          if (response.is_shutdown()) {
            if (conn) {
              con_ret.is_dead_conn = true;
            }
            session->set_server_shutdown(true);
            if (session->defined_lock_need_kept_conn(it->first))
              session->remove_defined_lock_kept_conn(it->first);
          }
          Packet *tmp_packet = Backend::instance()->get_new_packet();
          con_ret.packet = packet;
          packet = tmp_packet;
          commit_conn_result.push_back(con_ret);
          conn = NULL;
          continue;
        }
        conn->reset();
        handler->put_back_connection(it->first, it->second);
        conn = NULL;

      } catch (...) {
        LOG_DEBUG("TransactionUNLockNode fail receive due to exception.\n");
        conn_result con_ret;
        con_ret.is_dead_conn = true;
        con_ret.conn = NULL;
        con_ret.space = it->first;
        con_ret.packet = NULL;
        commit_conn_result.push_back(con_ret);
        if (session->defined_lock_need_kept_conn(it->first))
          session->remove_defined_lock_kept_conn(it->first);
        handler->clean_dead_conn(&conn, it->first);
      }
    }
    conn = NULL;

    if (commit_conn_result.empty()) {
      if (is_send_to_client) {
        handler->deal_autocommit_with_ok_eof_packet(packet);
        handler->record_affected_rows(packet);
        if (!session->is_call_store_procedure()) {
#ifdef DEBUG
          LOG_DEBUG("Sending transaction or unlock result to client\n");
#endif
          handler->send_to_client(packet);
        }
        deal_savepoint();
        is_send_to_client = false;
      }
    } else {
      /* If there is dead conn, we ignore all error packet, and throw
       * ExecuteNodeError. Otherwise, we store and use the first
       * error_packet.*/
      bool has_dead_conn = false;
      error_packet = NULL;
      vector<conn_result>::iterator it = commit_conn_result.begin();
      for (; it != commit_conn_result.end(); it++) {
        if (it->is_dead_conn) {
          has_dead_conn = true;
          if (it->conn) handler->clean_dead_conn(&(it->conn), it->space);
          continue;
        }
        if (it->packet) {
          if (error_packet)
            delete it->packet;
          else
            error_packet = it->packet;
          if (it->conn) handler->put_back_connection(it->space, it->conn);
        }
      }

      if (has_dead_conn)
        throw ExecuteNodeError(
            "Get exception for commit with dead server connection.");
      if (error_packet) throw ErrorPacketException();
      throw ExecuteNodeError("Unexpect behavior.");
    }
  } catch (ErrorPacketException &e) {
    LOG_DEBUG(
        "TransactionUNLockNode get an error packet when execute sql [%s].\n",
        sql);
    if (st_type == STMT_COMMIT) report_trans_end_for_consistence_point();
    status = EXECUTE_STATUS_COMPLETE;
    throw e;
  } catch (ExecuteNodeError &e) {
    if (conn) {
      handler->clean_dead_conn(&conn, dataspace);
      conn = NULL;
    }
    got_error = true;
    if (st_type == STMT_COMMIT) report_trans_end_for_consistence_point();
    status = EXECUTE_STATUS_COMPLETE;
    throw e;
  } catch (exception &e) {
    got_error = true;
    if (st_type == STMT_COMMIT) report_trans_end_for_consistence_point();

    status = EXECUTE_STATUS_COMPLETE;
    LOG_DEBUG("TransactionUNLockNode fail due to exception [%s].\n", e.what());
    string error_message("TransactionUNLockNode fail due to exception:");
    error_message.append(e.what());
    if (conn) {
      handler->clean_dead_conn(&conn, dataspace);
      /* Set the conn = NULL in case clean this conn again in deconstruct
       * method. */
      conn = NULL;
    }
    throw ExecuteNodeError(error_message.c_str());
    ;
  }
#ifdef DEBUG
  node_end_timing();
#endif
#ifdef DEBUG
  LOG_DEBUG("MySQLTransactionUNLockNode %@ cost %d ms\n", this, node_cost_time);
#endif
  if (st_type == STMT_COMMIT) report_trans_end_for_consistence_point();
  status = EXECUTE_STATUS_COMPLETE;
}

/* class MySQLXATransactionNode */
MySQLXATransactionNode::MySQLXATransactionNode(ExecutePlan *plan,
                                               const char *sql,
                                               bool is_send_to_client)
    : MySQLTransactionUNLockNode(plan, sql, is_send_to_client),
      has_optimized_readonly_conn(false) {
  this->name = "MySQLXATransactionNode";
  st_type = plan->statement->get_stmt_node()->type;
  is_error = false;
  warnings = 0;
  xa_command_type = XA_ROLLBACK;
  fail_num = 0;
  can_swap = false;
  has_swap = false;
  xa_state = XA_INIT_STATE;
  all_kept_conn_optimized = false;
  commit_fail = false;
}

void handle_conn_and_session_for_error(Connection *conn, Session *s,
                                       DataSpace *space) {
  s->get_handler()->clean_dead_conn(&conn, space);
}

int MySQLXATransactionNode::exec_non_xa_for_all_kept_conn(
    map<DataSpace *, Connection *> *kept_connections, DataSpace *dataspace,
    XACommand type, bool is_send_only) {
  try {
    if (is_send_only) {
      map<DataSpace *, Connection *>::iterator it;
      unsigned long xid = session->get_xa_id();
      char tmp[256];
      // TODO: This read-only connection will clean by backend thread in the
      // future #1427
      for (it = kept_connections->begin(); it != kept_connections->end();) {
        if (it->second->get_resource_status() == RESOURCE_STATUS_DEAD) {
          LOG_ERROR("Kept connection has been killed!\n");
          throw HandlerError("Connection has been killed!");
        }

        int len = sprintf(
            tmp, "%lu-%u-%d-%d-%u", xid, it->first->get_virtual_machine_id(),
            it->second->get_group_id(), Backend::instance()->get_cluster_id(),
            it->second->get_thread_id());
        tmp[len] = '\0';
        string sql = "XA END '";
        sql += tmp;
        sql += "'; XA ROLLBACK '";
        sql += tmp;
        sql += "';";
        if (it->first != dataspace) {
          try {
            if (it->second) {
              it->second->execute(sql.c_str(), 2);
              it->second->set_start_xa_conn(false);
            }
            it++;
          } catch (...) {
            if (session->defined_lock_need_kept_conn(it->first))
              session->remove_defined_lock_kept_conn(it->first);
            session->remove_kept_connection(it->first);
            session->remove_using_conn(it->second);
            it->second->get_pool()->add_back_to_dead(it->second);
            it->second = NULL;
            kept_connections->erase(it++);
          }
        } else {
          it++;
        }
      }
      if (dataspace && kept_connections->count(dataspace)) {
        if (type == XA_PREPARE) {
          int len = sprintf(
              tmp, "%lu-%u-%d-%d-%u", xid, dataspace->get_virtual_machine_id(),
              dataspace->get_group_id(), Backend::instance()->get_cluster_id(),
              ((*kept_connections)[dataspace])->get_thread_id());
          tmp[len] = '\0';
          string sql = "XA END '";
          sql += tmp;
          sql += "';XA COMMIT '";
          sql += tmp;
          sql += "' ONE PHASE";
          ((*kept_connections)[dataspace])->execute(sql.c_str(), 2);
          ((*kept_connections)[dataspace])->set_start_xa_conn(false);
        } else if (type == XA_ROLLBACK) {
          string sql = "XA END '";
          sql += tmp;
          sql += "'; XA ROLLBACK '";
          sql += tmp;
          sql += "';";
          ((*kept_connections)[dataspace])->execute(sql.c_str(), 2);
          ((*kept_connections)[dataspace])->set_start_xa_conn(false);
        } else {
          LOG_ERROR(
              "XACommand is not XA_PREPARE or XA_ROLLBACK in "
              "MySQLXATransactionNode\n");
          throw HandlerError("XACommand is not XA_PREPARE or XA_ROLLBACK");
        }
      }

      if (can_swap) {
        xa_swap_conns(kept_connections);
        session->set_mul_connection_num(kept_connections->size());
      }
      return 0;
    } else {
      if (dataspace && kept_connections->count(dataspace)) {
        if (((*kept_connections)[dataspace])->get_resource_status() ==
            RESOURCE_STATUS_DEAD) {
          LOG_ERROR("Kept connection has been killed!\n");
          throw HandlerError("Connection has been killed!");
        }

        ((*kept_connections)[dataspace])->handle_client_modify_return();
      }
    }
  } catch (...) {
    if (dataspace && kept_connections->count(dataspace)) {
      if (session->defined_lock_need_kept_conn(dataspace))
        session->remove_defined_lock_kept_conn(dataspace);
      session->remove_kept_connection(dataspace);
      session->remove_using_conn((*kept_connections)[dataspace]);
      ((*kept_connections)[dataspace])
          ->get_pool()
          ->add_back_to_dead(((*kept_connections)[dataspace]));
      ((*kept_connections)[dataspace]) = NULL;
      is_error = true;
    }
    receive_for_non_modify_connection(kept_connections, dataspace);
    return 1;
  }
  receive_for_non_modify_connection(kept_connections, dataspace);
  return 0;
}

void MySQLXATransactionNode::receive_for_non_modify_connection(
    map<DataSpace *, Connection *> *kept_connections, DataSpace *dataspace) {
  map<DataSpace *, Connection *>::iterator it;
  for (it = kept_connections->begin(); it != kept_connections->end(); it++) {
    if (it->first != dataspace) {
      try {
        if (it->second) {
          it->second->handle_client_modify_return();
        }
      } catch (...) {
        if (session->defined_lock_need_kept_conn(it->first))
          session->remove_defined_lock_kept_conn(it->first);
        session->remove_kept_connection(it->first);
        session->remove_using_conn(it->second);
        it->second->get_pool()->add_back_to_dead(it->second);
        it->second = NULL;
      }
    }
  }
}

list<DataSpace *> MySQLXATransactionNode::get_transaction_modified_spaces(
    Session *s) {
  map<DataSpace *, list<string> > *space_map = s->get_redo_logs_map();
  list<DataSpace *> dataspace_list;
  if (space_map == 0) {
    LOG_ERROR("redo log map is empty.\n");
    throw Error("redo log map is empty.");
  }
  map<DataSpace *, list<string> >::iterator it = space_map->begin();
  list<string>::iterator list_it;
  for (; it != space_map->end(); it++) {
    for (list_it = (it->second).begin(); list_it != (it->second).end();
         list_it++) {
      if (is_modify_sql(*list_it)) {
        dataspace_list.push_back(it->first);
        break;
      }
    }
  }
  return dataspace_list;
}

void MySQLXATransactionNode::xa_swap_conns(
    map<DataSpace *, Connection *> *kept_connections) {
  Connection *conn = NULL;
  map<DataSpace *, Connection *>::iterator it3;
  for (it3 = kept_connections->begin(); it3 != kept_connections->end(); it3++) {
    conn = it3->second;
    if (conn) {
      conn->set_session(session);
      struct event *conn_event = conn->get_conn_socket_event();
      evutil_socket_t conn_socket = conn->get_conn_socket();
      SocketEventBase *conn_base = conn->get_socket_base();
#ifdef DEBUG
      ACE_ASSERT(conn_base);
#endif
      session->add_server_base(conn_socket, conn_base, conn_event);
#ifdef DEBUG
      LOG_DEBUG(
          "Finish to prepare the conn socket session swap for conn %@ and "
          "session %@.\n",
          conn, session);
#endif
      // has_swap = true should only when session has add_server_base
      has_swap = true;
    }
  }
}
void MySQLXATransactionNode::xa_swap_conns(Connection *conn) {
  conn->set_session(session);
  struct event *conn_event = conn->get_conn_socket_event();
  evutil_socket_t conn_socket = conn->get_conn_socket();
  SocketEventBase *conn_base = conn->get_socket_base();
#ifdef DEBUG
  ACE_ASSERT(conn_base);
#endif
  session->add_server_base(conn_socket, conn_base, conn_event);
#ifdef DEBUG
  LOG_DEBUG(
      "Finish to prepare the conn socket session swap for conn %@ and session "
      "%@.\n",
      conn, session);
#endif
  session->set_mul_connection_num(1);
  has_swap = true;
}

void MySQLXATransactionNode::xa_swap_conns(map<Connection *, bool> *tx_rrlkc) {
  map<Connection *, bool>::iterator tx_it;
  Connection *conn = NULL;
  for (tx_it = tx_rrlkc->begin(); tx_it != tx_rrlkc->end(); tx_it++) {
    conn = tx_it->first;
    if (conn) {
      conn->set_session(session);
      struct event *conn_event = conn->get_conn_socket_event();
      evutil_socket_t conn_socket = conn->get_conn_socket();
      SocketEventBase *conn_base = conn->get_socket_base();
#ifdef DEBUG
      ACE_ASSERT(conn_base);
#endif
      session->add_server_base(conn_socket, conn_base, conn_event);
#ifdef DEBUG
      LOG_DEBUG(
          "Finish to prepare the conn socket session swap for conn %@ and "
          "session %@.\n",
          conn, session);
#endif
      has_swap = true;
    }
  }
}
int MySQLXATransactionNode::exec_xa_for_all_kept_conn(
    map<DataSpace *, Connection *> *kept_connections, XACommand type,
    bool is_send) {
  int ret = 0, tmp = 0;
  map<DataSpace *, Connection *>::iterator it;
  Driver *driver = Driver::get_driver();
  XA_helper *xa_helper = driver->get_xa_helper();
  unsigned long xid = session->get_xa_id();
  if (type == XA_PREPARE) {
    if (is_send) {
      for (it = kept_connections->begin(); it != kept_connections->end();) {
        tmp = xa_helper->exec_xa_commit_first_phase(session, it->first,
                                                    it->second);
        if (tmp) {
          ret++;
          int r = 1;
          if (!ACE_Reactor::instance()->reactor_event_loop_done()) {
            r = xa_helper->handle_xa_if_prepared_server_alived(
                session, it->first, it->second, true);
          }
          if (tmp == ERR_XA_CONN || r) {
            if (session->defined_lock_need_kept_conn(it->first))
              session->remove_defined_lock_kept_conn(it->first);
            handle_conn_and_session_for_error(it->second, session, it->first);
            char tmp_xid[256];
            int len = sprintf(tmp_xid, "%lu-%u-%d-%d-%u", xid,
                              it->first->get_virtual_machine_id(),
                              it->second->get_group_id(),
                              Backend::instance()->get_cluster_id(),
                              it->second->get_thread_id());
            tmp_xid[len] = '\0';
            Backend::instance()->add_source_need_rollback_xid_machine(
                it->first->get_data_source(), tmp_xid);
          }
          kept_connections->erase(it++);
        } else
          it++;
      }
      if (can_swap) {
        map<Connection *, bool> *tx_rrlkc =
            session->get_tx_record_redo_log_kept_connections();
        xa_swap_conns(tx_rrlkc);
        xa_swap_conns(kept_connections);
        session->set_mul_connection_num(kept_connections->size() +
                                        tx_rrlkc->size());
      }
      return ret;
    } else {
      map<Connection *, bool> *tx_rrlkc =
          session->get_tx_record_redo_log_kept_connections();
      map<Connection *, bool>::iterator tx_it;
      for (tx_it = tx_rrlkc->begin(); tx_it != tx_rrlkc->end(); tx_it++) {
        tmp = xa_helper->handle_after_xa_prepare(session, tx_it->first);
        if (tmp) {
          ret++;
        }
        if (tmp == ERR_XA_CONN) {
          session->set_tx_record_redo_log_connection_to_dead(tx_it->first);
        }
      }
      session->clean_all_tx_record_redo_log_kept_connections();
      for (it = kept_connections->begin(); it != kept_connections->end();) {
        tmp = xa_helper->handle_after_xa_prepare(session, it->second);
        (it->second)->reset();
        if (tmp) {
          ret++;
          int r = 1;
          if (!ACE_Reactor::instance()->reactor_event_loop_done()) {
            r = xa_helper->handle_xa_if_prepared_server_alived(
                session, it->first, it->second, true);
          }
          if (tmp == ERR_XA_CONN || r) {
            if (session->defined_lock_need_kept_conn(it->first))
              session->remove_defined_lock_kept_conn(it->first);
            handle_conn_and_session_for_error(it->second, session, it->first);
            char tmp_xid[256];
            int len = sprintf(tmp_xid, "%lu-%u-%d-%d-%u", xid,
                              it->first->get_virtual_machine_id(),
                              it->second->get_group_id(),
                              Backend::instance()->get_cluster_id(),
                              it->second->get_thread_id());
            tmp_xid[len] = '\0';
            Backend::instance()->add_source_need_rollback_xid_machine(
                it->first->get_data_source(), tmp_xid);
          }
          kept_connections->erase(it++);
        } else
          it++;
      }
      return ret;
    }
  } else if (type == XA_ROLLBACK) {
    if (is_send) {
      for (it = kept_connections->begin(); it != kept_connections->end();) {
        tmp = xa_helper->exec_xa_rollback(session, it->first, it->second);
        if (tmp) {
          // For rollback, we assume that the only possible reason for execution
          // fail is server unavaliable.
          ret++;
          int r = 1;
          if (!ACE_Reactor::instance()->reactor_event_loop_done()) {
            r = xa_helper->handle_xa_if_prepared_server_alived(
                session, it->first, it->second, true);
          }
          if (tmp == ERR_XA_CONN || r) {
            if (session->defined_lock_need_kept_conn(it->first))
              session->remove_defined_lock_kept_conn(it->first);
            handle_conn_and_session_for_error(it->second, session, it->first);
            char tmp_xid[256];
            int len = sprintf(tmp_xid, "%lu-%u-%d-%d-%u", xid,
                              it->first->get_virtual_machine_id(),
                              it->second->get_group_id(),
                              Backend::instance()->get_cluster_id(),
                              it->second->get_thread_id());
            tmp_xid[len] = '\0';
            Backend::instance()->add_source_need_rollback_xid_machine(
                it->first->get_data_source(), tmp_xid);
          }

          kept_connections->erase(it++);
        } else
          it++;
      }
    }
    return ret;
  } else if (type == XA_ROLLBACK_AFTER_PREPARE) {
    if (is_send) {
      for (it = kept_connections->begin(); it != kept_connections->end();) {
        tmp = xa_helper->exec_xa_rollback_after_prepare(session, it->first,
                                                        it->second);
        if (tmp) {
          int r = 1;
          if (!ACE_Reactor::instance()->reactor_event_loop_done()) {
            r = xa_helper->handle_xa_if_prepared_server_alived(
                session, it->first, it->second, true);
          }
          if (r) {
            char tmp[256];
            int len = sprintf(tmp, "%lu-%u-%d-%d-%u", xid,
                              it->first->get_virtual_machine_id(),
                              it->second->get_group_id(),
                              Backend::instance()->get_cluster_id(),
                              it->second->get_thread_id());
            tmp[len] = '\0';
            Backend::instance()->add_source_need_rollback_xid_machine(
                it->first->get_data_source(), tmp);
          }
          // For rollback, we assume that the only possible reason for execution
          // fail is server unavaliable.
          ret++;
          if (session->defined_lock_need_kept_conn(it->first))
            session->remove_defined_lock_kept_conn(it->first);
          handle_conn_and_session_for_error(it->second, session, it->first);
          kept_connections->erase(it++);
        } else
          it++;
      }
    }
    return ret;
  } else if (type == XA_COMMIT) {
    if (is_send) {
#ifndef DBSCALE_TEST_DISABLE
      /*just for test federated_max_rows*/
      Backend *bk = Backend::instance();
      dbscale_test_info *test_info = bk->get_dbscale_test_info();
      if (!strcasecmp(test_info->test_case_name.c_str(), "xa_running_test") &&
          !strcasecmp(test_info->test_case_operation.c_str(), "commit_block")) {
        LOG_DEBUG(
            "Do dbscale test operation 'commit_block' for case "
            "'xa_running_test'.\n");
        while (strcasecmp(test_info->test_case_operation.c_str(), "")) {
          ACE_OS::sleep(1);
        }
        LOG_DEBUG(
            "Finish test operation 'commit_block' for case "
            "'xa_running_test'.\n");
      }
#endif

      for (it = kept_connections->begin(); it != kept_connections->end();) {
        tmp = xa_helper->exec_xa_commit_second_phase(session, it->first,
                                                     it->second);
        if (tmp) {
          // For commit, we assume that the only possible reason for execution
          // fail is server unavaliable.
          ret++;
          int r = 1;
          if (!ACE_Reactor::instance()->reactor_event_loop_done()) {
            r = xa_helper->handle_xa_if_prepared_server_alived(
                session, it->first, it->second, false);
          }
          if (r) {
            // the xid machine need commit success, add to backend and wait for
            // recover
            char tmp[256];
            int len = sprintf(tmp, "%lu-%u-%d-%d-%u", xid,
                              it->first->get_virtual_machine_id(),
                              it->second->get_group_id(),
                              Backend::instance()->get_cluster_id(),
                              it->second->get_thread_id());
            tmp[len] = '\0';
            Backend::instance()->add_source_need_recover_xid_machine(
                it->first->get_data_source(), tmp);
            commit_fail = true;
          } else
            handle_xa_success_spaces.push_back(it->first);
          if (session->defined_lock_need_kept_conn(it->first))
            session->remove_defined_lock_kept_conn(it->first);
          handle_conn_and_session_for_error(it->second, session, it->first);
          kept_connections->erase(it++);
        } else
          it++;
      }
      if (can_swap) {
        xa_swap_conns(kept_connections);
        session->set_mul_connection_num(kept_connections->size());
      }
      return ret;
    } else {
      for (it = kept_connections->begin(); it != kept_connections->end();
           it++) {
        tmp = xa_helper->handle_after_xa_commit(session, it->first, it->second);
        if (tmp) {
          // For commit, we assume that the only possible reason for execution
          // fail is server unavaliable.
          ret++;
          int r = 1;
          if (!ACE_Reactor::instance()->reactor_event_loop_done()) {
            r = xa_helper->handle_xa_if_prepared_server_alived(
                session, it->first, it->second, false);
          }
          if (r) {
            // the xid machine need commit success, add to backend and wait
            // for recover
            unsigned long xid = session->get_xa_id();
            char tmp[256];
            int len = sprintf(tmp, "%lu-%u-%d-%d-%u", xid,
                              it->first->get_virtual_machine_id(),
                              it->second->get_group_id(),
                              Backend::instance()->get_cluster_id(),
                              it->second->get_thread_id());
            tmp[len] = '\0';
            Backend::instance()->add_source_need_recover_xid_machine(
                it->first->get_data_source(), tmp);
            commit_fail = true;
          } else
            handle_xa_success_spaces.push_back(it->first);
          if (session->defined_lock_need_kept_conn(it->first))
            session->remove_defined_lock_kept_conn(it->first);
          handle_conn_and_session_for_error(it->second, session, it->first);
        }
      }
      if (!commit_fail) {
        unsigned long xid = session->get_xa_id();
        char tmp_xid[256];
        int len = sprintf(tmp_xid, "%d-%lu",
                          Backend::instance()->get_cluster_id(), xid);
        tmp_xid[len] = '\0';

        // only all connection commit success, then do clean
        for (it = kept_connections->begin(); it != kept_connections->end();
             it++) {
          MySQLXA_purge_thread::instance()->add_xid_to_purge(
              it->first->get_data_source(), tmp_xid);
        }
        vector<DataSpace *>::iterator it2 = handle_xa_success_spaces.begin();
        for (; it2 != handle_xa_success_spaces.end(); it2++) {
          MySQLXA_purge_thread::instance()->add_xid_to_purge(
              (*it2)->get_data_source(), tmp_xid);
        }
      }
      return ret;
    }
  }
  return ret;
}
void MySQLXATransactionNode::change_xa_state(XASwapState state) {
  LOG_DEBUG("xa state change from [%d] to [%d] \n", xa_state, state);
  xa_state = state;
}

bool MySQLXATransactionNode::xa_init() {
  kept_connections = session->get_kept_connections();
  map<DataSpace *, Connection *>::iterator it = kept_connections.begin();
  for (; it != kept_connections.end(); ++it) {
    if (it->first == Backend::instance()->get_auth_data_space()) {
      DataSpace *auth_space = it->first;
      Connection *auth_conn = it->second;
      handle_auth_space_for_xa(auth_space, auth_conn);
      kept_connections.erase(it);
      break;
    }
  }
  if (kept_connections.empty()) {
    handle_if_no_kept_conn();
    return false;
  }
  if (!session->is_in_transaction()) {
    handle_if_not_in_transaction();
    return false;
  }
  if (!session->get_xa_id()) {
    handle_if_not_in_transaction();
    return false;
  }

  if (st_type == STMT_COMMIT) {
    if (session->get_xa_need_wait_for_consistence_point()) {
      session->start_commit_consistence_transaction();
    }
    if (!session->get_has_global_flush_read_lock()) {
      /*In flush tables with read lock mode, one server may has more than one
       * kept conn to execute flush command and hold the global read lock.  IN
       * this case, do xa commit will deadlock. So in this case, we should do
       * xa rollback, which is the default value for xa_command_type.*/
      xa_command_type = XA_PREPARE;
    }
  }

  if (!optimize_xa_non_modified_sql)
    dataspace_list = get_transaction_modified_spaces(session);
  else
    handle_optimize_xa_non_modified_sql();
  can_swap = session->is_may_backend_exec_swap_able();
  change_xa_state(XA_FIRST_PHASE_SEND_STATE);
  return true;
}

void MySQLXATransactionNode::handle_auth_space_for_xa(DataSpace *auth_space,
                                                      Connection *auth_conn) {
  unsigned long xid = session->get_xa_id();
  char tmp[256];
  int len =
      sprintf(tmp, "%lu-%u-%d-%d-%u", xid, auth_space->get_virtual_machine_id(),
              auth_conn->get_group_id(), Backend::instance()->get_cluster_id(),
              auth_conn->get_thread_id());
  tmp[len] = '\0';
  string sql = "XA END '";
  sql += tmp;
  sql += "'; XA ROLLBACK '";
  sql += tmp;
  sql += "';";
  try {
    auth_conn->execute(sql.c_str(), 2);
    auth_conn->handle_client_modify_return();
    auth_conn->set_start_xa_conn(false);
  } catch (...) {
    session->remove_kept_connection(auth_space);
    session->remove_using_conn(auth_conn);
    auth_conn->get_pool()->add_back_to_dead(auth_conn);
  }
}

void MySQLXATransactionNode::handle_optimize_xa_non_modified_sql() {
  if (optimize_xa_non_modified_sql && !has_optimized_readonly_conn &&
      !plan->session->is_in_lock() && plan->session->is_in_transaction()) {
    has_optimized_readonly_conn = true;
    bool contain_readonly_conn = false;
    map<DataSpace *, Connection *>::iterator it;
    for (it = kept_connections.begin(); it != kept_connections.end();) {
      char tmp[256];
      int len = sprintf(
          tmp, "%lu-%u-%d-%d-%u", session->get_xa_id(),
          it->first->get_virtual_machine_id(), it->second->get_group_id(),
          Backend::instance()->get_cluster_id(), it->second->get_thread_id());
      tmp[len] = '\0';
      if (readonly_conn_can_optimize(it->first, it->second, tmp)) {
        kept_connections.erase(it++);
        contain_readonly_conn = true;
        continue;
      }
      it++;
    }
    if (contain_readonly_conn) {
      session->get_status()->item_inc(TIMES_XA_OPTIMIZE_READ_ONLY_STMT);
      for (unsigned int i = 0; i < optimize_xa_non_modified_sql_thread_num;
           ++i) {
        Backend::instance()->get_xa_readonly_conn_handler(i)->signal_cond();
      }
      if (kept_connections.empty()) {
        all_kept_conn_optimized = true;
      }
    }

    dataspace_list.clear();
    map<DataSpace *, Connection *>::iterator map_it;
    for (map_it = kept_connections.begin(); map_it != kept_connections.end();
         map_it++) {
      dataspace_list.push_back(map_it->first);
    }
  }
}

bool MySQLXATransactionNode::readonly_conn_can_optimize(DataSpace *dataspace,
                                                        Connection *conn,
                                                        string xid) {
  // should not put back the read only conn in the lock mode.
  if (!session->get_has_global_flush_read_lock() &&
      !plan->session->is_xa_modified_conn(conn)) {
    // should not put back the read only conn in get_lock.
    if (session->defined_lock_need_kept_conn(dataspace)) return false;
    if (session->remove_kept_connection(dataspace)) {
      session->remove_using_conn(conn);
      // should check whether remove kept_connections success or not
      // Otherwise there are two threads share one connection
      Backend::instance()
          ->get_xa_readonly_conn_handler(
              atoll(xid.c_str()) % optimize_xa_non_modified_sql_thread_num)
          ->add_conn_to_map(conn, xid);
      LOG_DEBUG(
          "in xa transaction, add readonly connection [%@] to backend thread, "
          "this backend thread will send 'XA ROLLBACK' to server\n",
          conn);
      return true;
    }
  }
  return false;
}
void MySQLXATransactionNode::report_xa_trans_end_for_consistence_point() {
  if (session->get_xa_need_wait_for_consistence_point()) {
    session->end_commit_consistence_transaction();
  }
}
void MySQLXATransactionNode::execute() {
  if (close_cross_node_transaction && session->session_modify_mul_server()) {
    LOG_ERROR(
        "Refuse to execute cross node transaction when "
        "close_cross_node_transaction != 0.\n");
    throw Error(
        "Refuse to execute cross node transaction when "
        "close_cross_node_transaction != 0.");
  }

  if (all_kept_conn_optimized) {
    status = EXECUTE_STATUS_COMPLETE;
    change_xa_state(XA_END_STATE);
  }
  try {
    if (xa_state == XA_INIT_STATE) {
      if (!xa_init()) return;
    }

    if (!all_kept_conn_optimized &&
        (dataspace_list.size() == 1 || dataspace_list.size() == 0)) {
      DataSpace *space = NULL;
      if (dataspace_list.size() == 1) {
        space = dataspace_list.front();
        if (xa_state == XA_FIRST_PHASE_SEND_STATE)
          session->get_status()->item_inc(
              TIMES_XA_OPTIMIZE_ONLY_AFFECT_ONE_SERVER);
      }
      switch (xa_state) {
        case XA_FIRST_PHASE_SEND_STATE: {
          fail_num = exec_non_xa_for_all_kept_conn(&kept_connections, space,
                                                   xa_command_type, true);
          // if get error, do not swap
          if (fail_num) {
            change_xa_state(XA_END_STATE);
            break;
          }
          change_xa_state(XA_FIRST_PHASE_RECV_STATE);
          if (has_swap) {
            has_swap = false;
            return;
          }
        }
        case XA_FIRST_PHASE_RECV_STATE: {
          fail_num = exec_non_xa_for_all_kept_conn(&kept_connections, space,
                                                   xa_command_type, false);
          change_xa_state(XA_END_STATE);
          break;
        }
        default: {
          LOG_ERROR("XATransactionNode get unknown xa_state [%d]\n", xa_state);
#ifdef DEBUG
          ACE_ASSERT(0);
#endif
        }
      }
    } else if (!all_kept_conn_optimized) {
      switch (xa_state) {
        case XA_FIRST_PHASE_SEND_STATE: {
          unsigned long xid = session->get_xa_id();
          session->add_running_xa_map(xid,
                                      xa_command_type == XA_PREPARE
                                          ? RUNNING_XA_PREPARE
                                          : RUNNING_XA_ROLLBACK,
                                      &kept_connections);

          session->record_relate_source_redo_log(&kept_connections);
          fail_num = exec_xa_for_all_kept_conn(&kept_connections,
                                               xa_command_type, true);
          change_xa_state(XA_FIRST_PHASE_RECV_STATE);
          if (has_swap) {
            has_swap = false;
            return;
          }
        }
        case XA_FIRST_PHASE_RECV_STATE: {
          fail_num += exec_xa_for_all_kept_conn(&kept_connections,
                                                xa_command_type, false);
          kept_connections.clear();
          kept_connections = session->get_kept_connections();

          if (xa_command_type == XA_PREPARE) {
            if (fail_num == 0) {
              session->acquire_using_conn_mutex();
              // check be killed before go to the last commit, if this check
              // passed, kill will not terminate this handler during the second
              // phase commit.
              if (handler->be_killed()) {
                session->release_using_conn_mutex();
                throw ThreadIsKilled();
              }
              session->set_xa_prepared();
              session->release_using_conn_mutex();
              xa_command_type = XA_COMMIT;
            } else {
              is_error = true;
              xa_command_type = XA_ROLLBACK_AFTER_PREPARE;
            }
          }
          change_xa_state(XA_SECOND_PHASE_SEND_STATE);
        }
        case XA_SECOND_PHASE_SEND_STATE: {
          unsigned long xid = session->get_xa_id();
          if (session->add_running_xa_map(xid, xa_command_type == XA_COMMIT
                                                   ? RUNNING_XA_COMMIT
                                                   : RUNNING_XA_ROLLBACK)) {
            // this running xa transaction contains fail source conn, so abort
            // finial commit.
            if (xa_command_type == XA_COMMIT)
              xa_command_type = XA_ROLLBACK_AFTER_PREPARE;
            LOG_INFO(
                "Set xa transaction %d to XA_ROLLBACK_AFTER_PREPARE for "
                "session %@.\n",
                xid, session);
          }

          if (xa_command_type == XA_COMMIT ||
              xa_command_type == XA_ROLLBACK_AFTER_PREPARE) {
            if (exec_xa_for_all_kept_conn(&kept_connections, xa_command_type,
                                          true)) {
              if (Backend::instance()->get_backend_server_version() ==
                      MYSQL_VERSION_57 ||
                  Backend::instance()->get_backend_server_version() ==
                      MYSQL_VERSION_8) {
                warnings++;
                WarnInfo *w = new WarnInfo(
                    WARNING_COMMIT_DELAY_SUCCESS_CODE,
                    dbscale_err_msg[WARNING_COMMIT_DELAY_SUCCESS_CODE]);
                session->add_warning_info(w);
              } else {
                is_error = true;
              }
            }
          }
          change_xa_state(XA_SECOND_PHASE_RECV_STATE);
          if (has_swap) {
            has_swap = false;
            return;
          }
        }
        case XA_SECOND_PHASE_RECV_STATE: {
          if (xa_command_type == XA_COMMIT ||
              xa_command_type == XA_ROLLBACK_AFTER_PREPARE) {
            if (exec_xa_for_all_kept_conn(&kept_connections, xa_command_type,
                                          false)) {
              if (Backend::instance()->get_backend_server_version() ==
                      MYSQL_VERSION_57 ||
                  Backend::instance()->get_backend_server_version() ==
                      MYSQL_VERSION_8) {
                warnings++;
                WarnInfo *w = new WarnInfo(
                    WARNING_COMMIT_DELAY_SUCCESS_CODE,
                    dbscale_err_msg[WARNING_COMMIT_DELAY_SUCCESS_CODE]);
                session->add_warning_info(w);
              } else {
                is_error = true;
              }
            }
          }
          change_xa_state(XA_END_STATE);
          break;
        }
        default: {
          LOG_ERROR("XATransactionNode get unknown xa_state [%d]\n", xa_state);
#ifdef DEBUG
          ACE_ASSERT(0);
#endif
        }
      }
    }
    if (!session->get_has_global_flush_read_lock()) {
      // In global read lock mode, should not add conn back to free
      session->remove_all_connection_to_free();
    }

    if (is_send_to_client) {
      try {
        // TODO: if commit failed, block the failed source.
        if (is_error) {
          packet = NULL;
          if (xa_command_type == XA_COMMIT) {
            packet = handler->get_error_packet(
                ERROR_XA_EXECUTE_FAIL_CODE,
                "Get error during final transaction commit phase.", NULL);
          } else {
            packet = handler->get_error_packet(
                ERROR_XA_EXECUTE_FAIL_CODE, "Fail to end the XA transaction!",
                NULL);
          }
          if (!session->is_call_store_procedure()) {
            handler->send_to_client(packet);
            delete packet;
            packet = NULL;
            session->set_has_send_client_error_packet();
          }
          error_packet = packet;
          if (session->is_call_store_procedure())
            throw ErrorPacketException();
          else
            throw ExecuteNodeError(
                "MySQLXATransactionNode::execute get error.");
        } else {
          if (!session->is_call_store_procedure()) {
            send_ok_packet_to_client(handler, 0, warnings);
          }
        }
      } catch (...) {
        status = EXECUTE_STATUS_COMPLETE;
        throw;
      }

      is_send_to_client = false;
    }

    status = EXECUTE_STATUS_COMPLETE;
    if (st_type == STMT_COMMIT) report_xa_trans_end_for_consistence_point();

  } catch (Exception &e) {
    status = EXECUTE_STATUS_COMPLETE;
    if (st_type == STMT_COMMIT) report_xa_trans_end_for_consistence_point();

    LOG_ERROR("XATransactionNode fail due to Exception [%s].\n", e.what());
    throw;
  } catch (exception &e) {
    got_error = true;
    status = EXECUTE_STATUS_COMPLETE;
    if (st_type == STMT_COMMIT) report_xa_trans_end_for_consistence_point();

    LOG_ERROR("XATransactionNode fail due to exception [%s].\n", e.what());
    string error_message("XATransactionNode fail due to exception:");
    error_message.append(e.what());
    throw ExecuteNodeError(error_message.c_str());
    ;
  }
}

/* class MySQLFetchNode */

MySQLFetchNode::MySQLFetchNode(ExecutePlan *plan, DataSpace *dataspace,
                               const char *sql)
    : MySQLExecuteNode(plan, dataspace), conn(NULL), cond(mutex) {
  this->sql.append(sql);
  this->name = "MySQLFetchNode";
  has_get_partition_key_pos = false;
  thread_status = THREAD_STOP;
  bthread = NULL;
  sql_sent = false;
  got_error = false;
  this->eof_packet = NULL;
  this->end_packet = NULL;
  is_get_end_packet = false;
  this->error_packet = NULL;
  ready_rows_size = 0;

  ready_buffer_rows_size = 0;
  if (max_fetchnode_ready_rows_size > 18446744073709551615UL / 1024UL) {
    max_fetchnode_buffer_rows_size = 18446744073709551615UL;
  } else {
    max_fetchnode_buffer_rows_size = max_fetchnode_ready_rows_size * 1024;
  }
  migrate_partition_key_pos_vec = NULL;
  header_received = false;
  pkt_list.clear();
  if (use_packet_pool) {
    id_in_plan = session->get_next_id_in_plan() %
                 ((size_t)session->get_packet_pool_count());
  } else {
    id_in_plan = 0;
  }
  kept_ready_packets = 0;
  local_fetch_signal_batch = fetch_signal_batch;
  force_use_non_trx_conn = false;
  ready_rows->set_session(plan->session);
  plan->session->set_has_fetch_node(true);
  LOG_DEBUG("Plan %@ FetchNode %@ id %Q\n", plan, this, id_in_plan);
}

void MySQLFetchNode::execute() {
  if (plan->session->check_for_transaction() &&
      session->get_session_option("cursor_use_free_conn").int_val) {
    force_use_non_trx_conn = plan->is_cursor;
  }
  if (!sql_sent) {
    session->set_skip_mutex_in_operation(true);
    try {
#ifndef DBSCALE_TEST_DISABLE
      Backend *bk = Backend::instance();
      dbscale_test_info *test_info = bk->get_dbscale_test_info();
      if (!strcasecmp(test_info->test_case_name.c_str(), "fetchnode") &&
          !strcasecmp(test_info->test_case_operation.c_str(), "unkown_error")) {
        throw Error("unknown error.");
      }
#endif
      Packet exec_packet;
      MySQLQueryRequest query(sql.c_str());
      query.set_sql_replace_char(
          plan->session->get_query_sql_replace_null_char());
      query.pack(&exec_packet);
      if (plan->get_migrate_tool()) {
        conn = plan->get_migrate_tool()->get_migrate_read_conn();
        handler->send_to_server(conn, &exec_packet);
      } else {
        if (plan->statement->is_cross_node_join()) {
          conn = handler->send_to_server_retry(
              dataspace, &exec_packet, session->get_schema(), false, true,
              false, force_use_non_trx_conn);
        } else {
          conn = handler->send_to_server_retry(
              dataspace, &exec_packet, session->get_schema(),
              session->is_read_only(), true, false, force_use_non_trx_conn);
        }
      }
      LOG_DEBUG("Get connection %@ for node %@.\n", conn, this);
      sql_sent = true;
      session->set_skip_mutex_in_operation(false);
    } catch (Exception &e) {
      mutex.acquire();
      got_error = true;
      mutex.release();
      status = EXECUTE_STATUS_COMPLETE;
      if (conn) {
        if (!plan->get_migrate_tool())
          handler->clean_dead_conn(&conn, dataspace, !force_use_non_trx_conn);
        else {
          conn->set_status(CONNECTION_STATUS_TO_DEAD);
          conn = NULL;
        }
      }
      LOG_ERROR("Send packet error : %s.\n", e.what());
      error_message.append(e.what());
      record_migrate_error_message(plan, error_message);
      return;
    } catch (exception &e) {
      mutex.acquire();
      got_error = true;
      status = EXECUTE_STATUS_COMPLETE;
      mutex.release();
      if (conn) {
        if (!plan->get_migrate_tool())
          handler->clean_dead_conn(&conn, dataspace, !force_use_non_trx_conn);
        else {
          conn->set_status(CONNECTION_STATUS_TO_DEAD);
          conn = NULL;
        }
      }
      error_message.append("Execute Node failed: ");
      error_message.append(e.what());
      LOG_ERROR("[%s]\n", error_message.c_str());
      record_migrate_error_message(plan, error_message);
      return;
    }
  }
}

bool MySQLFetchNode::can_swap() {
  return session->is_may_backend_exec_swap_able() & (!got_error);
}

void MySQLFetchNode::clean() {
  /* check if the fetch thread finished */
  if (thread_status == THREAD_STARTED) {
    LOG_DEBUG("Fetch node %@ cleaning wait.\n", this);
    this->wait_for_cond();
    LOG_DEBUG("Fetch node %@ cleaning wait finish.\n", this);
  } else if (thread_status == THREAD_CREATED) {
    bthread->re_init_backend_thread();
    bthread->get_pool()->add_back_to_free(bthread);
  } else {
    got_error = true;
  }

  Packet *packet;
  if (eof_packet) {
    delete eof_packet;
    eof_packet = NULL;
  }

  while (!field_packets.empty()) {
    packet = field_packets.front();
    field_packets.pop_front();
    delete packet;
  }
  field_packets.clear();
  packet = NULL;

  while (!ready_rows->empty()) {
    packet = ready_rows->front();
    ready_rows->pop_front();
    delete packet;
  }

  while (!ready_rows_kept.empty()) {
    packet = ready_rows_kept.front();
    ready_rows_kept.pop_front();
    delete packet;
  }
  kept_ready_packets = 0;

  ready_rows->clear();
  packet = NULL;

  if (use_packet_pool && !pkt_list.empty()) {
    int s = (int)pkt_list.size();
    session->put_free_packet_back_to_pool(id_in_plan, s, pkt_list);
    pkt_list.clear();
  }

  if (end_packet) {
    delete end_packet;
    end_packet = NULL;
  }

  if (conn) {
    if (!got_error || error_packet) {
      if (!plan->get_migrate_tool())
        handler->put_back_connection(dataspace, conn, force_use_non_trx_conn);
    } else {
      if (!plan->get_migrate_tool())
        handler->clean_dead_conn(&conn, dataspace, !force_use_non_trx_conn);
      else
        conn->set_status(CONNECTION_STATUS_TO_DEAD);
    }
    conn = NULL;
  }

  if (error_packet) {
    if (error_packet != &header_packet) {
      delete error_packet;
    }
    error_packet = NULL;
  }
  if (migrate_partition_key_pos_vec) {
    migrate_partition_key_pos_vec->clear();
    delete migrate_partition_key_pos_vec;
    migrate_partition_key_pos_vec = NULL;
  }
}

void MySQLFetchNode::add_kept_list_to_ready_and_signal() {
  try {
    ACE_Guard<ACE_Thread_Mutex> guard(mutex);
    if (!ready_rows_kept.empty()) {
      while (!ready_rows_kept.empty()) {
        ready_rows->push_back(ready_rows_kept.front());

        ready_buffer_rows_size += ready_rows_kept.front()->total_capacity();
        ready_rows_size++;
        ready_rows_kept.pop_front();
      }
      cond.signal();
      kept_ready_packets = 0;
    }
  } catch (ListOutOfMemError &e) {
    throw;
  } catch (...) {
    cond.signal();
    throw;
  }
}

void MySQLFetchNode::get_partition_key_pos() {
  if (plan->get_migrate_tool() && !has_get_partition_key_pos) {
    has_get_partition_key_pos = true;
    vector<const char *> *key_names_vec =
        plan->get_migrate_tool()->get_partition_key_names();
    if (key_names_vec == NULL)
      migrate_partition_key_pos_vec = NULL;
    else {
      migrate_partition_key_pos_vec = new vector<unsigned int>();
      vector<const char *>::iterator it = key_names_vec->begin();
      list<Packet *>::iterator it_field;
      unsigned int index = 0;
      // record the pos of partition key
      for (it_field = field_packets.begin(); it_field != field_packets.end();
           it_field++, index++) {
        MySQLColumnResponse col_resp(*it_field);
        col_resp.unpack();

        for (it = key_names_vec->begin(); it != key_names_vec->end(); it++) {
          if (strcmp(*it, col_resp.get_column()) == 0) {
            migrate_partition_key_pos_vec->push_back(index);
            break;
          }
        }
      }
    }
  }
}
bool MySQLFetchNode::migrate_filter(Packet *row) {
  if (migrate_partition_key_pos_vec == NULL) return true;
  MySQLRowResponse row_res(row);
  vector<string> partition_key_value;
  vector<unsigned int>::iterator it = migrate_partition_key_pos_vec->begin();
  for (; it != migrate_partition_key_pos_vec->end(); it++) {
    unsigned int pos = *it;
    // check whether the value of partition key is NULL
    if (!row_res.field_is_null(pos)) {
      uint64_t str_len = 0;
      const char *column_str = row_res.get_str(pos, &str_len);
      string tmp;
      tmp.append(column_str, str_len);
      partition_key_value.push_back(tmp);
    } else {
      LOG_ERROR("Get partition key value[NULL] when do migrate.\n");
#ifdef DEBUG
      ACE_ASSERT(0);
#endif
      throw Error("Get partition key value[NULL] when do migrate.");
    }
  }
  vector<const char *> values;
  for (unsigned i = 0; i < partition_key_value.size(); i++) {
    values.push_back(partition_key_value.at(i).c_str());
  }
  return plan->get_migrate_tool()->filter(&values);
}
/* start the FetchNode thread using this method. */
void MySQLFetchNode::start_thread() {
  if (thread_status == THREAD_STOP && !got_error &&
      !plan->get_fetch_node_no_thread()) {
    // start the new thread
    bthread = plan->get_one_bthread();
    if (!bthread) {
      got_error = true;
      LOG_ERROR(
          "Fail to get a backend thread from pool, so the fetch node stop.\n");
      throw Error(
          "Fail to get a backend thread from pool, so the fetch node stop");
    }
    bthread->set_task(this);
    thread_status = THREAD_CREATED;
  }
}

int MySQLFetchNode::fetch_row() {
  Packet *packet;
  if (is_get_end_packet || got_error) {
    status = EXECUTE_STATUS_COMPLETE;
    return 0;
  }
  if (!header_received && receive_header_packets()) {
    return 1;
  }
  ExecuteProfileHandler *execute_profile = session->get_profile_handler();
  unsigned int tmp_id = execute_profile->start_parallel_monitor(
      get_executenode_name(), conn->get_server()->get_name(), sql.c_str());

  try {
    ready_rows_size = 0;
    packet = Backend::instance()->get_new_packet(
        row_packet_size, session->get_fetch_node_packet_alloc());
    handler->receive_from_server(conn, packet);

    unsigned int count_index = -1;
    handle_federated_empty_resultset(packet, count_index);
    // Receiving row packets
    while (!driver->is_eof_packet(packet)) {
      if (driver->is_error_packet(packet)) {
        LOG_ERROR("FetchNode %@ get an error packet.\n", this);
        Packet *tmp_packet = NULL;
        // Receiving error packet
        // packet is located on session->get_fetch_node_packet_alloc()
        // session need refresh session->get_fetch_node_packet_alloc()
        // so mv packet memory from session->get_fetch_node_packet_alloc() to
        // new memory
        transfer_packet(&packet, &tmp_packet);
        handle_error_packet(tmp_packet);
        return 1;
      }
      if (count_index != (unsigned int)-1) {
        uint64_t count_num = 1;
        MySQLRowResponse count_row(packet);
        count_num = count_row.get_uint(count_index);
        if (count_num == 0) {
          wakeup_federated_follower();
        }
        count_index = -1;
      }
#ifdef DEBUG
      LOG_DEBUG("FetchNode %@ get a row packet.\n", this);
#endif
      parent->add_row_packet(this, packet);
      ready_rows_size++;
      if (max_fetchnode_ready_rows_size &&
          ready_buffer_rows_size > max_fetchnode_buffer_rows_size) {
#ifndef DBSCALE_TEST_DISABLE
        LOG_INFO("FetchNode Full\n");
#endif
        return 1;
      }
      bool row_map_size_overtop =
          parent->get_need_restrict_row_map_size() &&
          ((parent->get_buffer_rowmap_size(this) >=
            max_fetchnode_buffer_rows_size) ||
           (parent->get_rowmap_size(this) >= rowmap_size_config));
      if (row_map_size_overtop) return 1;
      packet = Backend::instance()->get_new_packet(
          row_packet_size, session->get_fetch_node_packet_alloc());
      handler->receive_from_server(conn, packet);
    }
    if (driver->is_eof_packet(packet)) {
      if (support_show_warning)
        handle_warnings_OK_and_eof_packet(plan, packet, handler, dataspace,
                                          conn);
    }
    LOG_DEBUG("FetchNode %@ got a eof packet.\n", this);
    is_get_end_packet = true;
    delete packet;
  } catch (...) {
    LOG_ERROR("FetchNode %@ exit cause self error: %s.\n", this, e.what());
    handle_error_packet(NULL);
    error_message.append("Execute Node failed: ");
    error_message.append(e.what());
    if (conn)
      handler->clean_dead_conn(&conn, dataspace, !force_use_non_trx_conn);
    conn = NULL;
  }
  execute_profile->end_execute_monitor(tmp_id);
  return 1;
}

void MySQLFetchNode::handle_error_throw() {
  if (got_error) throw_error_packet();
}

/** Return ture if send row packet to parent, else return false.
 * Return ture if send row packet to parent, else return false.
 */
bool MySQLFetchNode::notify_parent() {
  Packet *packet;
  int ret = false;
  if (plan->get_fetch_node_no_thread()) {
    session->set_skip_mutex_in_operation(true);
    ret = fetch_row();
    session->set_skip_mutex_in_operation(false);
    if (is_finished() || got_error) {
      if (got_error) {
        ;  // we do nothing here, we would throw exception later.
      } else {
#ifdef DEBUG
        LOG_DEBUG("FetchNode %@ is finished.\n", this);
#endif
      }
      ret = false;
      status = EXECUTE_STATUS_COMPLETE;
    }
    return ret;
  }

  ACE_Guard<ACE_Thread_Mutex> guard(mutex);
  // check fetch node finished or get error
  if (is_finished() || got_error) {
    if (got_error) {
      throw_error_packet();
    } else {
#ifdef DEBUG
      LOG_DEBUG("FetchNode %@ is finished.\n", this);
#endif
      ret = false;
    }
  } else {
    if (ready_rows->empty()) cond.wait();

    if (got_error) {
      throw_error_packet();
      ret = false;
    } else if (ready_rows->empty()) {  // the result set is empty
      ACE_ASSERT(is_finished());
      LOG_DEBUG("FetchNode %@ is finished after wait.\n", this);
      ret = false;
    } else {
      bool is_migrate =
          plan->get_migrate_tool() && migrate_partition_key_pos_vec;
      bool row_map_size_overtop =
          parent->get_need_restrict_row_map_size() &&
          ((parent->get_buffer_rowmap_size(this) >=
            max_fetchnode_buffer_rows_size) ||
           (parent->get_rowmap_size(this) >= rowmap_size_config));
#ifdef DEBUG
      if (parent->get_need_restrict_row_map_size())
        LOG_DEBUG("the parent of fetchnode %s is %d,parent buffer size is %u\n",
                  parent->get_executenode_name(), row_map_size_overtop,
                  parent->get_buffer_rowmap_size(this));
#endif

      // filter packet for partition table
      if (is_migrate) {
        if (!row_map_size_overtop) {
          while (!ready_rows->empty()) {
            packet = ready_rows->front();
            ready_rows->pop_front();
            ready_rows_size--;
            if (migrate_filter(packet))
              parent->add_row_packet(this, packet);
            else
              delete packet;
          }
        }
      } else if (!row_map_size_overtop) {
        if (ready_rows_size > 0) {
          parent->swap_ready_list_with_row_map_list(
              this, &ready_rows, ready_rows_size, ready_buffer_rows_size);
          ready_rows_size = 0;
          ready_buffer_rows_size = 0;
        }
      }
      ret = true;
    }
  }

  return ret;
}

/* If the fetch node get an empty result set, check the if
 * it contains federated table, if is and there's only one last
 * federated thread has not registed to the rule, then the leader
 * federated thread has not be created, wakeup a waiting thread.
 */
void MySQLFetchNode::wakeup_federated_follower() {
  set<string> name_vec;
  plan->statement->get_fe_tmp_table_name(sql, name_vec);
  set<string>::iterator it = name_vec.begin();
  string tmp_table_name;
  Backend *backend = Backend::instance();
  for (; it != name_vec.end(); it++) {
    tmp_table_name.assign(*it);
    LOG_DEBUG("Get federated cross node join table name %s from sql %s.\n",
              tmp_table_name.c_str(), sql.c_str());
    DataSpace *send_space = backend->get_data_space_for_table(
        TMP_TABLE_SCHEMA, tmp_table_name.c_str());
    DataSource *send_source = send_space->get_data_source();
    CrossNodeJoinManager *cross_join_manager =
        backend->get_cross_node_join_manager();
    Session *work_session =
        cross_join_manager->get_work_session(tmp_table_name);
#ifdef DEBUG
    ACE_ASSERT(work_session);
#endif
    if (!send_source) tmp_table_name.append("_par0");
    TransferRuleManager *rule_manager =
        work_session->get_transfer_rule_manager();
    TransferRule *rule =
        rule_manager->get_transfer_rule_by_remote_table_name(tmp_table_name);
    if (rule->is_leader_thread()) {
      rule->wakeup_one_follower();
    }
  }
}

void MySQLFetchNode::handle_federated_empty_resultset(
    Packet *packet, unsigned int &count_index) {
  // TODO:Change the way of checking the sql if is a federated tmp table join
  // sql.
  if (session->get_session_option("cross_node_join_method").int_val ==
          DATA_MOVE_READ &&
      sql.find(TMP_TABLE_NAME) != string::npos) {
    if (driver->is_eof_packet(packet)) {
      wakeup_federated_follower();
    } else {
      // Check the query if contains 'COUNT()'.
      list<AggregateDesc> aggr_list;
      get_aggregate_functions(plan->statement->get_stmt_node()->scanner,
                              aggr_list);
      list<AggregateDesc>::iterator it_agg = aggr_list.begin();
      for (; it_agg != aggr_list.end(); it_agg++) {
        if (it_agg->type == AGGREGATE_TYPE_COUNT) {
          count_index = it_agg->column_index;
          break;
        }
      }
    }
  }
}

void MySQLFetchNode::handle_dead_xa_conn(Connection *conn, DataSpace *space) {
  if (conn->is_start_xa_conn()) {
    unsigned long xid = session->get_xa_id();
    char tmp[256];
    int len =
        sprintf(tmp, "%lu-%u-%d-%d-%u", xid, space->get_virtual_machine_id(),
                conn->get_group_id(), Backend::instance()->get_cluster_id(),
                conn->get_thread_id());
    tmp[len] = '\0';
    string sql = "XA END '";
    sql += tmp;
    sql += "'; XA ROLLBACK '";
    sql += tmp;
    sql += "';";
    Connection *exe_conn = NULL;
    exe_conn = space->get_connection(session);
    if (exe_conn) {
      try {
        exe_conn->execute(sql.c_str(), 2);
        exe_conn->handle_client_modify_return();
        conn->set_start_xa_conn(false);
        exe_conn->get_pool()->add_back_to_free(conn);
        exe_conn = NULL;
      } catch (...) {
        LOG_DEBUG("Fail to rollback %s on conn %@ before add to dead\n",
                  sql.c_str(), conn);
        if (exe_conn) {
          exe_conn->get_pool()->add_back_to_dead(exe_conn);
        }
      }
    }
  }
}

int MySQLFetchNode::svc() {
  Packet *packet = NULL;
  if (is_finished()) return FINISHED;
#ifdef DEBUG
  node_start_timing();
#endif

  if (!header_received) LOG_DEBUG("FetchNode %@ SQL : %s\n", this, sql.c_str());
  if (!header_received && receive_header_packets()) {
    return FINISHED;
  }
  ExecuteProfileHandler *execute_profile = session->get_profile_handler();
  unsigned int tmp_id = execute_profile->start_parallel_monitor(
      get_executenode_name(), conn->get_server()->get_name(), sql.c_str());
  int get_row_packet_num = 0;
#ifndef DBSCALE_TEST_DISABLE
  int loop_count = 1;
#endif
  try {
    if (use_packet_pool && pkt_list.empty()) {
      session->get_free_packet_from_pool(
          id_in_plan, packet_pool_packet_bundle_local, &pkt_list);
    }
    if (!use_packet_pool || pkt_list.empty()) {
      packet = Backend::instance()->get_new_packet(row_packet_size);
    } else {
      packet = pkt_list.front();
      pkt_list.pop_front();
    }
    handler->receive_from_server(conn, packet);
    get_partition_key_pos();  // get partition pos for migrate
    unsigned int count_index = -1;
    handle_federated_empty_resultset(packet, count_index);
    // Receiving row packets
    while (!driver->is_eof_packet(packet)) {
      if (driver->is_error_packet(packet)) {
        MySQLErrorResponse error(packet);
        error.unpack();
        LOG_ERROR("FetchNode node %@ get an error packet %@, %d (%s) %s.\n",
                  this, packet, error.get_error_code(), error.get_sqlstate(),
                  error.get_error_message());

        handle_error_packet(packet);
        packet = NULL;
        return FINISHED;
      }

      if (parent->is_finished()) {
        if (!session->is_keeping_connection()) {
          LOG_INFO(
              "FetchNode %@ is not keeping connection, exit cause parent "
              "finished.\n",
              this);
          if (conn) {
            if (!plan->get_migrate_tool()) {
              handle_dead_xa_conn(conn, dataspace);
              handler->clean_dead_conn(&conn, dataspace,
                                       !force_use_non_trx_conn);
            } else
              conn->set_status(CONNECTION_STATUS_TO_DEAD);
            conn = NULL;
          }
          handle_error_packet(NULL);
          delete packet;
          packet = NULL;
          return FINISHED;
        } else {
          while (!driver->is_eof_packet(packet)) {
            handler->receive_from_server(conn, packet);
            if (driver->is_error_packet(packet)) {
              LOG_ERROR("FetchNode %@ get an error packet.\n", this);
              handle_error_packet(packet);
              packet = NULL;
              return FINISHED;
            }
          }
          break;
        }
      }

      if (count_index != (unsigned int)-1) {
        uint64_t count_num = 1;
        MySQLRowResponse count_row(packet);
        count_num = count_row.get_uint(count_index);
        if (count_num == 0) {
          wakeup_federated_follower();
        }
        count_index = -1;
      }
#ifdef DEBUG
      LOG_DEBUG("FetchNode %@ get a row packet.\n", this);
#endif
#ifndef DBSCALE_TEST_DISABLE
      loop_count++;
      if (loop_count == 5) {
        Backend *bk = Backend::instance();
        dbscale_test_info *test_info = bk->get_dbscale_test_info();
        if (test_info->test_case_name.length() &&
            !strcasecmp(test_info->test_case_name.c_str(), "load_select") &&
            !strcasecmp(test_info->test_case_operation.c_str(),
                        "load_select_fetch_fail")) {
          ACE_OS::sleep(2);
          throw Exception("dbscale test fail.");
        }
      }
#endif

      get_row_packet_num++;
      kept_ready_packets++;
      ready_rows_kept.push_back(packet);

      packet = NULL;
      if (kept_ready_packets >= local_fetch_signal_batch) {
        add_kept_list_to_ready_and_signal();
      }

      if (get_row_packet_num >= MAX_FETCH_NODE_RECEIVE) {
        if (kept_ready_packets > 0) {
          add_kept_list_to_ready_and_signal();
        }
        return WORKING;
      }
      if (max_fetchnode_ready_rows_size) {
        bool need_break = false;
        while (max_fetchnode_ready_rows_size &&
               ready_buffer_rows_size >= max_fetchnode_buffer_rows_size) {
          LOG_DEBUG("Fetchnode full,ready_buffer_rows_size in node is %u \n",
                    ready_buffer_rows_size);
          if (parent->is_finished() ||
              ACE_Reactor::instance()->reactor_event_loop_done()) {
            LOG_INFO(
                "fetchnode sleeping cancelled because parent finished or ACE "
                "reactor event loop done.\n");

            if ((parent->is_finished() && !session->is_keeping_connection()) ||
                ACE_Reactor::instance()->reactor_event_loop_done()) {
              LOG_INFO(
                  "FetchNode %@ is not keeping connection, exit cause parent "
                  "finished.\n",
                  this);
              if (conn) {
                if (!plan->get_migrate_tool()) {
                  handle_dead_xa_conn(conn, dataspace);
                  handler->clean_dead_conn(&conn, dataspace,
                                           !force_use_non_trx_conn);
                } else
                  conn->set_status(CONNECTION_STATUS_TO_DEAD);
                conn = NULL;
              }
              handle_error_packet(NULL);
              delete packet;
              packet = NULL;
              return FINISHED;
            } else {
              while (!driver->is_eof_packet(packet)) {
                handler->receive_from_server(conn, packet);
                if (driver->is_error_packet(packet)) {
                  LOG_ERROR("FetchNode %@ get an error packet.\n", this);
                  handle_error_packet(packet);
                  packet = NULL;
                  return FINISHED;
                }
              }
              need_break = true;
              break;
            }
          }
          if (kept_ready_packets > 0) {
            add_kept_list_to_ready_and_signal();
          }
          return NEED_SLEEP;
        }
        if (need_break) break;
      }
      if (use_packet_pool && pkt_list.empty()) {
        session->get_free_packet_from_pool(
            id_in_plan, packet_pool_packet_bundle_local, &pkt_list);
      }
      if (!use_packet_pool || pkt_list.empty()) {
        packet = Backend::instance()->get_new_packet(row_packet_size);
      } else {
        packet = pkt_list.front();
        pkt_list.pop_front();
      }
      handler->receive_from_server(conn, packet);
    }
    if (kept_ready_packets > 0) {
      add_kept_list_to_ready_and_signal();
    }

    if (driver->is_eof_packet(packet)) {
      if (support_show_warning)
        handle_warnings_OK_and_eof_packet(plan, packet, handler, dataspace,
                                          conn);
    }
  } catch (ListOutOfMemError &e) {
    LOG_ERROR("FetchNode %@ exit cause self error: %s\n", this, e.what());
    string msg = "FetchNode exit cause self error:";
    msg += e.what();
    record_migrate_error_message(plan, msg);
    error_message.append("There are no enough memory for the sql.");
    handle_error_packet(NULL);
    if (packet) {
      delete packet;
      packet = NULL;
    }
    cond.signal();
    return FINISHED;
  } catch (exception &e) {
    LOG_ERROR("FetchNode %@ exit cause self error: %s.\n", this, e.what());
    string msg = "FetchNode exit cause self error:";
    msg += e.what();
    record_migrate_error_message(plan, msg);
    handle_error_packet(NULL);
    error_message.append("Execute Node failed: ");
    error_message.append(e.what());
    if (packet) {
      delete packet;
      packet = NULL;
    }
    cond.signal();
    return FINISHED;
  }

  if (conn) {
    if (has_sql_calc_found_rows()) {
      found_rows(handler, driver, conn, session);
      Packet *packet_tmp = session->get_error_packet();
      if (packet_tmp) {
        LOG_ERROR("FetchNode %@ get an error packet.\n", this);
        handle_error_packet(packet_tmp);
        cond.signal();
        return FINISHED;
      }
    }
  }

  LOG_DEBUG("FetchNode %@ got a eof packet.\n", this);
  // Receiving end packet
  mutex.acquire();
  end_packet = packet;
  packet = NULL;
  status = EXECUTE_STATUS_COMPLETE;
  cond.signal();
  mutex.release();
  execute_profile->end_execute_monitor(tmp_id);

  if (plan->statement->get_stmt_node()->has_unknown_func && conn)
    session->record_xa_modified_conn(conn);

  // release the conn assp
  if (conn) {
    if (!plan->get_migrate_tool())
      handler->put_back_connection(dataspace, conn, force_use_non_trx_conn);
    conn = NULL;
  }
#ifdef DEBUG
  node_end_timing();
#endif
#ifdef DEBUG
  LOG_DEBUG("MySQLFetchNode %@ cost %d ms\n", this, node_cost_time);
#endif

  return FINISHED;
}

int MySQLFetchNode::receive_header_packets() {
  Packet *tmp_packet;
  header_received = true;
  try {
    conn->handle_merge_exec_begin_or_xa_start(session);
    handler->receive_from_server(conn, &header_packet);
    if (driver->is_ok_packet(&header_packet)) {
      LOG_DEBUG("fetch node get an ok packet, sql[%s].\n", sql.c_str());
      throw HandlerError("Unexpected error, fetch node get an ok packet.");
    }

    if (driver->is_error_packet(&header_packet)) {
      MySQLErrorResponse error(&header_packet);
      error.unpack();
      LOG_ERROR("FetchNode node %@ get an error packet %@, %d (%s) %s.\n", this,
                &header_packet, error.get_error_code(), error.get_sqlstate(),
                error.get_error_message());

      handle_error_packet(&header_packet);
      return 1;
    }

    tmp_packet = Backend::instance()->get_new_packet(row_packet_size);
    // Receiving column packets.
    handler->receive_from_server(conn, tmp_packet);
    while (!driver->is_eof_packet(tmp_packet)) {
      if (driver->is_error_packet(tmp_packet)) {
        handle_error_packet(tmp_packet);
        return 1;
      }
      field_packets.push_back(tmp_packet);
      tmp_packet = Backend::instance()->get_new_packet(row_packet_size);
      handler->receive_from_server(conn, tmp_packet);
    }
  } catch (Exception &e) {
    mutex.acquire();
    got_error = true;
    status = EXECUTE_STATUS_COMPLETE;
    if (conn) {
      if (!plan->get_migrate_tool())
        handler->clean_dead_conn(&conn, dataspace, !force_use_non_trx_conn);
      else {
        conn->set_status(CONNECTION_STATUS_TO_DEAD);
        conn = NULL;
      }
    }
    LOG_ERROR("Receive header error : %s.\n", e.what());
    error_message.append(e.what());
    cond.signal();
    mutex.release();
    return 1;
  } catch (exception &e) {
    mutex.acquire();
    got_error = true;
    status = EXECUTE_STATUS_COMPLETE;
    if (conn) {
      if (!plan->get_migrate_tool())
        handler->clean_dead_conn(&conn, dataspace, !force_use_non_trx_conn);
      else {
        conn->set_status(CONNECTION_STATUS_TO_DEAD);
        conn = NULL;
      }
    }
    LOG_ERROR("Receive header error : unknown error.\n");
    error_message.append("Execute Node failed: ");
    error_message.append(e.what());
    cond.signal();
    mutex.release();
    return 1;
  }

  LOG_DEBUG("Fetch Node %@ receive header finished.\n", this);
  // Set eof packet
  eof_packet = tmp_packet;
  return 0;
}

/* class MySQLSendNode */

MySQLSendNode::MySQLSendNode(ExecutePlan *plan) : MySQLInnerNode(plan) {
  send_header_flag = true;
  this->name = "MySQLSendNode";
  this->send_packet_profile_id = -1;
  this->wait_child_profile_id = -1;
  select_uservar_flag = statement->get_select_uservar_flag();
  select_field_num = statement->get_select_field_num();
  if (select_uservar_flag) {
    uservar_vec = *(statement->get_select_uservar_vec());
  }
  this->federated_max_rows = (uint64_t)(
      session->get_session_option("max_federated_cross_join_rows").ulong_val);
  this->cross_join_max_rows = (uint64_t)(
      session->get_session_option("max_cross_join_moved_rows").ulong_val);
#ifndef DBSCALE_TEST_DISABLE
  /*just for test federated_max_rows*/
  Backend *bk = Backend::instance();
  dbscale_test_info *test_info = bk->get_dbscale_test_info();
  if (!strcasecmp(test_info->test_case_name.c_str(), "federated_max_rows") &&
      !strcasecmp(test_info->test_case_operation.c_str(), "abort")) {
    this->federated_max_rows = 1;
  }
#endif
  row_num = 0;
  tmp_id = 0;
  node_can_swap = session->is_may_backend_exec_swap_able();
  pkt_list.clear();
  pkt_list_size = 0;
  field_num = 0;
  ready_rows->set_session(plan->session);
}

void MySQLSendNode::send_header() {
  LOG_DEBUG("Start to Send header.\n");
  Packet *header_packet = get_header_packet();
  handler->send_mysql_packet_to_client_by_buffer(header_packet);
  list<Packet *> *field_packets = get_field_packets();

  vector<MySQLColumnType> v_ctype;
  if (session->is_binary_resultset()) {
    if (session->get_prepare_item(session->get_execute_stmt_id())) {
      list<MySQLColumnType> *column_type_list =
          session->get_prepare_item(session->get_execute_stmt_id())
              ->get_column_type_list();
      list<MySQLColumnType>::iterator it_c = column_type_list->begin();
      for (; it_c != column_type_list->end(); it_c++) {
        v_ctype.push_back(*it_c);
      }
    }
  }

  size_t pos = 0;
  for (std::list<Packet *>::iterator it = field_packets->begin();
       it != field_packets->end(); it++) {
    if (select_uservar_flag) {
      MySQLColumnResponse column_response(*it);
      column_response.unpack();
      bool is_number = column_response.is_number();
      field_is_number_vec.push_back(is_number);
    }

    if (session->is_binary_resultset()) {
      if (!v_ctype.empty() && v_ctype.size() > pos) {
        MySQLColumnType prepare_type = v_ctype[pos];
        MySQLColumnResponse col_resp(*it);
        col_resp.unpack();
        MySQLColumnType col_type = col_resp.get_column_type();
        if (col_type != prepare_type) {
          col_resp.set_column_type(prepare_type);
          col_resp.pack(*it);
        }
        LOG_DEBUG(
            "Adjust the column %s from type %d to type %d for binary result "
            "convert.\n",
            col_resp.get_column(), int(col_type), int(prepare_type));
      }
    }

    handler->send_mysql_packet_to_client_by_buffer(*it);
    ++field_num;
    pos++;
  }
  Packet *eof_packet = get_eof_packet();
  handler->deal_autocommit_with_ok_eof_packet(eof_packet);
  handler->send_mysql_packet_to_client_by_buffer(eof_packet);
}

void MySQLExecuteNode::rebuild_packet_first_column_dbscale_row_id(
    Packet *row, uint64_t row_num, unsigned int field_num) {
  MySQLRowResponse row_resp(row);
  vector<string> vec;
  row_resp.fill_columns_to_vector(&vec, field_num);
  char tmp[21];
  sprintf(tmp, "%lu", row_num);
  vec[0] = tmp;
  list<const char *> row_data;
  for (unsigned int i = 0; i < field_num; ++i) {
    row_data.push_back(vec[i].c_str());
  }
  MySQLRowResponse row_resp2(row_data);
  row_resp2.pack(row);
}

void MySQLSendNode::send_row(MySQLExecuteNode *ready_child) {
  send_packet_profile_id = session->get_profile_handler()->start_serial_monitor(
      get_executenode_name(), "SendNode send packet", "",
      send_packet_profile_id);
  Packet *end_row = NULL;
  if (!row_map[ready_child]->empty()) end_row = row_map[ready_child]->back();
  if (statement->get_select_uservar_flag() && end_row != NULL) {
    MySQLRowResponse row_response(end_row);
    set_select_uservar_by_result(end_row, field_is_number_vec, uservar_vec,
                                 select_field_num, session);
  }
  Packet *row = NULL;
  if (!plan->is_federated() && !plan->statement->is_cross_node_join() &&
      !session->is_binary_resultset()) {
    while (!row_map[ready_child]->empty()) {
      row_num++;
      try {
        row = row_map[ready_child]->front();
        if (is_first_column_dbscale_row_id) {
          rebuild_packet_first_column_dbscale_row_id(row, row_num, field_num);
        }
        handler->send_mysql_packet_to_client_by_buffer(row);
      } catch (...) {
        row_map[ready_child]->pop_front();
        delete row;
        throw;
      }
      row_map[ready_child]->pop_front();
      if (use_packet_pool) {
        pkt_list.push_back(row);
        pkt_list_size++;
        // if ((size_t)pkt_list_size >= packet_pool_packet_bundle_local) {
        //  session->put_free_packet_back_to_pool(ready_child->get_id_in_plan(),
        //  pkt_list_size, pkt_list);
        //}
      } else {
        delete row;
      }
    }
  } else {
    while (!row_map[ready_child]->empty()) {
      if (plan->is_federated() && row_num >= federated_max_rows) {
        status = EXECUTE_STATUS_COMPLETE;
        LOG_ERROR(
            "Reach the max rows of [%u] for federated middle result set.\n",
            row_num);
        throw ExecuteNodeError(
            "Reach the max row number of federated middle result set.");
      }
      if (plan->statement->is_cross_node_join() &&
          row_num > cross_join_max_rows) {
        status = EXECUTE_STATUS_COMPLETE;
        LOG_ERROR(
            "Reach the max rows of [%u] for cross node join max moved rows.\n",
            row_num);
        throw ExecuteNodeError(
            "Reach the max row number of cross node join max moved rows.");
      }
      row = row_map[ready_child]->front();
      row_num++;
      if (is_first_column_dbscale_row_id) {
        rebuild_packet_first_column_dbscale_row_id(row, row_num, field_num);
      }
      if (session->is_binary_resultset()) {
        MySQLRowResponse row_resp(row);
        if (session->get_prepare_item(session->get_execute_stmt_id())) {
          list<MySQLColumnType> *column_type_list =
              session->get_prepare_item(session->get_execute_stmt_id())
                  ->get_column_type_list();
          row_resp.convert_to_binary(
              column_type_list,
              handler->get_convert_result_to_binary_stringstream(), &row);
        } else {
          LOG_ERROR("Failed to get prepare item for execute #%d.\n",
                    session->get_execute_stmt_id());
          throw ExecuteCommandFail("Cannot get prepare item.");
        }
      }
      try {
        handler->send_mysql_packet_to_client_by_buffer(row);
      } catch (...) {
        row_map[ready_child]->pop_front();
        delete row;
        throw;
      }
      row_map[ready_child]->pop_front();
      if (use_packet_pool) {
        pkt_list.push_back(row);
        pkt_list_size++;
        // if ((size_t)pkt_list_size >= packet_pool_packet_bundle_local) {
        //  session->put_free_packet_back_to_pool(ready_child->get_id_in_plan(),
        //  pkt_list_size, pkt_list);
        //}
      } else {
        delete row;
      }
    }
  }
  if (use_packet_pool && !pkt_list.empty()) {
    session->put_free_packet_back_to_pool(ready_child->get_id_in_plan(),
                                          pkt_list_size, pkt_list);
  }
  session->get_profile_handler()->end_execute_monitor(send_packet_profile_id);
}

void MySQLSendNode::clear_row_map() {
  list<MySQLExecuteNode *>::iterator it;
  for (it = children.begin(); it != children.end(); ++it) {
    Packet *row;
    while (!row_map[*it]->empty()) {
      row = row_map[*it]->front();
      row_map[*it]->pop_front();
      delete row;
    }
  }
}

void MySQLSendNode::send_eof() {
  LOG_DEBUG("Start to send eof.\n");
  Packet *end_packet = get_end_packet();
  if (!end_packet) {
    build_eof_packet();
    end_packet = &generated_eof;
  }
  if (plan->session->is_call_store_procedure() ||
      plan->session->get_has_more_result()) {
    rebuild_eof_with_has_more_flag(end_packet, driver);
    LOG_DEBUG(
        "For the call store procedure or multiple stmt, the last eof"
        " should be with flag has_more_result in send node.\n");
  }
  LOG_DEBUG("end_packet = %@\n", end_packet);
  handler->deal_autocommit_with_ok_eof_packet(end_packet);
  handler->send_mysql_packet_to_client_by_buffer(end_packet);
}

void MySQLSendNode::handle_children() {
  bool has_handle_child = false;
  list<MySQLExecuteNode *>::iterator it;
  for (it = children.begin(); it != children.end(); ++it) {
    if (!row_map[*it]->empty()) {
      handle_child(*it);
      has_handle_child = true;
    }
  }
  if (has_handle_child && plan->get_fetch_node_no_thread()) {
    handle_discarded_packets();
    session->reset_fetch_node_packet_alloc();
  }
}

void MySQLSendNode::execute() {
  ExecuteProfileHandler *execute_profile = session->get_profile_handler();
  while (status != EXECUTE_STATUS_COMPLETE) {
    switch (status) {
      case EXECUTE_STATUS_START:
        tmp_id = execute_profile->start_serial_monitor(get_executenode_name(),
                                                       "SendNode all", "");
        init_row_map();
        status = EXECUTE_STATUS_FETCH_DATA;
        break;

      case EXECUTE_STATUS_FETCH_DATA:
        children_execute();
        if (node_can_swap && plan->plan_can_swap()) {
          handle_swap_connections();
          return;
        }
        status = EXECUTE_STATUS_WAIT;

      case EXECUTE_STATUS_WAIT:
        try {
          wait_child_profile_id =
              session->get_profile_handler()->start_serial_monitor(
                  get_executenode_name(), "SendNode wait", "",
                  wait_child_profile_id);

          wait_children();
          if (one_child_got_error && !all_children_finished) {
            status = EXECUTE_STATUS_FETCH_DATA;
            clear_row_map();
          }
          session->get_profile_handler()->end_execute_monitor(
              wait_child_profile_id);
        } catch (ExecuteNodeError &e) {
          status = EXECUTE_STATUS_COMPLETE;
          throw e;
        }
        break;

      case EXECUTE_STATUS_HANDLE:
        try {
          handle_children();
        } catch (ClientBroken &e) {
          if (plan->get_fetch_node_no_thread()) set_children_error();
          throw;
        }
        status = EXECUTE_STATUS_FETCH_DATA;
        break;

      case EXECUTE_STATUS_BEFORE_COMPLETE:
        if (send_header_flag) {
          send_header();
          send_header_flag = false;
        }
        send_eof();
        flush_net_buffer();
        status = EXECUTE_STATUS_COMPLETE;

      case EXECUTE_STATUS_COMPLETE:
#ifdef DEBUG
        node_end_timing();
#endif
        execute_profile->end_execute_monitor(tmp_id);
#ifdef DEBUG
        LOG_DEBUG("MySQLSendNode %@ cost %d ms\n", this, node_cost_time);
#endif
        break;

      default:
        break;
    }
  }
  if (!has_sql_calc_found_rows()) {
    session->set_found_rows(row_num);
  }
  session->set_real_fetched_rows(row_num);
}

void append_column_value_to_replace_sql(string &replace_sql,
                                        const char *column_str,
                                        uint64_t column_len, ResultType type,
                                        CharsetType ctype) {
  if (type == RESULT_TYPE_STRING) {
    string tmp;
    tmp.append(column_str, column_len);
    deal_with_str_column_value(&tmp, ctype);
    replace_sql.append(tmp);
  } else
    replace_sql.append(column_str, column_len);
}
/* class MySQLQueryForMulColumnNode*/
MySQLQueryForMulColumnNode::MySQLQueryForMulColumnNode(ExecutePlan *plan,
                                                       DataSpace *dataspace,
                                                       const char *sql)
    : MySQLDirectExecuteNode(plan, dataspace, sql), has_get_one_row(false) {
  this->name = "MySQLQueryForMulColumnNode";
#ifdef DEBUG
  ACE_ASSERT(plan->get_sub_query_result_node());
#endif
  res_node = plan->get_sub_query_result_node();
  res_node->replace_sql = string("select 1 from dual where 1=0");
  col_nums = 0;
  is_direct_node = false;
}

void MySQLQueryForMulColumnNode::handle_send_client_packet(Packet *packet,
                                                           bool is_row_packet) {
  if (is_row_packet) {
    if (has_get_one_row) {
      throw dbscale::sql::SQLError(dbscale_err_msg[ERROR_ONE_ROW_CODE], "21000",
                                   ERROR_ONE_ROW_CODE);
    }
    if (!has_get_one_row) {
      res_node->replace_sql.clear();
      res_node->row_columns.clear();
    }
    handle_one_row(packet);
    has_get_one_row = true;
  }
}

void MySQLQueryForMulColumnNode::handle_send_field_packet(Packet *packet) {
  MySQLColumnResponse col_resp(packet);
  col_resp.unpack();
  MySQLColumnType col_type = col_resp.get_column_type();
  col_types.push_back(col_type);
  col_nums++;
}

void MySQLQueryForMulColumnNode::handle_one_row(Packet *packet) {
  MySQLRowResponse row(packet);

  unsigned int i = 0;
  for (; i < col_nums; i++) {
    ResultType res = get_result_type_from_column_type(col_types[i]);
    string one_column;
    if (res == RESULT_TYPE_STRING) one_column.append("'");
    if (!row.field_is_null(i)) {
      uint64_t str_len = 0;
      const char *column_tmp = row.get_str(i, &str_len);
      CharsetType ctype = session->get_client_charset_type();
      append_column_value_to_replace_sql(one_column, column_tmp, str_len, res,
                                         ctype);
    } else
      one_column.append("NULL");
    if (res == RESULT_TYPE_STRING) one_column.append("'");
    res_node->row_columns.push_back(one_column);
  }
}

/* class MySQLQueryForOneColumnNode */
MySQLQueryForOneColumnNode::MySQLQueryForOneColumnNode(ExecutePlan *plan,
                                                       DataSpace *dataspace,
                                                       const char *sql,
                                                       bool only_one_row)
    : MySQLDirectExecuteNode(plan, dataspace, sql),
      has_get_one_row(false),
      col_type(MYSQL_TYPE_END),
      only_one_row(only_one_row) {
  this->name = "MySQLQueryForOneColumnNode";
#ifdef DEBUG
  ACE_ASSERT(plan->get_sub_query_result_node());
#endif
  res_node = plan->get_sub_query_result_node();
  if (replace_empty_result_null)
    res_node->replace_sql = string("NULL");
  else
    res_node->replace_sql = string("select 1 from dual where 1=0");
  row_num = 0;
  cross_join_max_rows = (uint64_t)(
      session->get_session_option("max_cross_join_moved_rows").ulong_val);
  is_direct_node = false;
}
void MySQLQueryForOneColumnNode::handle_send_client_packet(Packet *packet,
                                                           bool is_row_packet) {
  if (is_row_packet) {
    if (only_one_row && has_get_one_row) {
      throw dbscale::sql::SQLError(dbscale_err_msg[ERROR_ONE_ROW_CODE], "21000",
                                   ERROR_ONE_ROW_CODE);
    }
    if (!has_get_one_row) res_node->replace_sql.clear();
    handle_one_row(packet);
    has_get_one_row = true;
  }
}

void MySQLQueryForOneColumnNode::handle_send_field_packet(Packet *packet) {
  if (col_type == MYSQL_TYPE_END) {
    MySQLColumnResponse col_resp(packet);
    col_resp.unpack();
    col_type = col_resp.get_column_type();
  } else {
    throw dbscale::sql::SQLError(dbscale_err_msg[ERROR_ONE_COLUMN_CODE],
                                 "21000", ERROR_ONE_COLUMN_CODE);
  }
}

void MySQLQueryForOneColumnNode::handle_one_row(Packet *packet) {
  row_num++;
  if (row_num > cross_join_max_rows) {
    LOG_ERROR(
        "Reach the max rows of [%u] for cross node join max moved rows.\n",
        row_num);
    throw ExecuteNodeError(
        "Reach the max row number of cross node join max moved rows.");
  }

  MySQLRowResponse row(packet);

  ResultType res = get_result_type_from_column_type(col_type);
  string &replace_sql = res_node->replace_sql;

  if (has_get_one_row) replace_sql.append(",");

  if (res == RESULT_TYPE_STRING) replace_sql.append("'");

  if (!row.field_is_null(0)) {
    uint64_t str_len = 0;
    const char *column_tmp = row.get_str(0, &str_len);
    CharsetType ctype = session->get_client_charset_type();
    append_column_value_to_replace_sql(replace_sql, column_tmp, str_len, res,
                                       ctype);
  } else
    replace_sql.append("NULL");

  if (res == RESULT_TYPE_STRING) replace_sql.append("'");
}

/* class MySQLQueryForOneColumnAggrNode */
MySQLQueryForOneColumnAggrNode::MySQLQueryForOneColumnAggrNode(
    ExecutePlan *plan, DataSpace *dataspace, const char *sql, bool get_min)
    : MySQLDirectExecuteNode(plan, dataspace, sql),
      col_type(MYSQL_TYPE_END),
      has_get_one_row(false),
      get_min(get_min ? 1 : -1) {
  this->name = "MySQLQueryForOneColumnAggrNode";
#ifdef DEBUG
  ACE_ASSERT(plan->get_sub_query_result_node());
#endif
  res_node = plan->get_sub_query_result_node();
  res_node->replace_sql = string("select 1 from dual where 1=0");
  is_direct_node = false;
}

void MySQLQueryForOneColumnAggrNode::handle_send_client_packet(
    Packet *packet, bool is_row_packet) {
  if (is_row_packet) {
    if (!has_get_one_row) res_node->replace_sql.clear();
    handle_one_row(packet);
    has_get_one_row = true;
  }
}

void MySQLQueryForOneColumnAggrNode::handle_send_last_eof_packet(
    Packet *packet) {
  if (!has_get_one_row) return;
  ACE_UNUSED_ARG(packet);
  string &replace_sql = res_node->replace_sql;
  replace_sql.append("select ");

  ResultType res = get_result_type_from_column_type(col_type);

  if (res == RESULT_TYPE_STRING) replace_sql.append("'");

  MySQLRowResponse row(&aggr_packet);
  if (!row.field_is_null(0)) {
    uint64_t str_len = 0;
    const char *column_tmp = row.get_str(0, &str_len);
    CharsetType ctype = session->get_client_charset_type();
    append_column_value_to_replace_sql(replace_sql, column_tmp, str_len, res,
                                       ctype);
  } else
    replace_sql.append("NULL");

  if (res == RESULT_TYPE_STRING) replace_sql.append("'");
}

void MySQLQueryForOneColumnAggrNode::handle_send_field_packet(Packet *packet) {
  if (col_type == MYSQL_TYPE_END) {
    MySQLColumnResponse col_resp(packet);
    col_resp.unpack();
    col_type = col_resp.get_column_type();
  } else {
    throw dbscale::sql::SQLError(dbscale_err_msg[ERROR_ONE_COLUMN_CODE],
                                 "21000", ERROR_ONE_COLUMN_CODE);
  }
}

void MySQLQueryForOneColumnAggrNode::handle_one_row(Packet *row) {
  if (!has_get_one_row) {
    MySQLRowResponse row_p(row);
    uint64_t row_len = row->length();
    reset_packet_size(&aggr_packet, ro