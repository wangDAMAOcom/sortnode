w_len + 9);
    row_p.pack(&aggr_packet);
  } else {
    MySQLRowResponse row1(&aggr_packet);
    MySQLRowResponse row2(row);
    int ret = MySQLColumnCompare::compare(&row1, &row2, 0, col_type,
                                          CHARSET_TYPE_OTHER, true);
    if (ret * get_min == 1) {
      uint64_t row_len = row->length();
      reset_packet_size(&aggr_packet, row_len + 9);
      row2.pack(&aggr_packet);
    }
  }
}

/* class MySQLQueryExistsNode */
MySQLQueryExistsNode::MySQLQueryExistsNode(ExecutePlan *plan,
                                           DataSpace *dataspace,
                                           const char *sql)
    : MySQLDirectExecuteNode(plan, dataspace, sql), has_get_one_row(false) {
  this->name = "MySQLQueryExistsNode";
#ifdef DEBUG
  ACE_ASSERT(plan->get_sub_query_result_node());
#endif
  res_node = plan->get_sub_query_result_node();
  res_node->replace_sql = string("select 1 from dual where 1=0");
  is_direct_node = false;
}
void MySQLQueryExistsNode::handle_send_client_packet(Packet *packet,
                                                     bool is_row_packet) {
  ACE_UNUSED_ARG(packet);
  if (is_row_packet) {
    if (!has_get_one_row) {
      res_node->replace_sql = string("select 1 from dual where 1=1");
      has_get_one_row = true;
    }
  }
}

/* class MySQLSendToDBScaleNode */
MySQLSendToDBScaleNode::MySQLSendToDBScaleNode(ExecutePlan *plan)
    : MySQLSendNode(plan) {
  node_can_swap = false;
  this->name = "MySQLSendToDBScaleNode";
}

void MySQLSendToDBScaleNode::send_row(MySQLExecuteNode *ready_child) {
  ACE_UNUSED_ARG(ready_child);
  throw NotImplementedError();
}

/* class MySQLSendMulColumnToDBScaleNode*/
MySQLSendMulColumnToDBScaleNode::MySQLSendMulColumnToDBScaleNode(
    ExecutePlan *plan)
    : MySQLSendToDBScaleNode(plan) {
  this->name = "MySQLSendMulColumnToDBScaleNode";
  col_nums = 0;
  res_node = plan->get_sub_query_result_node();
  res_node->replace_sql = string("select 1 from dual where 1=0");
  has_get_one_row = false;
}

void MySQLSendMulColumnToDBScaleNode::send_row(MySQLExecuteNode *ready_child) {
  Packet *row;
  if (row_map[ready_child]->size() > 1 || row_num != 0)
    throw dbscale::sql::SQLError(dbscale_err_msg[ERROR_ONE_ROW_CODE], "21000",
                                 ERROR_ONE_ROW_CODE);
  if (!has_get_one_row && row_map[ready_child]->size() > 0) {
    res_node->replace_sql.clear();
    res_node->row_columns.clear();
    has_get_one_row = true;
  }
  while (!row_map[ready_child]->empty()) {
    row = row_map[ready_child]->front();
    handle_one_row(row);
    row_map[ready_child]->pop_front();
    delete row;
    row_num++;
  }
}

void MySQLSendMulColumnToDBScaleNode::send_header() {
  list<Packet *> *field_packets = get_field_packets();

  list<Packet *>::iterator it = field_packets->begin();
  for (; it != field_packets->end(); it++) {
    MySQLColumnResponse col_resp(*it);
    col_resp.unpack();
    MySQLColumnType col_type = col_resp.get_column_type();
    col_types.push_back(col_type);
  }
  col_nums = field_packets->size();
}

void MySQLSendMulColumnToDBScaleNode::handle_one_row(Packet *packet) {
  MySQLRowResponse row(packet);

  unsigned int i = 0;
  for (; i < col_nums; i++) {
    ResultType res = get_result_type_from_column_type(col_types[i]);
    string one_column;
    if (res == RESULT_TYPE_STRING) one_column.append("'");
    if (!row.field_is_null(i)) {
      uint64_t str_len = 0;
      const char *column_tmp = row.get_str(i, &str_len);
      CharsetType ctype = session->get_client_charset_type();
      append_column_value_to_replace_sql(one_column, column_tmp, str_len, res,
                                         ctype);
    } else
      one_column.append("NULL");
    if (res == RESULT_TYPE_STRING) one_column.append("'");
    res_node->row_columns.push_back(one_column);
  }
}

/* MySQLSendOneColumnToDBScaleNode */
MySQLSendOneColumnToDBScaleNode::MySQLSendOneColumnToDBScaleNode(
    ExecutePlan *plan, bool only_one_row)
    : MySQLSendToDBScaleNode(plan),
      col_type(MYSQL_TYPE_END),
      only_one_row(only_one_row),
      has_get_one_row(false) {
  this->name = "MySQLSendOneColumnToDBScaleNode";
#ifdef DEBUG
  ACE_ASSERT(plan->get_sub_query_result_node());
#endif
  res_node = plan->get_sub_query_result_node();
  if (replace_empty_result_null)
    res_node->replace_sql = string("NULL");
  else
    res_node->replace_sql = string("select 1 from dual where 1=0");
}

void MySQLSendOneColumnToDBScaleNode::send_header() {
  list<Packet *> *field_packets = get_field_packets();
  if (field_packets->size() != 1) {
    throw dbscale::sql::SQLError(dbscale_err_msg[ERROR_ONE_COLUMN_CODE],
                                 "21000", ERROR_ONE_COLUMN_CODE);
  }
  MySQLColumnResponse col_resp(field_packets->front());
  col_resp.unpack();
  col_type = col_resp.get_column_type();
}

void MySQLSendOneColumnToDBScaleNode::send_row(MySQLExecuteNode *ready_child) {
  Packet *row;
  if (only_one_row && (row_map[ready_child]->size() > 1 || row_num != 0))
    throw dbscale::sql::SQLError(dbscale_err_msg[ERROR_ONE_ROW_CODE], "21000",
                                 ERROR_ONE_ROW_CODE);
  if (!has_get_one_row && row_map[ready_child]->size() > 0) {
    res_node->replace_sql.clear();
    has_get_one_row = true;
  }
  while (!row_map[ready_child]->empty()) {
    row = row_map[ready_child]->front();
    handle_one_row(row);
    row_map[ready_child]->pop_front();
    delete row;
    row_num++;
  }
}

void MySQLSendOneColumnToDBScaleNode::handle_one_row(Packet *packet) {
  MySQLRowResponse row(packet);

  ResultType res = get_result_type_from_column_type(col_type);
  string &replace_sql = res_node->replace_sql;

  if (row_num) replace_sql.append(",");

  if (res == RESULT_TYPE_STRING) replace_sql.append("'");

  if (!row.field_is_null(0)) {
    uint64_t str_len = 0;
    const char *column_tmp = row.get_str(0, &str_len);
    CharsetType ctype = session->get_client_charset_type();
    append_column_value_to_replace_sql(replace_sql, column_tmp, str_len, res,
                                       ctype);
  } else
    replace_sql.append("NULL");

  if (res == RESULT_TYPE_STRING) replace_sql.append("'");
}

/* class MySQLSendOneColumnAggrToDBScaleNode */
MySQLSendOneColumnAggrToDBScaleNode::MySQLSendOneColumnAggrToDBScaleNode(
    ExecutePlan *plan, bool get_min)
    : MySQLSendToDBScaleNode(plan),
      col_type(MYSQL_TYPE_END),
      get_min(get_min ? 1 : -1),
      has_get_one_row(false) {
  this->name = "MySQLSendOneColumnAggrToDBScaleNode";
#ifdef DEBUG
  ACE_ASSERT(plan->get_sub_query_result_node());
#endif
  res_node = plan->get_sub_query_result_node();
  res_node->replace_sql = string("select 1 from dual where 1=0");
}

void MySQLSendOneColumnAggrToDBScaleNode::send_eof() {
  if (!has_get_one_row) return;
  string &replace_sql = res_node->replace_sql;
  replace_sql.append("select ");

  ResultType res = get_result_type_from_column_type(col_type);

  if (res == RESULT_TYPE_STRING) replace_sql.append("'");

  MySQLRowResponse row(&aggr_packet);
  if (!row.field_is_null(0)) {
    uint64_t str_len = 0;
    const char *column_tmp = row.get_str(0, &str_len);
    CharsetType ctype = session->get_client_charset_type();
    append_column_value_to_replace_sql(replace_sql, column_tmp, str_len, res,
                                       ctype);
  } else
    replace_sql.append("NULL");

  if (res == RESULT_TYPE_STRING) replace_sql.append("'");
}

void MySQLSendOneColumnAggrToDBScaleNode::send_header() {
  list<Packet *> *field_packets = get_field_packets();
  if (field_packets->size() != 1) {
    throw dbscale::sql::SQLError(dbscale_err_msg[ERROR_ONE_COLUMN_CODE],
                                 "21000", ERROR_ONE_COLUMN_CODE);
  }
  MySQLColumnResponse col_resp(field_packets->front());
  col_resp.unpack();
  col_type = col_resp.get_column_type();
}

void MySQLSendOneColumnAggrToDBScaleNode::send_row(
    MySQLExecuteNode *ready_child) {
  if (!has_get_one_row && row_map[ready_child]->size() > 0) {
    res_node->replace_sql.clear();
    has_get_one_row = true;
  }
  Packet *row;
  if (!row_map[ready_child]->empty()) {
    row = row_map[ready_child]->front();
    handle_one_row(row);
    row_map[ready_child]->pop_front();
    delete row;
    row_num++;
  }
}

void MySQLSendOneColumnAggrToDBScaleNode::handle_one_row(Packet *row) {
  if (!row_num) {
    MySQLRowResponse row_p(row);
    uint64_t row_len = row->length();
    reset_packet_size(&aggr_packet, row_len + 9);
    row_p.pack(&aggr_packet);
  } else {
    MySQLRowResponse row1(&aggr_packet);
    MySQLRowResponse row2(row);
    int ret = MySQLColumnCompare::compare(&row1, &row2, 0, col_type,
                                          CHARSET_TYPE_OTHER, true);
    if (ret * get_min == 1) {
      uint64_t row_len = row->length();
      reset_packet_size(&aggr_packet, row_len + 9);
      row2.pack(&aggr_packet);
    }
  }
}

/* MySQLSendExistsToDBScaleNode */
MySQLSendExistsToDBScaleNode::MySQLSendExistsToDBScaleNode(ExecutePlan *plan)
    : MySQLSendToDBScaleNode(plan) {
  this->name = "MySQLSendExistsToDBScaleNode";
#ifdef DEBUG
  ACE_ASSERT(plan->get_sub_query_result_node());
#endif
  res_node = plan->get_sub_query_result_node();
  res_node->replace_sql = string("select 1 from dual where 1=0");
  set_res_node = false;
}

void MySQLSendExistsToDBScaleNode::send_row(MySQLExecuteNode *ready_child) {
  Packet *row;
  while (!row_map[ready_child]->empty()) {
    row = row_map[ready_child]->front();
    if (!set_res_node) {
      res_node->replace_sql = string("select 1 from dual where 1=1");
      set_res_node = true;
    }
    row_map[ready_child]->pop_front();
    delete row;
    row_num++;
  }
}

/* class MySQLIntoOutfileNode */
MySQLIntoOutfileNode::MySQLIntoOutfileNode(ExecutePlan *plan)
    : MySQLSendNode(plan) {
  this->name = "MySQLIntoOutfileNode";
  affect_rows = 0;
  into_outfile_item *into_outfile = plan->statement->get_into_outfile();
  is_local = into_outfile->is_local;
  filename = into_outfile->filename;

  node_can_swap = false;
  row_buffer = new char[DEFAULT_BUFFER_SIZE];
}

void MySQLIntoOutfileNode::prepare_fifo_or_load() {
  if (plan->statement->insert_select_via_fifo()) {
    LOG_DEBUG("external INSERT SELECT via fifo start to open fifo\n");
    open_fifo(plan);
    LOG_DEBUG("external INSERT SELECT via fifo end to open fifo\n");
  } else if (plan->statement->is_load_insert_select()) {
    load_insert_select();
  } else {
    param.set_got_error(false);
    param.set_external_load_flag(UNDEFINE);
    pipe_fd = 0;
    if (!is_local) {
      file.open(filename);
    }
  }
}

MySQLIntoOutfileNode::~MySQLIntoOutfileNode() { delete[] row_buffer; }

void *monitor_worker_via_fifo(void *arg) {
  spawn_param *param = (spawn_param *)arg;
  if (param->fd) {
    ExternalLoadResultHandler exp_handler;
    try {
      exp_handler.handler_expect_result(param->fd, param);
      const char *inserted_rows = exp_handler.get_inserted_rows();
      param->insert_rows = atoll(inserted_rows);
    } catch (...) {
      param->set_got_error(true);
    }
    if (param->fd) {
      pclose(param->fd);
    }
  }
  return NULL;
}

void *load_insert_select_exec(void *arg) {
  MySQLIntoOutfileNode *node = (MySQLIntoOutfileNode *)arg;
  char fields_term =
      node->plan->session->get_session_option("load_insert_select_fields_term")
          .char_val[0];
  char lines_term =
      node->plan->session->get_session_option("load_insert_select_lines_term")
          .char_val[0];
  string load_sql("LOAD DATA INFILE '");
  load_sql.append(node->get_filename());
  load_sql.append("' INTO TABLE ");
  load_sql.append(node->plan->statement->get_insert_select_modify_schema());
  load_sql.append(".");
  load_sql.append(node->plan->statement->get_insert_select_modify_table());
  load_sql.append(" FIELDS TERMINATED BY '");
  load_sql.append(1, fields_term);
  load_sql.append("' ENCLOSED BY '\"' LINES TERMINATED BY '");
  load_sql.append(1, lines_term);
  load_sql.append("'");

  LOG_DEBUG("LOAD DATA for INSERT SELECT sql [%s]\n", load_sql.c_str());

  Statement *new_stmt = NULL;
  ExecutePlan *new_plan = NULL;
  try {
    Parser *parser = MySQLParser::instance();
    new_stmt = parser->parse(
        load_sql.c_str(),
        allow_dot_in_ident);  // use global value of allow_dot_in_ident
    new_stmt->set_default_schema(node->plan->statement->get_schema());
    new_stmt->set_load_insert_select(true);
    new_plan = (ExecutePlan *)node->handler->get_execute_plan(new_stmt);
    new_stmt->generate_execution_plan(new_plan);
    new_plan->execute();
  } catch (...) {
    LOG_ERROR("Load insert select error in load execution.\n");
    node->set_got_error();
  }
  if (new_stmt) {
    new_stmt->free_resource();
    delete new_stmt;
    new_stmt = NULL;
  }
  if (new_plan) {
    delete new_plan;
    new_plan = NULL;
  }
  return NULL;
}

void MySQLIntoOutfileNode::load_insert_select() {
  param.set_got_error(false);
  param.set_external_load_flag(UNDEFINE);
  pipe_fd = 0;
  int ret =
      ACE_Thread::spawn((ACE_THR_FUNC)load_insert_select_exec, this,
                        THR_JOINABLE | THR_SCHED_DEFAULT, &l_id, &l_handle);
  if (ret == -1) {
    LOG_ERROR("Error when execute load.\n");
    throw HandlerError("Error when execute load.");
  }
  file.open(filename);
}

void MySQLIntoOutfileNode::open_fifo(ExecutePlan *plan) {
  string insert_select_via_fifo_cmd;
  string script = plan->statement->get_local_load_script();
  if (script[0] != '/') {
    insert_select_via_fifo_cmd.append("./");
  }
  insert_select_via_fifo_cmd.append(script);
  insert_select_via_fifo_cmd.append(" ");
  insert_select_via_fifo_cmd.append(
      plan->statement->get_insert_select_modify_schema());
  insert_select_via_fifo_cmd.append(" ");
  insert_select_via_fifo_cmd.append(
      plan->statement->get_insert_select_modify_table());
  insert_select_via_fifo_cmd.append(" , \\\" ");
  insert_select_via_fifo_cmd.append(filename);
  LOG_DEBUG("full command [%s].\n", insert_select_via_fifo_cmd.c_str());
  fd = popen(insert_select_via_fifo_cmd.c_str(), "r");
  if (fd == NULL) {
    fprintf(stderr, "execute command failed");
    LOG_ERROR("Fail to execute command %s.\n",
              insert_select_via_fifo_cmd.c_str());
    throw HandlerError("Fail to execute command.");
  }

  param.set_got_error(false);
  param.insert_rows = 0;
  param.fd = fd;
  param.set_external_load_flag(UNDEFINE);
  int ret =
      ACE_Thread::spawn((ACE_THR_FUNC)monitor_worker_via_fifo, &param,
                        THR_JOINABLE | THR_SCHED_DEFAULT, &t_id, &t_handle);
  if (ret == -1) {
    LOG_ERROR("Error when execute command %s.\n",
              insert_select_via_fifo_cmd.c_str());
    throw HandlerError("Error when execute command.");
  }
  file.open(filename);
  while (param.get_external_load_flag() == UNDEFINE) {
    LOG_DEBUG("Waiting for external load script report load file status.\n");
    ACE_OS::sleep(1);
  }
  if (param.get_external_load_flag() == FILE_NOT_OPEN) {
    file.close();
    ACE_Thread::join(t_handle);
    throw ExecuteNodeError(
        "Failed to execute statement, fail to open file, check log for more "
        "information.");
  }
}

void MySQLIntoOutfileNode::send_header() {
  string catalog_name;
  string schema_name;
  string table_name;
  uint32_t column_len = 0;
  list<Packet *> *field_packets = get_field_packets();
  for (std::list<Packet *>::iterator it = field_packets->begin();
       it != field_packets->end(); it++) {
    MySQLColumnResponse column_response(*it);
    column_response.unpack();
    is_column_number.push_back(column_response.is_number());
    column_len += column_response.get_column_length();
    if (it == field_packets->begin()) {
      catalog_name = column_response.get_catalog();
      schema_name = column_response.get_schema();
      table_name = column_response.get_table();
    }
  }
  // rebuild a column, and send to client
  if (is_local) {
    Packet res_header_packet;
    MySQLResultSetHeaderResponse result_set_header(1, 0);
    result_set_header.pack(&res_header_packet);
    handler->send_mysql_packet_to_client_by_buffer(&res_header_packet);
    MySQLColumnResponse my_col(catalog_name.c_str(), schema_name.c_str(),
                               table_name.c_str(), table_name.c_str(),
                               "into-outfile-col", "into-outfile-col", 8,
                               column_len + 1, MYSQL_TYPE_VAR_STRING, 0, 0, 0);
    Packet col_packet;
    my_col.pack(&col_packet);
    handler->send_mysql_packet_to_client_by_buffer(&col_packet);
    Packet *eof_packet = get_eof_packet();
    handler->deal_autocommit_with_ok_eof_packet(eof_packet);
    handler->send_mysql_packet_to_client_by_buffer(eof_packet);
    handler->flush_net_buffer();
  }
}

void MySQLIntoOutfileNode::send_row(MySQLExecuteNode *ready_child) {
  into_outfile_item *into_outfile = plan->statement->get_into_outfile();
  check_lines_term_null(into_outfile);
  Packet *row;
  while (!row_map[ready_child]->empty()) {
    row = row_map[ready_child]->front();
    write_into_outfile(row, into_outfile, file, &param);
    affect_rows++;
    if (is_local) {
      handler->send_to_client(row);
    } else if (param.has_got_error() ||
               param.get_external_load_flag() == FINISH) {
      status = EXECUTE_STATUS_COMPLETE;
      file.close();
      if (plan->statement->insert_select_via_fifo()) {
        ACE_Thread::join(t_handle);
      }
      throw ExecuteNodeError(
          "Got error when execute statement, check log for more information.");
    }

    row_map[ready_child]->pop_front();
    delete row;
  }
}

void MySQLIntoOutfileNode::execute() {
  while (status != EXECUTE_STATUS_COMPLETE) {
    switch (status) {
      case EXECUTE_STATUS_START:
        prepare_fifo_or_load();
        init_row_map();
        status = EXECUTE_STATUS_FETCH_DATA;
        break;

      case EXECUTE_STATUS_FETCH_DATA:
        children_execute();
        status = EXECUTE_STATUS_WAIT;

      case EXECUTE_STATUS_WAIT:
        try {
          wait_children();
        } catch (ExecuteNodeError &e) {
          status = EXECUTE_STATUS_COMPLETE;
          throw e;
        }
        break;

      case EXECUTE_STATUS_HANDLE:
#ifdef DEBUG
        node_start_timing();
#endif
        handle_children();
#ifdef DEBUG
        node_end_timing();
#endif
        status = EXECUTE_STATUS_FETCH_DATA;
        break;

      case EXECUTE_STATUS_BEFORE_COMPLETE:
        if (send_header_flag) {
          send_header();
          send_header_flag = false;
        }
        status = EXECUTE_STATUS_COMPLETE;

      case EXECUTE_STATUS_COMPLETE: {
        if (!is_local) {
          file.close();
        }
        if (plan->statement->insert_select_via_fifo()) {
          LOG_DEBUG(
              "external INSERT SELECT via fifo start wait monitor thread\n");
          ACE_Thread::join(t_handle);
          LOG_DEBUG(
              "external INSERT SELECT via fifo end wait monitor thread\n");

          if (param.has_got_error()) {
            LOG_ERROR(
                "Got error when execute INSERT SELECT statement, %Q rows "
                "inserted.\n",
                param.insert_rows);
            throw ExecuteNodeError(
                "Got error when execute INSERT SELECT statement, "
                "please check log for more information.");
          } else {
            if (!session->is_call_store_procedure())
              send_ok_packet_to_client(handler, param.insert_rows, 0);
#ifdef DEBUG
            LOG_DEBUG(
                "MySQLIntoOutfileNode %@ for external INSERT SELECT cost %d "
                "ms\n",
                this, node_cost_time);
#endif
          }
        } else if (plan->statement->is_load_insert_select()) {
          LOG_DEBUG("Wait for load thread.\n");
          ACE_Thread::join(l_handle);
          LOG_DEBUG("End wait for load thread.\n");
          Packet *result_packet = session->get_result_packet();
          if (param.has_got_error() || !result_packet) {
            LOG_ERROR("Got error when execute INSERT SELECT statement.\n",
                      param.insert_rows);
            throw ExecuteNodeError(
                "Got error when execute INSERT SELECT statement, "
                "please check log for more information.");
          }
          handler->send_to_client(result_packet);
          delete result_packet;
          session->set_result_packet(NULL);
        } else if (!is_local) {
          if (!session->is_call_store_procedure())
            send_ok_packet_to_client(handler, affect_rows, 0);
#ifdef DEBUG
          LOG_DEBUG("MySQLIntoOutfileNode %@ cost %d ms\n", this,
                    node_cost_time);
#endif
        } else {
          send_eof();
          flush_net_buffer();
        }
        break;
      }
      default:
        break;
    }
  }
}

/* class MySQLSelectIntoNode */
MySQLSelectIntoNode::MySQLSelectIntoNode(ExecutePlan *plan)
    : MySQLSendNode(plan) {
  this->name = "MySQLSelectIntoNode";
  affect_rows = 0;
  select_into_item *select_into = plan->statement->get_select_into();
  generate_select_into_vec(select_into);
  node_can_swap = false;
}

void MySQLSelectIntoNode::generate_select_into_vec(
    select_into_item *select_into) {
  name_item *into_list = select_into->into_list;
  name_item *head = into_list;
  do {
    bool is_uservar = into_list->is_uservar;
    string name = into_list->name;
    if (is_uservar) {
      boost::to_upper(name);
    }
    pair<bool, string> is_uservar_pair(is_uservar, name);
    select_into_vec.push_back(is_uservar_pair);
    into_list = into_list->next;
  } while (into_list != head);
}

void MySQLSelectIntoNode::write_into_name_list(Packet *row) {
  Session *session = plan->session;
  MySQLRowResponse row_response(row);
  unsigned int fields_num = field_is_number_vec.size();

  for (unsigned int i = 0; i != fields_num; i++) {
    if (!select_into_vec[i].first) {
      continue;
    }

    string uservar_name = select_into_vec[i].second;
    if (row_response.field_is_null(i)) {
      write_result_to_uservar(session, uservar_name, NULL);
      continue;
    }

    uint64_t length;
    const char *str = row_response.get_str(i, &length);
    write_result_to_uservar(session, uservar_name, str, length,
                            field_is_number_vec[i]);
  }
}

void MySQLSelectIntoNode::send_header() {
  list<Packet *> *field_packets = get_field_packets();
  for (std::list<Packet *>::iterator it = field_packets->begin();
       it != field_packets->end(); it++) {
    MySQLColumnResponse column_response(*it);
    column_response.unpack();
    field_is_number_vec.push_back(column_response.is_number());
  }
}

void MySQLSelectIntoNode::send_row(MySQLExecuteNode *ready_child) {
  Packet *row;
  while (!row_map[ready_child]->empty()) {
    row = row_map[ready_child]->front();
    affect_rows++;
    row_map[ready_child]->pop_front();
    try {
      if (affect_rows > 1) {
        throw dbscale::sql::SQLError(
            dbscale_err_msg[ERROR_SELECT_INTO_ONE_ROW_CODE], "42000",
            ERROR_SELECT_INTO_ONE_ROW_CODE);
      } else if (field_is_number_vec.size() != select_into_vec.size()) {
        throw dbscale::sql::SQLError(
            dbscale_err_msg[ERROR_SELECT_INTO_DIFF_COLUMNS_CODE], "21000",
            ERROR_SELECT_INTO_DIFF_COLUMNS_CODE);
      } else {
        write_into_name_list(row);
      }
      if (statement->get_select_uservar_flag()) {
        set_select_uservar_by_result(
            row, field_is_number_vec,
            *(plan->statement->get_select_uservar_vec()),
            plan->statement->get_select_field_num(), plan->session);
      }
      delete row;
      row = NULL;
    } catch (dbscale::sql::SQLError &e) {
      delete row;
      row = NULL;
      throw e;
    }
  }
}

void MySQLSelectIntoNode::execute() {
  while (status != EXECUTE_STATUS_COMPLETE) {
    switch (status) {
      case EXECUTE_STATUS_START:
        init_row_map();
        status = EXECUTE_STATUS_FETCH_DATA;
        break;

      case EXECUTE_STATUS_FETCH_DATA:
        children_execute();
        status = EXECUTE_STATUS_WAIT;

      case EXECUTE_STATUS_WAIT:
        try {
          wait_children();
        } catch (ExecuteNodeError &e) {
          status = EXECUTE_STATUS_COMPLETE;
          throw e;
        }
        break;

      case EXECUTE_STATUS_HANDLE:
#ifdef DEBUG
        node_start_timing();
#endif
        try {
          handle_children();
        } catch (...) {
          status = EXECUTE_STATUS_COMPLETE;
          throw;
        }
#ifdef DEBUG
        node_end_timing();
#endif
        status = EXECUTE_STATUS_FETCH_DATA;
        break;

      case EXECUTE_STATUS_BEFORE_COMPLETE:
        if (send_header_flag) {
          send_header();
          send_header_flag = false;
        }
        status = EXECUTE_STATUS_COMPLETE;

      case EXECUTE_STATUS_COMPLETE:
        if (!session->is_call_store_procedure())
          send_ok_packet_to_client(handler, affect_rows, 0);
#ifdef DEBUG
        LOG_DEBUG("MySQLIntoOutfileNode %@ cost %d ms\n", this, node_cost_time);
#endif
        break;

      default:
        break;
    }
  }
}

void MySQLIntoOutfileNode::clean() {
  MySQLSendNode::clean();
  if (plan->statement->insert_select_via_fifo() ||
      plan->statement->is_load_insert_select()) {
    for (int i = 0; i < 3; i++) {  // delete fifo, try 3 times.
      if (!remove(filename)) {     // return 0, delete fifo successful.
        break;
      }
      if (i == 2) {  // try 3 times but failed.
        LOG_ERROR("Error deleting fifo file.\n");
      }
    }
  }
}

/* class MySQLSortNode */

MySQLSortNode::MySQLSortNode(ExecutePlan *plan, list<SortDesc> *sort_desc_para)
    : MySQLInnerNode(plan) {
  need_restrict_row_map_size = true;
  if (sort_desc_para) {
    list<SortDesc>::iterator it = sort_desc_para->begin();
    for (; it != sort_desc_para->end(); it++) sort_desc.push_back(*it);
  }
  this->name = "MySQLSortNode";
  column_inited_flag = false;
  status = EXECUTE_STATUS_START;
  adjust_column_flag = false;
  check_column_type = false;
  sort_node_size = 0;
  sort_ready_nodes = ready_rows;
  node_can_swap = session->is_may_backend_exec_swap_able();
  can_swap_ready_rows = false;

#ifndef DBSCALE_TEST_DISABLE
  dbscale_test_info *test_info = plan->session->get_dbscale_test_info();
  if (!strcasecmp(test_info->test_case_name.c_str(), "fetchnode") &&
      !strcasecmp(test_info->test_case_operation.c_str(),
                  "max_fetchnode_ready_rows_size")) {
    LOG_DEBUG(
        "Do dbscale test operation 'max_fetch_node_ready_rows_size' for case "
        "'fetchnode'\n");
    need_record_loop_count = true;
  }
#endif
}

/* Here we use Binary Inserting Sort*/
void MySQLSortNode::insert_row(MySQLExecuteNode *child) {
  Packet *packet = row_map[child]->front();

  int low = 0, high = sort_node_size - 1;
  int m = 0;
  while (low <= high) {
    m = (low + high) / 2;
    if (MySQLColumnCompare::compare(merge_sort_vec[m], packet, &sort_desc,
                                    &column_types) < 0) {
      low = m + 1;
    } else {
      high = m - 1;
    }
  }

  for (int j = sort_node_size; j > low; j--) {
    merge_sort_vec[j] = merge_sort_vec[j - 1];
    sort_pos[j] = sort_pos[j - 1];
  }

  merge_sort_vec[low] = packet;
  sort_pos[low] = child;
  sort_node_size++;
}

void MySQLSortNode::pop_row() {
  MySQLExecuteNode *node = sort_pos[sort_node_size - 1];
  Packet *packet = merge_sort_vec[sort_node_size - 1];
  sort_ready_nodes->push_back(packet);
  ready_rows_buffer_size += packet->total_capacity();
  ACE_ASSERT(packet != NULL);
#ifdef DEBUG
  LOG_DEBUG("packet = %@ in pop_row\n", packet);
#endif
  buffer_row_map_size[node] -= row_map[node]->front()->total_capacity();
  row_map[node]->pop_front();
  row_map_size[node]--;
  sort_node_size--;
}

unsigned int MySQLSortNode::get_last_rows() {
  unsigned int rows = 0;
  list<MySQLExecuteNode *>::iterator it_child;
  for (it_child = children.begin(); it_child != children.end(); ++it_child) {
    rows += row_map[*it_child]->size();
  }

  return rows;
}

void MySQLSortNode::add_last_one_list() {
  MySQLExecuteNode *node = NULL;
  list<Packet *, StaticAllocator<Packet *> > *row_list = NULL;
  Packet *packet = NULL;
  node = sort_pos[0];
  row_list = row_map[node];
  while (!row_list->empty()) {
    packet = row_list->front();
    sort_ready_nodes->push_back(packet);
    ready_rows_buffer_size += packet->total_capacity();
    buffer_row_map_size[node] -= packet->total_capacity();
    row_list->pop_front();
    row_map_size[node]--;
  }
}

void MySQLSortNode::sort() {
  sort_node_size = 0;
  list<MySQLExecuteNode *>::iterator it_child;
  for (it_child = children.begin(); it_child != children.end(); ++it_child) {
    if (!row_map[*it_child]->empty()) {
      insert_row(*it_child);
    }
  }
  pop_row();

  map<MySQLExecuteNode *, list<Packet *>::iterator>::iterator it;
  while (true) {
    if (!row_map[sort_pos[sort_node_size]]->empty()) {
      insert_row(sort_pos[sort_node_size]);
      pop_row();
    } else {
      return;
    }
  }
}

void MySQLSortNode::last_sort() {
  if (get_last_rows() == 0) {
    return;
  }

  sort_node_size = 0;
  list<MySQLExecuteNode *>::iterator it_child;
  for (it_child = children.begin(); it_child != children.end(); ++it_child) {
    if (!row_map[*it_child]->empty()) {
      insert_row(*it_child);
    }
  }
  pop_row();

  if (sort_node_size == 0) {
    add_last_one_list();
    return;
  }

  map<MySQLExecuteNode *, list<Packet *>::iterator>::iterator it;
  while (true) {
    if (sort_node_size == 1 && row_map[sort_pos[sort_node_size]]->empty()) {
      add_last_one_list();
      return;
    } else if (!row_map[sort_pos[sort_node_size]]->empty()) {
      insert_row(sort_pos[sort_node_size]);
      pop_row();
    } else {
      pop_row();
    }
  }
}

void MySQLSortNode::init_merge_sort_variables() {
  list<MySQLExecuteNode *>::iterator it;
  for (it = children.begin(); it != children.end(); ++it) {
    merge_sort_vec.push_back(NULL);
    sort_pos.push_back(NULL);
  }
}

void MySQLSortNode::execute() {
  while (status != EXECUTE_STATUS_COMPLETE) {
    switch (status) {
      case EXECUTE_STATUS_START:
        init_row_map();
        init_merge_sort_variables();
        status = EXECUTE_STATUS_FETCH_DATA;
        break;

      case EXECUTE_STATUS_FETCH_DATA:
        children_execute();
        if (node_can_swap && plan->plan_can_swap()) {
          handle_swap_connections();
          return;
        }
        status = EXECUTE_STATUS_WAIT;

      case EXECUTE_STATUS_WAIT:
        try {
          wait_children();
        } catch (ExecuteNodeError &e) {
          status = EXECUTE_STATUS_COMPLETE;
          throw e;
        }
        break;

      case EXECUTE_STATUS_HANDLE: {
#ifdef DEBUG
        node_start_timing();
#endif
        init_column_types(get_field_packets(), column_types, column_num,
                          &column_inited_flag);
        adjust_column_index();
        check_column_valid();
        sort();
#ifdef DEBUG
        node_end_timing();
#endif
        status = EXECUTE_STATUS_FETCH_DATA;

        LOG_DEBUG("sortnode sorted ready buffer size is %Q,count is %u.\n",
                  ready_rows_buffer_size, sort_ready_nodes->size());
        unsigned long size_of_packets =
            sort_ready_nodes->size() * (sizeof(Packet));
        unsigned long size_of_ace_data_blocks =
            sort_ready_nodes->size() * (sizeof(ACE_Data_Block));
        unsigned long size_of_packet_pointers =
            sort_ready_nodes->size() * (sizeof(Packet *));
        unsigned long total_list_use_mem =
            (size_of_packets + size_of_ace_data_blocks +
             size_of_packet_pointers) /
            1024;
        unsigned long left_max_sorted_rows_buffer = 0;
        if (sort_rows_size > total_list_use_mem) {
          left_max_sorted_rows_buffer = sort_rows_size - total_list_use_mem;
        }

        if ((ready_rows_buffer_size / 1024) < left_max_sorted_rows_buffer) {
          LOG_DEBUG(
              "ready_rows_buffer_size is %Q ,left_max_sorted_rows_buffer is "
              "%Q.\n",
              ready_rows_buffer_size, left_max_sorted_rows_buffer);
          break;
        } else
          return;
      }
      case EXECUTE_STATUS_BEFORE_COMPLETE:
#ifdef DEBUG
        node_start_timing();
#endif
        last_sort();
#ifdef DEBUG
        node_end_timing();
#endif
        status = EXECUTE_STATUS_COMPLETE;
        break;

      case EXECUTE_STATUS_COMPLETE:
#ifdef DEBUG
        LOG_DEBUG("MySQLSortNode %@ cost %d ms\n", this, node_cost_time);
#endif
        break;

      default:
        ACE_ASSERT(0);
        break;
    }
  }
}

void MySQLSortNode::adjust_column_index() {
  if (!adjust_column_flag) {
    list<SortDesc>::iterator it;
    for (it = sort_desc.begin(); it != sort_desc.end(); it++) {
      if (it->column_index < 0) {
        it->column_index += column_num;
      }
    }
    adjust_column_flag = true;
  }
}

void MySQLSortNode::check_column_valid() {
  if (!check_column_type) {
    list<SortDesc>::iterator it;
    for (it = sort_desc.begin(); it != sort_desc.end(); it++) {
      if (!field_is_valid_for_compare(column_types[it->column_index])) {
        LOG_ERROR("Unsupport column type %d for compare.\n",
                  column_types[it->column_index]);
        throw ExecuteNodeError(
            "Unsupport column type for compare,\
                               please check the log for detail.");
      }
    }
    check_column_type = true;
  }
}

/* class MySQLProjectNode */

MySQLProjectNode::MySQLProjectNode(ExecutePlan *plan, unsigned skip_columns)
    : MySQLInnerNode(plan) {
  this->skip_columns = skip_columns;
  this->name = "MySQLProjectNode";
  field_packets_inited = false;
  header_packet_inited = false;
  columns_num = 0;
  node_can_swap = session->is_may_backend_exec_swap_able();
}

void MySQLProjectNode::init_header_packet() {
  first_child = children.front();
  MySQLResultSetHeaderResponse header(first_child->get_header_packet());
  header.unpack();
  uint64_t columns = header.get_columns();
  columns_num = columns - skip_columns;
  header.set_columns(columns_num);
  header.pack(&header_packet);
  header_packet_inited = true;
}

void MySQLProjectNode::init_field_packet() {
  unsigned int i = 0;
  field_packets.clear();
  first_child = children.front();
  list<Packet *> *field_list = first_child->get_field_packets();
  list<Packet *>::iterator it = field_list->begin();

  columns_num = field_list->size() - skip_columns;
  while (i++ < columns_num) {
    field_packets.push_back(*it);
    it++;
  }
  field_packets_inited = true;
}

void MySQLProjectNode::handle_child(MySQLExecuteNode *child) {
  Packet *row_packet;
  Packet *new_row;
  while (!row_map[child]->empty()) {
    row_packet = row_map[child]->front();
    row_map[child]->pop_front();

    MySQLRowResponse row(row_packet);
    row.set_current(columns_num - 1);
    row.move_next();
    char *start_pos = row.get_row_data();
    char *end_pos = row.get_current_data();
    uint64_t row_length = end_pos - start_pos;
    row.set_row_data(start_pos);
    row.set_row_length(row_length);
    new_row = Backend::instance()->get_new_packet(row_packet_size);
    row.pack(new_row);
    ready_rows->push_back(new_row);
    delete row_packet;
  }
}

void MySQLProjectNode::handle_children() {
  LOG_DEBUG("Node %@ start handle children.\n", this);
  init_columns_num();
  list<MySQLExecuteNode *>::iterator it;
  for (it = children.begin(); it != children.end(); ++it) {
    if (!row_map[*it]->empty()) handle_child(*it);
  }
  LOG_DEBUG("Node %@ handle children complete.\n", this);
}

void MySQLProjectNode::execute() {
  while (status != EXECUTE_STATUS_COMPLETE) {
    switch (status) {
      case EXECUTE_STATUS_START:
        init_row_map();
        status = EXECUTE_STATUS_FETCH_DATA;
        break;

      case EXECUTE_STATUS_FETCH_DATA:
        children_execute();
        if (node_can_swap && plan->plan_can_swap()) {
          handle_swap_connections();
          return;
        }
        status = EXECUTE_STATUS_WAIT;

      case EXECUTE_STATUS_WAIT:
        try {
          wait_children();
        } catch (ExecuteNodeError &e) {
          status = EXECUTE_STATUS_COMPLETE;
          throw e;
        }
        break;

      case EXECUTE_STATUS_HANDLE:
#ifdef DEBUG
        node_start_timing();
#endif
        handle_children();
#ifdef DEBUG
        node_end_timing();
#endif
        status = EXECUTE_STATUS_FETCH_DATA;
        return;
        break;

      case EXECUTE_STATUS_BEFORE_COMPLETE:
        status = EXECUTE_STATUS_COMPLETE;
      case EXECUTE_STATUS_COMPLETE:
#ifdef DEBUG
        LOG_DEBUG("MySQLProjectNode %@ cost %d ms\n", this, node_cost_time);
#endif
        break;

      default:
        ACE_ASSERT(0);
        break;
    }
  }
}

/* class MySQLLimitNode */

MySQLLimitNode::MySQLLimitNode(ExecutePlan *plan, long offset, long num)
    : MySQLInnerNode(plan), offset(offset), num(num), row_count(0) {
  this->name = "MySQLLimitNode";
  node_can_swap = session->is_may_backend_exec_swap_able();
}

int MySQLLimitNode::handle_child(MySQLExecuteNode *child) {
  Packet *packet = NULL;
  while (!row_map[child]->empty()) {
    packet = row_map[child]->front();
    row_map[child]->pop_front();
    if (row_count < offset) {
      delete packet;
      row_count++;
      continue;
    }
    if (row_count >= offset + num) {
      delete packet;
      return 1;
    }
    ready_rows->push_back(packet);
    row_count++;
  }
  return 0;
}

void MySQLLimitNode::handle_children() {
  list<MySQLExecuteNode *>::iterator it;
  for (it = children.begin(); it != children.end(); ++it) {
    if (!row_map[*it]->empty())
      if (handle_child(*it)) break;
  }
  LOG_DEBUG(
      "Limit node %@, row_count %d, ready_rows %d"
      "after handle_children.\n",
      this, row_count, ready_rows->size());
}

void MySQLLimitNode::execute() {
  while (status != EXECUTE_STATUS_COMPLETE) {
    switch (status) {
      case EXECUTE_STATUS_START:
        init_row_map();
        status = EXECUTE_STATUS_FETCH_DATA;
        break;

      case EXECUTE_STATUS_FETCH_DATA:
        children_execute();
        if (node_can_swap && plan->plan_can_swap()) {
          handle_swap_connections();
          return;
        }
        status = EXECUTE_STATUS_WAIT;

      case EXECUTE_STATUS_WAIT:
        try {
          wait_children();
        } catch (ExecuteNodeError &e) {
          status = EXECUTE_STATUS_COMPLETE;
          throw e;
        }
        break;

      case EXECUTE_STATUS_HANDLE:
#ifdef DEBUG
        node_start_timing();
#endif
        if (row_count < offset + num) handle_children();
        if (ready_rows->empty() &&
            (all_children_finished || row_count >= offset + num)) {
          status = EXECUTE_STATUS_COMPLETE;
        } else if (row_count >= offset + num) {
          status = EXECUTE_STATUS_HANDLE;
        } else {
          status = EXECUTE_STATUS_FETCH_DATA;
        }
#ifdef DEBUG
        node_end_timing();
#endif
        if (!ready_rows->empty()) return;
        break;
      case EXECUTE_STATUS_BEFORE_COMPLETE:
        status = EXECUTE_STATUS_COMPLETE;
      case EXECUTE_STATUS_COMPLETE:
#ifdef DEBUG
        LOG_DEBUG("MySQLLimitNode %@ cost %d ms\n", this, node_cost_time);
#endif
        break;

      default:
        ACE_ASSERT(0);
        break;
    }
  }
}

/* class MySQLKillNode */

MySQLKillNode::MySQLKillNode(ExecutePlan *plan, int cluster_id, uint32_t kid)
    : MySQLExecuteNode(plan), kid(kid), cluster_id(cluster_id) {
  this->name = "MySQLKillNode";
}

void MySQLKillNode::execute() {
#ifdef DEBUG
  ACE_ASSERT(kid != handler->get_session()->get_thread_id());
#endif
  Session *h = NULL;
#ifndef CLOSE_MULTIPLE
  Backend *backend = Backend::instance();
  if (multiple_mode && cluster_id != ERROR_CLUSTER_ID &&
      cluster_id != backend->get_cluster_id()) {
    MultipleManager *mul = MultipleManager::instance();
    if (mul->get_is_cluster_master()) {
      string kill_sql("KILL ");
      char s_cluster_id[20];
      sprintf(s_cluster_id, "%d", cluster_id);
      kill_sql.append(s_cluster_id);
      kill_sql.append(" ");
      char s_kid[20];
      sprintf(s_kid, "%d", kid);
      kill_sql.append(s_kid);
      mul->execute_master_query(kill_sql.c_str(), cluster_id);
    }
    Packet ok_packet;
    MySQLOKResponse ok(0, 0);
    ok.pack(&ok_packet);
    handler->deal_autocommit_with_ok_eof_packet(&ok_packet);
    handler->record_affected_rows(&ok_packet);
    if (!plan->session->is_call_store_procedure()) {
      handler->send_to_client(&ok_packet);
    }

    status = EXECUTE_STATUS_COMPLETE;
    return;
  }
#endif
  try {
    h = driver->get_session_by_thread_id_for_kill(kid);
    if (!h) {
      throw FindKillThreadFail();
    }
    if (h->is_executing_spark()) {
#ifndef DBSCALE_DISABLE_SPARK
      string job_id = h->get_cur_spark_job_id();
      SparkKillParameter spark_kill_param;
      spark_kill_param.job_id = job_id;
      SparkReturnValue return_value = kill_spark_service(spark_kill_param);
      if (!return_value.success) {
        throw Error(return_value.error_string.c_str());
      }
#endif
    } else {
      h->enable_prepare_kill();
      if (h->get_transfer_rule_manager()) {
        handle_federated_situation(h);
      }
      driver->prepare_session_kill(h);
      h->killall_using_conns();
      driver->finish_session_kill(h);
    }
  } catch (FindKillThreadFail &e) {
    LOG_WARN("Fail to find the kill thread %d.\n", kid);
    status = EXECUTE_STATUS_COMPLETE;
    throw ExecuteNodeError("Fail to find kill thread id.");
  } catch (ThreadKillFailed &e) {
    LOG_ERROR("Fail to kill thread %d, due to %s.\n", kid, e.what());
    status = EXECUTE_STATUS_COMPLETE;
    string message("Fail to kill thread due to ");
    message += e.what();
    throw ExecuteNodeError(message.c_str());
  } catch (Exception &e) {
    LOG_ERROR("Got unexpect expection for kill node.\n");
    status = EXECUTE_STATUS_COMPLETE;
    throw ExecuteNodeError(e.what());
  }

  Packet ok_packet;
  MySQLOKResponse ok(0, 0);
  ok.pack(&ok_packet);
  handler->deal_autocommit_with_ok_eof_packet(&ok_packet);
  handler->record_affected_rows(&ok_packet);
  if (!plan->session->is_call_store_procedure()) {
    handler->send_to_client(&ok_packet);
  }

  status = EXECUTE_STATUS_COMPLETE;
}

bool MySQLKillNode::handle_federated_situation(Session *h) {
  bool ret = false;
  while (!ret) {
    LOG_DEBUG("Waiting for federated session finished.\n");
    bool session_available = driver->check_session_available_aquire(h);
    if (session_available) {
      if (h->federated_session_finished())
        ret = true;
      else {
        int killed_session_count = 0;
        try {
          killed_session_count =
              h->get_transfer_rule_manager()->killall_transfer_rule_sessions();
        } catch (...) {
          driver->release_session_mutex();
          throw;
        }
        h->set_federated_num(killed_session_count);
      }
      driver->release_session_mutex();
    } else {
      ret = true;
    }
    if (h->federated_session_finished()) break;
    ACE_OS::sleep(2);
  }
  return ret;
}

/* class MySQLOKNode */

MySQLOKNode::MySQLOKNode(ExecutePlan *plan) : MySQLInnerNode(plan) {
  this->name = "MySQLOKNode";
}

void MySQLOKNode::execute() {
  init_row_map();
  MySQLExecuteNode *node = children.front();
  node->execute();
  node->notify_parent();
  handler->deal_with_metadata_execute(
      plan->statement->get_stmt_node()->type, plan->statement->get_sql(),
      session->get_schema(), plan->statement->get_stmt_node());

  if (!plan->session->is_call_store_procedure() &&
      !plan->statement->is_cross_node_join() &&
      !plan->statement->is_union_table_sub() &&
      !plan->session->get_is_silence_ok_stmt()) {
    Packet *packet = row_map[node]->front();
    handler->deal_autocommit_with_ok_eof_packet(packet);
    handler->record_affected_rows(packet);
    if (!plan->get_migrate_tool()) {
      if (plan->session->get_has_more_result()) {
        rebuild_ok_with_has_more_flag(packet, driver);
        LOG_DEBUG(
            "For multiple stmt, the ok packet of middle stmt should be with"
            "flag has_more_result.\n");
      }
      handler->send_to_client(packet);
    }
    LOG_DEBUG("OK Node send packet %@ to client.\n", packet);
  } else
    LOG_DEBUG(
        "In store procedure call or cross node join or union table subquery, "
        "so skip the sending"
        " of ok packet in ok node with call [%d] cross join [%d] union [%d] "
        "sliense [%d].\n",
        plan->session->is_call_store_procedure() ? 1 : 0,
        plan->statement->is_cross_node_join() ? 1 : 0,
        plan->statement->is_union_table_sub() ? 1 : 0,
        plan->session->get_is_silence_ok_stmt() ? 1 : 0);
  status = EXECUTE_STATUS_COMPLETE;
}

/* class MySQLSlaveDBScaleErrorNode */
void MySQLSlaveDBScaleErrorNode::execute() {
  try {
    Backend *backend = Backend::instance();
    if (backend->get_need_send_stop_slave_flag()) {
      LOG_DEBUG("slave dbscale server need stop slave\n");
      DataSpace *catalog = backend->get_catalog();
      catalog->execute_one_modify_sql("stop slave");
      backend->set_need_send_stop_slave_flag(false);
    }

    LOG_DEBUG(
        "this is a dbscale server and 'slave-dbscale-mode' is off,so it is "
        "denied to be a slave\n");
    Packet error_packet;
    MySQLErrorResponse error(
        9001, "'slave-dbscale-mode' is off, dbscale is denied to be a slave",
        "", 0);
    error.pack(&error_packet);
    handler->send_to_client(&error_packet);
  } catch (exception &e) {
    status = EXECUTE_STATUS_COMPLETE;
    LOG_ERROR("Execute Node fail in MySQLSlaveDBScaleErrorNode due to [%s].\n",
              e.what());
    throw;
  }
  status = EXECUTE_STATUS_COMPLETE;
}

/* class MySQLExprCalculateNode */
MySQLExprCalculateNode::MySQLExprCalculateNode(
    ExecutePlan *plan, list<SelectExprDesc> &select_expr_list)
    : MySQLInnerPipeNode(plan) {
  this->name = "MySQLExprCalculateNode";
  this->expr_list = select_expr_list;
  inited_expr_list = false;
  column_num = 0;
}

void MySQLExprCalculateNode::handle_child(MySQLExecuteNode *child) {
  Packet *row;
  init_expr_list();
  while (!row_map[child]->empty()) {
    row = row_map[child]->front();
    row_map[child]->pop_front();
    row = reset_packet_value(row);
    ready_rows->push_back(row);
  }
}
void MySQLExprCalculateNode::calculate_expr(SelectExprDesc *desc) {
  desc->is_null = false;
  desc->column_data.clear();
  ExpressionValue expr_value;
  desc->expr->get_expression_value(&expr_value);
  switch (expr_value.value_type) {
    case RESULT_TYPE_NULL: {
      desc->is_null = true;
    } break;
    case RESULT_TYPE_NUM: {
      char column[GMP_N_DIGITS + 5];
      char formator[10];
      sprintf(formator, "%%.%dFf", expr_value.gmp_value.deci_num);
      int len = gmp_sprintf(column, formator, expr_value.gmp_value.value);
      column[len] = '\0';
      desc->column_data.append(column);
    } break;
    case RESULT_TYPE_BOOL: {
      if (expr_value.bool_value)
        desc->column_data.append("1");
      else
        desc->column_data.append("0");
    } break;
    case RESULT_TYPE_STRING: {
      desc->column_data.append(expr_value.str_value);
    } break;
    default:
      LOG_ERROR("Unsupport result type for MySQLExprCalculateNode.\n");
      throw ExecuteNodeError(
          "Unsupport result type for MySQLExprCalculateNode.");
  }
}
Packet *MySQLExprCalculateNode::reset_packet_value(Packet *row) {
  MySQLRowResponse row_res(row);
  int column_len = 0;
  char *column_data = NULL;
  Packet *new_row = Backend::instance()->get_new_packet(row_packet_size);
  new_row->wr_ptr(new_row->base() + PACKET_HEADER_SIZE);

  list<SelectExprDesc>::iterator it;
  list<FieldExpression *>::iterator fe_it;
  for (fe_it = field_expr_list.begin(); fe_it != field_expr_list.end();
       fe_it++) {
    (*fe_it)->set_row(row);
  }

  unsigned int need_len = 1;  // for terminate '\0'
  it = expr_list.begin();
  fe_it = field_expr_list.begin();
  for (unsigned int i = 0; i < column_num; i++) {
    row_res.set_current(i);
    if (it != expr_list.end() && it->index == i) {
      need_len = need_len + 9 + it->column_data.size();
      it++;
    } else {
      need_len = need_len + 9 + row_res.get_current_length();
    }
    if (fe_it != field_expr_list.end() &&
        (unsigned int)((*fe_it)->column_index) == i) {
      (*fe_it)->is_null = row_res.field_is_null();
    }
    row_res.move_next();
  }
  for (it = expr_list.begin(); it != expr_list.end(); it++) {
    calculate_expr(&(*it));
  }
  unsigned int remain_len =
      new_row->size() - (new_row->wr_ptr() - new_row->base());
  if (remain_len < need_len) {
    uint64_t resize_len = need_len + new_row->wr_ptr() - new_row->base();
    LOG_DEBUG("Packet size not enough, resize packet size from %d to %d\n",
              new_row->size(), resize_len);
    new_row->size(resize_len);
  }
  it = expr_list.begin();
  for (unsigned int i = 0; i < column_num; i++) {
    row_res.set_current(i);
    if (it != expr_list.end() && it->index == i) {
      if (it->is_null) {
        new_row->packchar(
            '\373');  //'\373' represents that the field value is NULL
      } else {
        new_row->pack_lenenc_int(it->column_data.size());
        new_row->packdata(it->column_data.c_str(), it->column_data.size());
      }
      it++;
    } else {
      if (row_res.field_is_null())
        new_row->packchar(
            '\373');  //'\373' represents that the field value is NULL
      else {
        column_len = row_res.get_current_length();
        column_data = row_res.get_current_data();
        new_row->pack_lenenc_int(column_len);
        new_row->packdata(column_data, column_len);
      }
    }
    row_res.move_next();
  }
  size_t load_length = new_row->length() - PACKET_HEADER_SIZE;
  pack_header(new_row, load_length);
  delete row;
  return new_row;
}
void get_expression_type(list<Packet *> *field_packets,
                         FieldExpression *expression, ResultType &result_type);

void init_expr_low(Expression *expr, STMT_EXPR_TYPE stmt_expr_type,
                   list<Packet *> *field_packets,
                   list<FieldExpression *> &field_expression_list) {
  expr_type expr_type = expr->type;
  switch (expr_type) {
    case EXPR_EQ:
    case EXPR_GR:
    case EXPR_LESS:
    case EXPR_GE:
    case EXPR_LESSE:
    case EXPR_NE:
    case EXPR_EQ_N:
    case EXPR_AND:
    case EXPR_OR:
    case EXPR_XOR:
    case EXPR_ELSE: {
      BoolBinaryExpression *bi_expr = (BoolBinaryExpression *)expr;
      init_expr_low(bi_expr->left, stmt_expr_type, field_packets,
                    field_expression_list);
      init_expr_low(bi_expr->right, stmt_expr_type, field_packets,
                    field_expression_list);
    } break;

    case EXPR_IF_COND:
    case EXPR_WHEN_THEN: {
      ConditionExpression *cond_expr = (ConditionExpression *)expr;
      init_expr_low(cond_expr->left, stmt_expr_type, field_packets,
                    field_expression_list);
      init_expr_low(cond_expr->right, stmt_expr_type, field_packets,
                    field_expression_list);
    } break;

    case EXPR_MINUS: {
      ArithmeticUnaryExpression *un_expr = (ArithmeticUnaryExpression *)expr;
      init_expr_low(un_expr->right, stmt_expr_type, field_packets,
                    field_expression_list);
    } break;

    case EXPR_ADD:
    case EXPR_SUB:
    case EXPR_MUL:
    case EXPR_DIV: {
      ArithmeticBinaryExpression *bi_expr = (ArithmeticBinaryExpression *)expr;
      init_expr_low(bi_expr->left, stmt_expr_type, field_packets,
                    field_expression_list);
      init_expr_low(bi_expr->right, stmt_expr_type, field_packets,
                    field_expression_list);
    } break;
    case EXPR_IS:
    case EXPR_IS_NOT: {
      TruthExpression *t_expr = (TruthExpression *)expr;
      init_expr_low(t_expr->left, stmt_expr_type, field_packets,
                    field_expression_list);
      init_expr_low(t_expr->right, stmt_expr_type, field_packets,
                    field_expression_list);
    } break;

    case EXPR_IF:
    case EXPR_IFNULL:
    case EXPR_CASE: {
      if (stmt_expr_type == FIELD_EXPR) {
        TerCondExpression *ter_cond_expr = (TerCondExpression *)expr;
        expr_list_item *item = ter_cond_expr->list_expr->expr_list_head;
        do {
          init_expr_low(item->expr, stmt_expr_type, field_packets,
                        field_expression_list);
          item = item->next;
        } while (item != ter_cond_expr->list_expr->expr_list_head);
        if (ter_cond_expr->else_expr)
          init_expr_low(ter_cond_expr->else_expr, stmt_expr_type, field_packets,
                        field_expression_list);
      } else {
        throw NotImplementedError("Filter expression is too complex.");
      }
    } break;

    case EXPR_FIELD: {
      ResultType result_type;
      FieldExpression *field_expr = (FieldExpression *)expr;
      if (field_expr->column_index < 0) {
        field_expr->column_index += field_packets->size();
      }
      get_expression_type(field_packets, field_expr, result_type);
      field_expr->result_type = result_type;
      field_expression_list.push_back(field_expr);
    } break;

    case EXPR_INT:
    case EXPR_STRING:
    case EXPR_FLOAT:
    case EXPR_NULL:
      break;

    default:
      throw NotImplementedError("expression is too complex");
  }
}

void MySQLExprCalculateNode::init_expr_list() {
  if (!inited_expr_list) {
    list<SelectExprDesc>::iterator it;
    for (it = expr_list.begin(); it != expr_list.end(); it++) {
      init_expr_low(it->expr, FIELD_EXPR, get_field_packets(), field_expr_list);
    }
    column_num = get_field_packets()->size();
    inited_expr_list = true;
  }
}

/* class MySQLConnectByNode */
MySQLConnectByNode::MySQLConnectByNode(ExecutePlan *plan,
                                       ConnectByDesc connect_by_desc)
    : MySQLInnerPipeNode(plan) {
  this->name = "MySQLConnectByNode";
  inited_column_index = false;
  where_index = connect_by_desc.where_index;
  start_index = connect_by_desc.start_index;
  prior_index = connect_by_desc.prior_index;
  recur_index = connect_by_desc.recur_index;
  row_id = 0;
  max_result_num =
      session->get_session_option("max_connect_by_result_num").uint_val;
  loop_flag = new bitset<MAX_CONNECT_BY_CACHED_ROWS>();
  ignore_flag = new bitset<MAX_CONNECT_BY_CACHED_ROWS>();
}

void MySQLConnectByNode::do_clean() {
  unsigned int i = 0;
  // the clean may cost a long time,
  // witch may delay the recieving of next request packet from client.
  for (; i < row_id; ++i) {
    if (!loop_flag->test(i)) delete id_prior_packets[i].second;
  }
  if (loop_flag) delete loop_flag;
  if (ignore_flag) delete ignore_flag;
}

void MySQLConnectByNode::handle_discarded_packets() {
  if (loop_flag->all()) return;
  unsigned int i = 0;
  for (; i < row_id; ++i) {
    if (!loop_flag->test(i)) {
      loop_flag->set(i);
      delete id_prior_packets[i].second;
    }
  }
}

void MySQLConnectByNode::init_column_index() {
  list<Packet *> *field_packets = get_field_packets();
  unsigned int column_num = field_packets->size();

  if (where_index) where_index += column_num;
  start_index += column_num;
  prior_index += column_num;
  recur_index += column_num;

  if (start_index < 0 || prior_index < 0 || recur_index < 0 ||
      where_index < 0) {
    LOG_ERROR("Fail to init connect by column index.\n");
    throw Error("Fail to init connect by column index.");
  }

  inited_column_index = true;
}

void MySQLConnectByNode::handle_child(MySQLExecuteNode *child) {
  if (!inited_column_index) init_column_index();

  Packet *row = NULL;
  while (!row_map[child]->empty()) {
    if (row_id >= max_result_num || row_id >= MAX_CONNECT_BY_CACHED_ROWS) {
      LOG_ERROR("Reach the max connect by result cache number.\n");
      throw Error("Reach the max connect by result cache number.");
    }
    row = row_map[child]->front();
    row_map[child]->pop_front();
    MySQLRowResponse row_res(row);
    uint64_t row_len;
    bool is_null;

    int where_result = 1;
    if (where_index) {
      is_null = row_res.field_is_null(where_index);
      if (!is_null) where_result = row_res.get_int((unsigned int)where_index);
    }

    int start_flag = 0;
    is_null = row_res.field_is_null(start_index);
    if (!is_null) start_flag = row_res.get_int((unsigned int)start_index);

    string prior_value;
    is_null = row_res.field_is_null(prior_index);
    if (!is_null) {
      const char *prior_data =
          row_res.get_str((unsigned int)prior_index, &row_len);
      prior_value.assign(prior_data, row_len);
    }

    string recur_value;
    is_null = row_res.field_is_null(recur_index);
    if (!is_null) {
      const char *recur_data =
          row_res.get_str((unsigned int)recur_index, &row_len);
      recur_value.assign(recur_data, row_len);
    }

    if (!where_result) ignore_flag->set(row_id);
    if (start_flag) start_ids.push_back(row_id);
    id_prior_packets[row_id] = make_pair(prior_value, row);
    if (!recur_value.empty()) recur_ids[recur_value].push_back(row_id);
    ++row_id;
  }
}

/* How to implement connect by:
 * 1. Erase the connect by part from original query sql, and append start, where
 * conditions, append prior and recursion related columns to the select fiedld
 * list. For example: SELECT * FROM t1 where t1.c3<100 window connect by t1.c1 =
 * prior t1.c2 start with t1.c1 = 1; will be changed to: SELECT *, t1.c1, t1.c2,
 * (t1.c1 = 1), (t1.c3<100) FROM t1;
 * 2. Store all results data in id_prior_packets, the key is row id, the value
 * is prior column value and row packet.
 * 3. Check the (t1.c1 = 1) column，if 1, means the row is the start row, put
 * into start_ids.
 * 4. Check the (t1.c3<100) column, if 0, the row will be filtered, put into
 * ignore_flag.
 * 5. Store each row in recur_ids, the key is recur column vlaue, value is all
 * the row ids has the same recur value.
 * 6. Use loop_flag to check if a row has already been put into ready_rows,
 * check each row before put into ready_rows, if 1, means there is a connect by
 * data loop, do not support.
 * 7. Use start_ids to start the recursive function:
 *    a. Put the row to ready_rows.
 *    b. Get the prior column value of the row.
 *    c. Check recur_ids, if there are rows has recur column value equal to the
 * prior column vlaue d  if yes goto a if no return
 * */
void MySQLConnectByNode::handle_before_complete() {
  list<unsigned int>::iterator it = start_ids.begin();
  for (; it != start_ids.end(); ++it) {
    if (loop_flag->test(*it)) {
      LOG_ERROR("Not support CONNECT BY loop for query data.\n");
      throw Error("Not support CONNECT BY loop for query data.");
    }
    if (!ignore_flag->test(*it)) {
      ready_rows->push_back(id_prior_packets[*it].second);
      loop_flag->set(*it);
    }
    find_recur_row_result(*it);
  }
}

void MySQLConnectByNode::find_recur_row_result(unsigned int id) {
  string prior_value = id_prior_packets[id].first;
  if (recur_ids.count(prior_value)) {
    list<unsigned int> id_list = recur_ids[prior_value];
    list<unsigned int>::iterator it = id_list.begin();
    for (; it != id_list.end(); ++it) {
      if (loop_flag->test(*it)) {
        LOG_ERROR("Not support CONNECT BY loop for query data.\n");
        throw Error("Not support CONNECT BY loop for query data.");
      }
      if (!ignore_flag->test(*it)) {
        ready_rows->push_back(id_prior_packets[*it].second);
        loop_flag->set(*it);
      }
      find_recur_row_result(*it);
    }
  }
}

/* class MySQLAvgNode */
MySQLAvgNode::MySQLAvgNode(ExecutePlan *plan, list<AvgDesc> &avg_list)
    : MySQLInnerPipeNode(plan) {
  for (auto &desc : avg_list) {
    AvgDesc desc_clone;
    desc_clone.clone(desc);
    this->avg_list.push_back(desc_clone);
  }
  inited_column_index = false;
  this->name = "MySQLAvgNode";
}
void MySQLAvgNode::clean() {
  MySQLInnerNode::clean();
  for (auto &desc : avg_list) {
    if (desc.mpf_inited) mpf_clear(desc.value);
  }
}

void MySQLAvgNode::init_column_index() {
  if (!inited_column_index) {
    list<Packet *> *field_packets = get_field_packets();
    unsigned int column_num = field_packets->size();

    /* adjust column index */
    list<AvgDesc>::iterator it;
    for (it = avg_list.begin(); it != avg_list.end(); it++) {
      it->sum_index += column_num;
      it->count_index += column_num;
      if (it->avg_index < 0) it->avg_index += column_num;
    }

    /* adjust the avg result decimal */
    list<Packet *>::iterator it_field;
    unsigned int index = 0;
    for (it_field = field_packets->begin(); it_field != field_packets->end();
         it_field++, index++) {
      MySQLColumnResponse col_resp(*it_field);
      col_resp.unpack();
      for (it = avg_list.begin(); it != avg_list.end(); it++) {
        if (it->avg_index == (int)index) {
          avg_column_type[it->avg_index] = col_resp.get_column_type();
          it->decimal = col_resp.get_decimals();
          LOG_DEBUG("decimal=%d, index=%d\n", it->decimal, index);
          break;
        }
      }
    }
    inited_column_index = true;
  }
}

void MySQLAvgNode::handle_child(MySQLExecuteNode *child) {
  Packet *row;
  mpf_t sum;
  uint64_t count = 0;
  list<AvgDesc>::iterator it;
  char avg_column[GMP_N_DIGITS + 5];

  init_column_index();

  unsigned int column_num = get_field_packets()->size();
  mpf_init2(sum, DECIMAL_STORE_BIT);
  while (!row_map[child]->empty()) {
    row = row_map[child]->front();
    row_map[child]->pop_front();
    MySQLRowResponse row_res(row);
    Packet *new_row = Backend::instance()->get_new_packet(row_packet_size);
    vector<int> column_len(column_num, 0);
    vector<string> column_data(column_num, "");
    vector<bool> reset_value(column_num, false);
    unsigned int needed_length = 0;

    new_row->wr_ptr(new_row->base() + PACKET_HEADER_SIZE);
    for (it = avg_list.begin(); it != avg_list.end(); it++) {
      it->reset_value = true;
      if (!row_res.field_is_null(it->sum_index) &&
          !row_res.field_is_null(it->count_index)) {
        row_res.get_mpf(it->sum_index, sum);
        count = row_res.get_uint(it->count_index);
        if (count == 0) {
          it->reset_value = false;
          continue;
        }
      } else {
        it->reset_value = false;
        continue;
      }
      mpf_div_ui(it->value, sum, count);
    }

    for (unsigned int i = 0; i < column_num; i++) {
      row_res.set_current(i);
      for (it = avg_list.begin(); it != avg_list.end(); it++) {
        if (it->avg_index == (int)i && it->reset_value) {
          if (it->decimal == 0)
            column_len[i] = gmp_sprintf(avg_column, "%.4Ff", it->value);
          else if (it->decimal == 31 &&
                   avg_column_type[i] == MYSQL_TYPE_DOUBLE) {
            column_len[i] = gmp_sprintf(avg_column, "%.16Ff", it->value);
            for (int j = column_len[i] - 1; j > 0; j--) {
              if (avg_column[j] == '0') {
                column_len[i]--;
              } else if (avg_column[j] == '.') {
                column_len[i]--;
                break;
              } else {
                break;
              }
            }
          } else {
            char formator[10];
            sprintf(formator, "%%.%dFf", it->decimal);
            column_len[i] = gmp_sprintf(avg_column, formator, it->value);
          }
          column_data[i] = avg_column;
          reset_value[i] = true;
          break;
        }
      }

      if (!row_res.field_is_null() && !reset_value[i]) {
        column_len[i] = row_res.get_current_length();
      }
      needed_length += column_len[i];
      row_res.move_next();
    }

    needed_length += 1 + 9 * column_num;
    /**
     *   max(1,9)    // '\373' or max required length of pack_lenenc_int()
     * + column_len  // packed data length
     * + 1           // for terminate '\0'
     */
    if (new_row->size() - (new_row->wr_ptr() - new_row->base()) <
        needed_length) {
      uint64_t resize_len = needed_length + new_row->wr_ptr() - new_row->base();
      LOG_DEBUG("Packet size not enough, resize packet size from %d to %d\n",
                new_row->size(), resize_len);
      new_row->size(resize_len);
    }

    for (unsigned int i = 0; i < column_num; i++) {
      row_res.set_current(i);
      if (row_res.field_is_null() && !reset_value[i])
        new_row->packchar(
            '\373');  //'\373' represents that the field value is NULL
      else {
        if (!reset_value[i]) {
          column_data[i] = row_res.get_current_data();
        }
        new_row->pack_lenenc_int(column_len[i]);
        new_row->packdata(column_data[i].c_str(), column_len[i]);
      }
      row_res.move_next();
    }
    size_t load_length = new_row->length() - PACKET_HEADER_SIZE;
    pack_header(new_row, load_length);
    ready_rows->push_back(new_row);
    delete row;
  }
  mpf_clear(sum);
}

/* class MySQLUnionGroupNode */

MySQLUnionGroupNode::MySQLUnionGroupNode(ExecutePlan *plan,
                                         vector<list<ExecuteNode *> > &nodes)
    : MySQLExecuteNode(plan, NULL) {
  this->name = "MySQLUnionGroupNode";
  this->nodes = nodes;
  finished_group_num = 0;
  column_size = 0;
  got_error = false;
}

void MySQLUnionGroupNode::check_union_columns() {
  if (column_size == 0) {
    MySQLResultSetHeaderResponse header(
        ((MySQLExecuteNode *)(nodes[0].front()))->get_header_packet());
    header.unpack();
    column_size = header.get_columns();
  }
  list<ExecuteNode *>::iterator it = nodes[finished_group_num].begin();
  for (; it != nodes[finished_group_num].end(); it++) {
    MySQLResultSetHeaderResponse header(
        ((MySQLExecuteNode *)(*it))->get_header_packet());
    header.unpack();
    if (column_size != header.get_columns()) {
      got_error = true;
      status = EXECUTE_STATUS_COMPLETE;
      MySQLErrorResponse error(
          1222, "The used SELECT statements have a different number of columns",
          "21000");
      error.pack(&error_packet);
      throw ErrorPacketException();
    }
  }
}

void MySQLUnionGroupNode::handle_children() {
  list<ExecuteNode *>::iterator it;
  for (it = nodes[finished_group_num].begin();
       it != nodes[finished_group_num].end(); ++it) {
    if (!row_map[*it]->empty()) handle_child((MySQLExecuteNode *)(*it));
  }
}

void MySQLUnionGroupNode::handle_child(MySQLExecuteNode *child) {
  Packet *row;
  while (!row_map[child]->empty()) {
    row = row_map[child]->front();
    ready_rows->push_back(row);
    row_map[child]->pop_front();
  }
}

void MySQLUnionGroupNode::execute() {
  while (status != EXECUTE_STATUS_COMPLETE) {
    switch (status) {
      case EXECUTE_STATUS_START: {
#ifdef DEBUG
        node_start_timing();
#endif
        init_row_map();
        status = EXECUTE_STATUS_FETCH_DATA;
        break;
      }
      case EXECUTE_STATUS_FETCH_DATA:
        children_execute();
        status = EXECUTE_STATUS_WAIT;
      case EXECUTE_STATUS_WAIT:
        try {
          wait_children();
        } catch (ExecuteNodeError &e) {
          status = EXECUTE_STATUS_COMPLETE;
          throw e;
        }
        break;
      case EXECUTE_STATUS_HANDLE:
        try {
          handle_children();
        } catch (...) {
          status = EXECUTE_STATUS_COMPLETE;
          throw;
        }
        status = EXECUTE_STATUS_FETCH_DATA;
        break;
      case EXECUTE_STATUS_BEFORE_COMPLETE:
        status = EXECUTE_STATUS_COMPLETE;
      case EXECUTE_STATUS_COMPLETE:
#ifdef DEBUG
        node_end_timing();
#endif
#ifdef DEBUG
        LOG_DEBUG("MySQLUnionGroupNode %@ cost %d ms\n", this, node_cost_time);
#endif
        break;

      default:
        break;
    }
  }
}

Packet *MySQLUnionGroupNode::get_error_packet() {
  list<MySQLExecuteNode *>::iterator it;
  for (it = children.begin(); it != children.end(); ++it) {
    if ((*it)->get_error_packet()) {
      return (*it)->get_error_packet();
    }
  }
  if (got_error) {
    return &error_packet;
  }
  return NULL;
}

void MySQLUnionGroupNode::children_execute() {
  LOG_DEBUG("Node %@ children start to execute.\n", this);
  if (finished_group_num < nodes.size()) {
    list<ExecuteNode *> execute_nodes = nodes[finished_group_num];
    list<ExecuteNode *>::iterator it = execute_nodes.begin();
    for (; it != execute_nodes.end(); ++it) {
      (*it)->execute();
    }
  }
  LOG_DEBUG("Node %@ children execute finished.\n", this);
}

bool MySQLUnionGroupNode::notify_parent() {
  Packet *row;
  if (ready_rows->empty()) {
    return false;
  }

  while (!ready_rows->empty()) {
    row = ready_rows->front();
    ready_rows->pop_front();
    parent->add_row_packet(this, row);
  }

  return true;
}

void MySQLUnionGroupNode::set_children_thread_status_start(
    unsigned int group_num) {
  list<ExecuteNode *>::iterator it = nodes[group_num].begin();
  for (; it != nodes[group_num].end(); ++it) {
    ((MySQLExecuteNode *)(*it))->set_thread_status_started();
  }
}

void MySQLUnionGroupNode::handle_error_all_children() {
  list<MySQLExecuteNode *>::iterator it;
  for (it = children.begin(); it != children.end(); ++it) {
    try {
      (*it)->handle_error_throw();
    } catch (...) {
      it++;
      for (; it != children.end(); it++) {
        try {
          (*it)->handle_error_throw();
        } catch (...) {
        }
      }
      throw;
    }
  }
}

void MySQLUnionGroupNode::wait_children() {
  LOG_DEBUG("Node %@ start to wait.\n", this);
  list<ExecuteNode *> node_list = nodes[finished_group_num];
  list<ExecuteNode *>::iterator it = node_list.begin();
  for (; it != node_list.end(); it++) {
    ((MySQLExecuteNode *)(*it))->start_thread();
  }
  set_children_thread_status_start(finished_group_num);
  plan->start_all_bthread();

  unsigned int finished_child = 0;
  it = node_list.begin();
  for (; it != node_list.end(); it++) {
    if (!((MySQLExecuteNode *)(*it))->notify_parent() && (*it)->is_finished()) {
      finished_child++;
    }
  }
  // Check union columns for one group after this group nodes got header
  // packets.
  check_union_columns();
  if (finished_child == node_list.size()) {
    finished_group_num++;
  }

  if (finished_group_num == nodes.size()) {
    handle_error_all_children();
    status = EXECUTE_STATUS_BEFORE_COMPLETE;
  } else {
    status = EXECUTE_STATUS_HANDLE;
  }
  LOG_DEBUG("Node %@ wait finished.\n", this);
}

void MySQLUnionGroupNode::init_row_map() {
  list<MySQLExecuteNode *>::iterator it;
  for (it = children.begin(); it != children.end(); ++it) {
    row_map[*it] =
        new AllocList<Packet *, Session *, StaticAllocator<Packet *> >();
    row_map[*it]->set_session(plan->session);
    row_map_size[*it] = 0;
  }
}

void MySQLUnionGroupNode::clean() {
  Packet *packet;
  MySQLExecuteNode *free_node;

  status = EXECUTE_STATUS_COMPLETE;

  // clean ready packets
  while (!ready_rows->empty()) {
    packet = ready_rows->front();
    ready_rows->pop_front();
    delete packet;
  }

  while (!children.empty()) {
    free_node = children.front();
    free_node->clean();

    // clean remaining rows
    if (row_map[free_node]) {
      while (!row_map[free_node]->empty()) {
        packet = row_map[free_node]->front();
        row_map[free_node]->pop_front();
        delete packet;
      }

      delete row_map[free_node];
      row_map[free_node] = NULL;
    }

    // delete child node
    children.pop_front();
    delete free_node;
  }
}

/* class MySQLUnionAllNode */
MySQLUnionAllNode::MySQLUnionAllNode(ExecutePlan *plan,
                                     vector<ExecuteNode *> &nodes)
    : MySQLInnerPipeNode(plan) {
  this->name = "MySQLUnionAllNode";
  column_size = 0;
  this->nodes = nodes;
  got_error = false;
}

void MySQLUnionAllNode::handle_children() {
  if (column_size == 0) check_union_columns();
  list<MySQLExecuteNode *>::iterator it;
  for (it = children.begin(); it != children.end(); ++it) {
    if (!row_map[*it]->empty()) handle_child(*it);
  }
  status = EXECUTE_STATUS_FETCH_DATA;
}

void MySQLUnionAllNode::check_union_columns() {
  vector<ExecuteNode *>::iterator it = nodes.begin();
  MySQLResultSetHeaderResponse header(
      ((MySQLExecuteNode *)(*it))->get_header_packet());
  header.unpack();
  column_size = header.get_columns();
  it++;
  for (; it != nodes.end(); it++) {
    MySQLResultSetHeaderResponse header(
        ((MySQLExecuteNode *)(*it))->get_header_packet());
    header.unpack();
    if (column_size != header.get_columns()) {
      got_error = true;
      status = EXECUTE_STATUS_COMPLETE;
      MySQLErrorResponse error(
          1222, "The used SELECT statements have a different number of columns",
          "21000");
      error.pack(&error_packet);
      throw ErrorPacketException();
    }
  }
}

Packet *MySQLUnionAllNode::get_error_packet() {
  Packet *error = MySQLInnerPipeNode::get_error_packet();
  if (error) {
    return error;
  } else if (got_error) {
    return &error_packet;
  }
  return NULL;
}

/* class MySQLInnerPipeNode */
MySQLInnerPipeNode::MySQLInnerPipeNode(ExecutePlan *plan)
    : MySQLInnerNode(plan) {
  this->name = "MySQLInnerPipeNode";
  node_can_swap = session->is_may_backend_exec_swap_able();
}
void MySQLInnerPipeNode::handle_children() {
  list<MySQLExecuteNode *>::iterator it;
  for (it = children.begin(); it != children.end(); ++it) {
    if (!row_map[*it]->empty()) handle_child(*it);
  }
  status = EXECUTE_STATUS_FETCH_DATA;
}

void MySQLInnerPipeNode::handle_child(MySQLExecuteNode *child) {
  Packet *row;
  while (!row_map[child]->empty()) {
    row = row_map[child]->front();
    ready_rows->push_back(row);
    row_map[child]->pop_front();
  }
}

void MySQLInnerPipeNode::execute() {
  ExecuteProfileHandler *execute_profile = session->get_profile_handler();
  while (status != EXECUTE_STATUS_COMPLETE) {
    switch (status) {
      case EXECUTE_STATUS_START: {
        init_row_map();
        status = EXECUTE_STATUS_FETCH_DATA;
        break;
      }
      case EXECUTE_STATUS_FETCH_DATA:
        children_execute();
        if (node_can_swap && plan->plan_can_swap()) {
          handle_swap_connections();
          return;
        }
        status = EXECUTE_STATUS_WAIT;
      case EXECUTE_STATUS_WAIT:
        try {
          wait_children();
        } catch (ExecuteNodeError &e) {
          status = EXECUTE_STATUS_COMPLETE;
          throw e;
        }
        break;
      case EXECUTE_STATUS_HANDLE:
#ifdef DEBUG
        node_start_timing();
#endif
        profile_id = execute_profile->start_serial_monitor(
            get_executenode_name(), profile_id);
        try {
          handle_children();
        } catch (...) {
          status = EXECUTE_STATUS_COMPLETE;
          throw;
        }
#ifdef DEBUG
        node_end_timing();
#endif
        execute_profile->end_execute_monitor(profile_id);
        status = EXECUTE_STATUS_FETCH_DATA;
        return;
        break;
      case EXECUTE_STATUS_BEFORE_COMPLETE:
        handle_before_complete();
        status = EXECUTE_STATUS_COMPLETE;
      case EXECUTE_STATUS_COMPLETE:
#ifdef DEBUG
        LOG_DEBUG("MySQLInnerPipeNode %@ cost %d ms\n", this, node_cost_time);
#endif
        break;

      default:
        break;
    }
  }
}
/* class MySQLOKMergeNode */

MySQLOKMergeNode::MySQLOKMergeNode(ExecutePlan *plan) : MySQLInnerNode(plan) {
  this->name = "MySQLOKMergeNode";
  ok_packet = NULL;
  affect_rows = 0;
  warnings = 0;
}

void MySQLOKMergeNode::handle_children() {
  list<MySQLExecuteNode *>::iterator it;
  for (it = children.begin(); it != children.end(); ++it) {
    if (!row_map[*it]->empty()) handle_child(*it);
  }

  status = EXECUTE_STATUS_FETCH_DATA;
}

void MySQLOKMergeNode::handle_child(MySQLExecuteNode *child) {
  Packet *packet = NULL;
  int first_msg = 0;
  int second_msg = 0;
  stmt_type type = plan->statement->get_stmt_node()->type;
  while (!row_map[child]->empty()) {
    packet = row_map[child]->front();
    row_map[child]->pop_front();
    MySQLOKResponse ok(packet);
    ok.unpack();
    affect_rows += ok.get_affected_rows();
    warnings += ok.get_warnings();
    if (type == STMT_UPDATE) {
      first_msg +=
          session->get_matched_or_change_message("matched:", ok.get_message());
      second_msg +=
          session->get_matched_or_change_message("Changed:", ok.get_message());
    }
    LOG_DEBUG("After handle modify node %@, affected_row[%d], warnings[%d].\n",
              child, affect_rows, warnings);
    if (!ok_packet) {
      ok_packet = packet;
      LOG_DEBUG("Keep packet %@ for ok packet rebuild.\n", packet);
    } else {
      LOG_DEBUG("Delete packet %@ after handle modify node %@.\n", packet,
                this);
      delete packet;
    }
  }
  if (type == STMT_UPDATE) {
    string ok_msg = "Rows matched: ";
    ok_msg.append(to_string(first_msg));
    ok_msg.append("  Changed: ");
    ok_msg.append(to_string(second_msg));
    ok_msg.append("  Warnings: ");
    ok_msg.append(to_string(warnings));
    update_msg = ok_msg;
  }
  LOG_DEBUG("Handle modify node %@ finish.\n", child);
}

void MySQLOKMergeNode::rebuild_ok_packet() {
  LOG_DEBUG("Rebuild ok packet with affected_rows [%d] warnings [%d].\n",
            affect_rows, warnings);
  if (ok_packet) {
    MySQLOKResponse ok(ok_packet);
    ok.set_affected_rows(affect_rows);
    ok.set_warnings(warnings);
    ok.set_message(update_msg);
    Packet *new_packet = Backend::instance()->get_new_packet(row_packet_size);
    ok.pack(new_packet);
    delete ok_packet;
    ok_packet = new_packet;
  } else {
    MySQLOKResponse ok(affect_rows, warnings);
    ok_packet = Backend::instance()->get_new_packet(row_packet_size);
    ok.pack(ok_packet);
  }
  ready_rows->push_back(ok_packet);
  ok_packet = NULL;
}

void MySQLOKMergeNode::execute() {
  while (status != EXECUTE_STATUS_COMPLETE) {
    switch (status) {
      case EXECUTE_STATUS_START: {
        init_row_map();
        status = EXECUTE_STATUS_FETCH_DATA;
        break;
      }

      case EXECUTE_STATUS_FETCH_DATA:
        children_execute();
        status = EXECUTE_STATUS_WAIT;

      case EXECUTE_STATUS_WAIT:
        try {
          wait_children();
        } catch (ExecuteNodeError &e) {
          status = EXECUTE_STATUS_COMPLETE;
          throw e;
        }
        break;

      case EXECUTE_STATUS_HANDLE:
#ifdef DEBUG
        node_start_timing();
#endif
        handle_children();
#ifdef DEBUG
        node_end_timing();
#endif
        break;

      case EXECUTE_STATUS_BEFORE_COMPLETE:
        rebuild_ok_packet();
        status = EXECUTE_STATUS_COMPLETE;

      case EXECUTE_STATUS_COMPLETE:
#ifdef DEBUG
        LOG_DEBUG("MySQLOKMergeNode %@ cost %d ms\n", this, node_cost_time);
#endif
        break;

      default:
        break;
    }
  }
}

/* classs MySQLModifyNode */

MySQLModifyNode::MySQLModifyNode(ExecutePlan *plan, DataSpace *dataspace)
    : MySQLExecuteNode(plan, dataspace),
      cond_sql(sql_mutex),
      cond_notify(mutex),
      new_stmt_for_shard(NULL) {
  this->name = "MySQLModifyNode";
  thread_status = THREAD_STOP;
  bthread = NULL;
  got_error = false;
  conn = NULL;
  status = EXECUTE_STATUS_START;
  this->error_packet = NULL;
}

void MySQLModifyNode::handle_error_packet(Packet *packet) {
  try {
    ACE_Guard<ACE_Thread_Mutex> guard(mutex);
    record_migrate_error_message(plan, packet,
                                 "Modify node get an error packet");
    got_error = true;
    status = EXECUTE_STATUS_COMPLETE;
    error_packet = packet;
    if (handle_tokudb_lock_timeout(conn, packet)) {
      if (conn) {
        handler->clean_dead_conn(&conn, dataspace);
      }
    }
    cond_notify.signal();
  } catch (...) {
    cond_notify.signal();
  }
}

void MySQLModifyNode::execute() {
  if (thread_status == THREAD_STOP) {
    status = EXECUTE_STATUS_FETCH_DATA;

#ifndef DBSCALE_TEST_DISABLE
    Backend *bk = Backend::instance();
    dbscale_test_info *test_info = bk->get_dbscale_test_info();
    if (!strcasecmp(test_info->test_case_name.c_str(), "bthread") &&
        !strcasecmp(test_info->test_case_operation.c_str(), "get_null")) {
      bthread = NULL;
    } else {
#endif
      Backend *backend = Backend::instance();
      bthread = backend->get_backend_thread_pool()->get_one_from_free();
#ifndef DBSCALE_TEST_DISABLE
    }
#endif
    if (!bthread) {
      got_error = true;
      LOG_ERROR("Fail to get thread for MySQLModifyNode::execute.\n");
      throw Error(
          "Fail to get a backend thread from pool, so stop execute the sql");
    }
    thread_status = THREAD_CREATED;
    LOG_DEBUG("Modify node %@ start to work.\n", this);
    bthread->set_task(this);
    thread_status = THREAD_STARTED;
    bthread->wakeup_handler_thread();
    // After the acquire of lock, the backend thread must is start to running
    // the task.
  }
}

void MySQLModifyNode::clean() {
  if (thread_status == THREAD_STARTED) {
    LOG_DEBUG("Modify node %@ cleaning wait.\n", this);
    this->wait_for_cond();
    LOG_DEBUG("Modify node %@ cleaning wait finish.\n", this);
  } else if (thread_status == THREAD_CREATED) {
    bthread->re_init_backend_thread();
    bthread->get_pool()->add_back_to_free(bthread);
  } else {
    got_error = true;
  }
  Packet *packet = NULL;
  while (!ready_rows->empty()) {
    packet = ready_rows->front();
    ready_rows->pop_front();
    delete packet;
  }

  string *s;
  while (!sql_list.empty()) {
    s = sql_list.front();
    sql_list.pop_front();
    delete s;
  }

  if (conn) {
    if (!got_error || error_packet) {
      if (plan->statement->is_cross_node_join())
        handler->put_back_connection(dataspace, conn, true);
      else if (!plan->get_migrate_tool())
        handler->put_back_connection(dataspace, conn);
    } else {
      if (plan->statement->is_cross_node_join())
        handler->clean_dead_conn(&conn, dataspace, false);
      else if (!plan->get_migrate_tool())
        handler->clean_dead_conn(&conn, dataspace);
      else {
        conn->set_status(CONNECTION_STATUS_TO_DEAD);
      }
    }
    conn = NULL;
  }

  if (error_packet) {
    delete error_packet;
    error_packet = NULL;
  }
  if (new_stmt_for_shard) {
    new_stmt_for_shard->free_resource();
    delete new_stmt_for_shard;
    new_stmt_for_shard = NULL;
  }

  if (session->is_drop_current_schema()) {
    session->set_schema(NULL);
  }
}

static int check_ddl_need_retry(Session *session, DataSpace *space,
                                const char *sql) {
  string query_sql =
      "SELECT PROCESSLIST_STATE FROM PERFORMANCE_SCHEMA.THREADS WHERE "
      "PROCESSLIST_INFO=\"";
  string tmp_sql = find_and_replace_quota(sql);
  query_sql.append(tmp_sql.c_str()).append("\"");
  Connection *conn = NULL;
  TimeValue tv(backend_sql_net_timeout);
  bool need_recheck = true;
  while (need_recheck) {
    need_recheck = false;
    try {
      conn = space->get_connection(session);
      if (conn) {
        bool find_meta_lock = false;
        vector<string> result;
        conn->query_for_one_column(query_sql.c_str(), 0, &result, &tv, true);
        if (result.size() == 0) {
          conn->get_pool()->add_back_to_free(conn);
          return 1;
        }
        vector<string>::iterator it = result.begin();
        for (; it != result.end(); ++it) {
          string value = *it;
          if (value.find("metadata lock") != string::npos) {
            find_meta_lock = true;
            break;
          }
        }
        conn->get_pool()->add_back_to_free(conn);
        conn = NULL;
        if (find_meta_lock) return 0;
        need_recheck = true;  // wait ddl run finished
        sleep(5);
      }
    } catch (...) {
      if (conn) {
        conn->get_pool()->add_back_to_dead(conn);
      }
    }
  }
  return -1;
}

int MySQLModifyNode::svc() {
  status = EXECUTE_STATUS_FETCH_DATA;
  string *s = NULL;
  Packet *packet = NULL;
  string real_sql;
  bool off_sql_log_bin = false;
  size_t list_size = 0;
  bool need_retry = false;
  TimeValue tv(ddl_recv_timeout, 0);
  stmt_type sql_type = plan->statement->get_stmt_node()->type;
  if (run_ddl_retry &&
      (sql_type == STMT_DROP_TB || sql_type == STMT_RENAME_TABLE)) {
    need_retry = true;
    LOG_DEBUG("run ddl statement so can retry if failed\n");
  }
  int retry_count = 0;
retry:
  try {
    while (1) {
      if (ACE_Reactor::instance()->reactor_event_loop_done()) {
        LOG_ERROR(
            "MySQLModifyNode svc failed due to reactor_event_loop_done\n");
        throw Error(
            "MySQLModifyNode svc failed due to reactor_event_loop_done");
      }
      sql_mutex.acquire();
      if (!retry_count && sql_list.empty()) {
        LOG_DEBUG("Modify node %@ start to wait_children new sql.\n", this);
        cond_sql.wait();
      }
      if (!sql_list.empty() && !retry_count) {
        s = sql_list.front();
        sql_list.pop_front();
        sql = string(*s);
      }
      if (!retry_count) list_size = sql_list.size();
      sql_mutex.release();

      if (!session->is_keeping_connection()) {
        if (parent->is_finished()) {
          LOG_INFO("ModifyNode %@ exit cause parent finished.\n", this);

          if (plan->statement->is_cross_node_join()) {
            // Do nothing
          } else if (!plan->get_migrate_tool())
            conn = session->get_kept_connection(dataspace);
          else
            conn = plan->get_migrate_tool()->get_migrate_write_conn(this);
          if (conn) {
            if (plan->statement->is_cross_node_join())
              handler->clean_dead_conn(&conn, dataspace, false);
            else if (!plan->get_migrate_tool())
              handler->clean_dead_conn(&conn, dataspace);
            else {
              conn->set_status(CONNECTION_STATUS_TO_DEAD);
              conn = NULL;
            }
          }
          delete s;
          status = EXECUTE_STATUS_COMPLETE;
          return FINISHED;
        }
      }

      LOG_DEBUG("Modify node handle sql [%s] with [%d] sql append.\n",
                sql.c_str(), list_size);
      if (!strlen(sql.c_str())) {
        LOG_DEBUG("Modify node %@ finish.\n", this);
        delete s;
        s = NULL;
        break;
      }

      if (enable_xa_transaction &&
          plan->session->get_session_option("close_session_xa").int_val == 0) {
        real_sql.clear();
        real_sql += sql;
      }

      Packet exec_packet;
      MySQLQueryRequest query(sql.c_str());
      query.set_sql_replace_char(
          plan->session->get_query_sql_replace_null_char());
      query.pack(&exec_packet);
      delete s;
      s = NULL;
#ifdef DEBUG
      if (retry_count == 0) node_start_timing();
#endif
      stmt_type st_type = plan->statement->get_stmt_node()->type;
      bool is_ddl =
          (STMT_DDL_START < st_type && st_type < STMT_DDL_END) ? true : false;
      bool skip_keep_conn = false;
      if (need_retry) {
        int check_working_time = 0;
        while (dataspace->data_source->get_work_state() !=
                   DATASOURCE_STATE_WORKING &&
               check_working_time < 60) {
          sleep(1);
          check_working_time += 1;
        }
        if (check_working_time == 60) {
          conn = NULL;
          retry_count = 5;  // no need retry
          LOG_ERROR(
              "Fail to get an usable connection, because %s is "
              "not "
              "working\n",
              dataspace->get_name());
          throw Error(
              "Fail to get an usable connection, because space is not working");
        }
      }
      if (plan->get_migrate_tool()) {
        conn = plan->get_migrate_tool()->get_migrate_write_conn(this);
        conn->reset();
        handler->send_to_server(conn, &exec_packet);
      } else {
        if (plan->statement->is_cross_node_join()) {
          if (dataspace->get_data_source() &&
              dataspace->get_data_source()->get_master_server() &&
              dataspace->get_data_source()
                  ->get_master_server()
                  ->is_mgr_server() &&
              strstr(sql.c_str(), TMP_TABLE_SCHEMA) != NULL &&
              strstr(sql.c_str(), TMP_TABLE_NAME) != NULL) {
            off_sql_log_bin = true;
          }
          skip_keep_conn = true;
          conn = handler->send_to_server_retry(
              dataspace, &exec_packet, session->get_schema(), false, true, true,
              skip_keep_conn, off_sql_log_bin);
        } else if (is_ddl) {
          skip_keep_conn = true;
          if ((st_type == STMT_DROP_DB &&
               session->is_temp_table_set_contain_db(session->get_schema())) ||
              plan->statement->get_stmt_node()->is_create_or_drop_temp_table) {
            skip_keep_conn = false;
          }
          conn = handler->send_to_server_retry(
              dataspace, &exec_packet, session->get_schema(),
              session->is_read_only(), false, false, skip_keep_conn,
              off_sql_log_bin);
        } else {
          conn = handler->send_to_server_retry(dataspace, &exec_packet,
                                               session->get_schema(),
                                               session->is_read_only());
        }
      }
      const char *server_name = conn->get_server()->get_name();
      bool non_modified_conn = true;
      LOG_DEBUG("Modify node receiving result from server\n");
      packet = Backend::instance()->get_new_packet(row_packet_size);
#ifndef DBSCALE_TEST_DISABLE
      if (on_test_stmt) {
        Backend *bk = Backend::instance();
        dbscale_test_info *test_info = bk->get_dbscale_test_info();
        if (!strcasecmp(test_info->test_case_name.c_str(),
                        "auth_source_fail") &&
            !strcasecmp(test_info->test_case_operation.c_str(),
                        "fail_for_create_drop_db")) {
          if (dataspace == bk->get_auth_data_space()) {
            bk->set_dbscale_test_info("", "", "");
            throw Error("Fail to receive from auth.");
          }
        }
      }
#endif
      if (need_retry) {
        conn->set_need_kill_timeout_conn(false);
        handler->receive_from_server(conn, packet, &tv);
        conn->set_need_kill_timeout_conn(true);
      }

      else
        handler->receive_from_server(conn, packet);
#ifdef DEBUG
      node_end_timing();
#endif
      sql = "";
      if (driver->is_error_packet(packet)) {
        non_modified_conn = false;
        MySQLErrorResponse error(packet);
        error.unpack();
        if (retry_count && need_retry &&
            Backend::instance()->check_ddl_return_retry_ok(
                plan->statement->get_stmt_node()->type,
                plan->statement->get_stmt_node(), error.get_error_code())) {
          LOG_DEBUG("after retry, ddl statement run success \n");
          delete packet;
          packet = Backend::instance()->get_new_packet();
          MySQLOKResponse ok(0, 0);
          ok.pack(packet);
        } else {
          if (!plan->get_migrate_tool()) {
            LOG_DEBUG("Modify node %@ get an error packet %@, %d (%s) %s.\n",
                      this, packet, error.get_error_code(),
                      error.get_sqlstate(), error.get_error_message());
          } else {
            LOG_ERROR("Modify node %@ get an error packet %@, %d (%s) %s.\n",
                      this, packet, error.get_error_code(),
                      error.get_sqlstate(), error.get_error_message());
          }
          handle_error_packet(packet);
          packet = NULL;
          return FINISHED;
        }
      }
      if (driver->is_ok_packet(packet)) {
        handler->deal_autocommit_with_ok_eof_packet(packet);
        if (!plan->get_migrate_tool()) {
          if (support_show_warning)
            handle_warnings_OK_and_eof_packet(
                plan, packet, handler, dataspace, conn,
                plan->statement->is_cross_node_join());

          if (plan->statement->get_stmt_node()->type == STMT_DROP_TB) {
            table_link *table =
                plan->statement->get_stmt_node()->table_list_head;
            if (table) {  // only will have one table
              const char *schema_name = table->join->schema_name
                                            ? table->join->schema_name
                                            : plan->statement->get_schema();
              const char *table_name = table->join->table_name;
              if (conn->dec_tmp_tb_num(schema_name, table_name)) {
                plan->session->remove_temp_table_set(schema_name, table_name);
                plan->statement->get_stmt_node()->is_create_or_drop_temp_table =
                    true;
              }
            }
          }

          MySQLOKResponse ok(packet);
          ok.unpack();
          if (ok.get_affected_rows() > 0) {
            non_modified_conn = false;
          }
        } else {
          MySQLOKResponse ok(packet);
          ok.unpack();
          uint16_t warnings = ok.get_warnings();
          if (warnings) {
            LOG_ERROR("Modify node %@ get OK packet with %u warnings.\n", this,
                      (unsigned int)warnings);
            delete packet;
            packet = handler->get_error_packet(
                9002, "Migrate modify node get OK packet with warnings.", NULL);
            handle_error_packet(packet);
            packet = NULL;
            print_warning_infos(conn);
            return FINISHED;
          }
        }
      }

      {
        ACE_Guard<ACE_Thread_Mutex> guard(mutex);
        ready_rows->push_back(packet);
        packet = NULL;
        cond_notify.signal();
      }

      if (conn) {
        if (!plan->get_migrate_tool()) {
          if (plan->statement->is_cross_node_join()) {
            if (off_sql_log_bin) {
              if (conn->get_session_var_map_md5() !=
                  session->get_session_var_map_md5()) {
                conn->set_session_var(session->get_session_var_map());
              }
            }
          }
          handler->put_back_connection(dataspace, conn, skip_keep_conn);
        }
      }

      if (!plan->get_migrate_tool()) {
        record_xa_modify_sql(plan, session, dataspace, real_sql.c_str(),
                             non_modified_conn);
        if (!non_modified_conn) {
          session->record_xa_modified_conn(conn);
        }
        record_modify_server(plan, session, server_name,
                             dataspace->get_virtual_machine_id(),
                             non_modified_conn);
      }
      conn = NULL;

      LOG_DEBUG("Modify node %@ finish sql.\n", this);
    }
  } catch (exception &e) {
    LOG_ERROR("Modify node thread %@ got exception %s.\n", this, e.what());
    if (need_retry && retry_count < 5) {
      retry_count++;
      int ret = check_ddl_need_retry(session, dataspace, sql.c_str());
      try {
        if (ret == 0) {
          if (conn && conn->get_need_kill_timeout_connection())
            handler->kill_timeout_connection(conn, packet, true, &tv);
        } else if (ret == 1) {
          if (conn) {
            conn->get_pool()->add_back_to_dead(conn);
            conn = NULL;
          }
          if (packet) {
            delete packet;
            packet = NULL;
          }
          sleep(monitor_interval + 1);
          goto retry;
        } else {
          if (conn) {
            if (conn->get_need_kill_timeout_connection())
              handler->kill_timeout_connection(conn, packet, true, &tv);
            conn->get_pool()->add_back_to_dead(conn);
            conn = NULL;
          }
          if (packet) {
            delete packet;
            packet = NULL;
          }
          sleep(monitor_interval + 1);
          goto retry;
        }
      } catch (exception &kill_exception) {
        LOG_ERROR("try to kill timeout connection faild \n");
      }
    }

    if (conn) {
      if (plan->statement->is_cross_node_join())
        handler->clean_dead_conn(&conn, dataspace, false);
      else if (!plan->get_migrate_tool())
        handler->clean_dead_conn(&conn, dataspace);
      else {
        conn->reset_cluster_xa_session_before_to_dead();
        conn->set_status(CONNECTION_STATUS_TO_DEAD);
        conn = NULL;
      }
    }
    if (packet) delete packet;

    handle_error_packet(NULL);
    if (s) delete s;
    s = NULL;
    cond_notify.signal();
    return FINISHED;
  }
  mutex.acquire();
  status = EXECUTE_STATUS_COMPLETE;
  cond_notify.signal();
  mutex.release();
#ifdef DEBUG
  LOG_DEBUG("MySQLModifyNode %@ cost %d ms\n", this, node_cost_time);
#endif
  return FINISHED;
}

bool MySQLModifyNode::notify_parent() {
  int ret = false;
  Packet *packet = NULL;

  ACE_Guard<ACE_Thread_Mutex> guard(mutex);
  // check fetch node finished or get error
  if (is_finished() || got_error) {
    if (got_error) {
      throw_error_packet();
    }
    ret = false;
  } else {
    if (ready_rows->empty()) cond_notify.wait();

    if (got_error) {
      throw_error_packet();
    } else if (ready_rows->empty()) {  // the result set is empty
      ACE_ASSERT(is_finished());
      ret = false;
    } else {
      while (!ready_rows->empty()) {
        packet = ready_rows->front();
        ready_rows->pop_front();
        parent->add_row_packet(this, packet);
        ret = true;
      }
    }
  }

  return ret;
}

void MySQLModifyNode::add_sql_during_exec(const char *stmt_sql, size_t len) {
  add_sql(stmt_sql, len, true);
}

void MySQLModifyNode::add_sql(const char *stmt_sql, size_t len,
                              bool need_shard_parse) {
  string *s;
  if (dataspace && dataspace->get_virtual_machine_id() > 0) {
    string tmp;
    if (len)
      tmp.assign(stmt_sql, len);
    else
      tmp.assign(stmt_sql);
    if (tmp.length() > 0) {
      if (need_shard_parse && !new_stmt_for_shard) {
        Parser *parser = MySQLParser::instance();
        new_stmt_for_shard = parser->parse(
            tmp.c_str(), plan->statement->get_allow_dot_in_ident(), true, NULL,
            NULL, NULL, handler->get_session()->get_client_charset_type());
      }
      string new_sql_tmp;
      len = 0;
      adjust_virtual_machine_schema(
          dataspace->get_virtual_machine_id(), dataspace->get_partition_id(),
          tmp.c_str(), plan->statement->get_schema(),
          need_shard_parse ? new_stmt_for_shard->get_stmt_node()
                           : plan->statement->get_latest_stmt_node(),
          plan->statement->get_record_scan_all_table_spaces_map(), new_sql_tmp);
      s = new string(new_sql_tmp.c_str());
    } else
      s = new string(stmt_sql);
  } else {
    if (len)
      s = new string(stmt_sql, len);
    else
      s = new string(stmt_sql);
  }
  LOG_DEBUG("Modify node %@ add sql [%s].\n", this, s->c_str());

  try {
    ACE_Guard<ACE_Thread_Mutex> guard(sql_mutex);
    sql_list.push_back(s);
    cond_sql.signal();
  } catch (...) {
    cond_sql.signal();
    throw;
  }
}

/* class MySQLModifyLimitNode */
MySQLModifyLimitNode::MySQLModifyLimitNode(ExecutePlan *plan, record_scan *rs,
                                           PartitionedTable *table,
                                           vector<unsigned int> &par_ids,
                                           unsigned int limit, string &sql)
    : MySQLInnerNode(plan) {
  this->name = "MySQLModifyLimitNode";
  this->sql = sql;
  this->par_ids = par_ids;
  this->rs = rs;
  this->limit = limit;
  this->table = table;
  total_affect_rows = 0;
  total_warning_rows = 0;
}

void MySQLModifyLimitNode::modify_limit_in_sql(string &sql,
                                               unsigned int limit_num) const {
  // generate the limit context
  char new_limit_num[128];
  size_t len = sprintf(new_limit_num, "%u", limit_num);

  unsigned int start_pos, end_pos;
  get_limit_start_and_end(sql, start_pos, end_pos);

  string new_sql;
  new_sql.append(sql.c_str(), STR_LEN_INDEX(0, start_pos - 1));
  new_sql.append(new_limit_num, len);
  new_sql.append(sql.c_str() + end_pos);

  sql.swap(new_sql);
}

/*
  sql:select xxx from xxx limit_100_________where ...;(‘_’ means space)
                                |  |
                            start  end
*/
void MySQLModifyLimitNode::get_limit_start_and_end(
    string &sql, unsigned int &start_pos, unsigned int &end_pos) const {
  start_pos = 0;
  end_pos = sql.length();

  unsigned int start_search_pos = rs->limit_pos + 5;
  for (unsigned int i = start_search_pos; i < sql.length(); i++) {
    if (isdigit(sql[i])) {
      start_pos = i;
      break;
    }
  }

  for (unsigned int i = start_pos; i < sql.length(); i++) {
    if (!isdigit(sql[i])) {
      end_pos = i;
      break;
    }
  }
  return;
}

void MySQLModifyLimitNode::execute() {
  LinkedHashMap modify_nodes;
  while (status != EXECUTE_STATUS_COMPLETE) {
    switch (status) {
      case EXECUTE_STATUS_START: {
        create_modify_node(modify_nodes);
        init_row_map();
        status = EXECUTE_STATUS_FETCH_DATA;
        break;
      }

      case EXECUTE_STATUS_FETCH_DATA: {
        generate_new_sql(modify_nodes);
        children_execute();
        if (node_can_swap && plan->plan_can_swap()) {
          handle_swap_connections();
          return;
        }
        status = EXECUTE_STATUS_WAIT;
      }

      case EXECUTE_STATUS_WAIT: {
        LOG_DEBUG("MySQLModifyLimitNode wait\n");
        try {
          wait_children();
        } catch (ErrorPacketException &e) {
          children_modify_end();
          LOG_DEBUG("MySQLModifyLimitNode wait error \n");
          status = EXECUTE_STATUS_COMPLETE;
          throw ErrorPacketException(
              "get an error packet during the modify node\n");
        }
        break;
      }

      case EXECUTE_STATUS_HANDLE: {
        LOG_DEBUG("MySQLModifyLimitNode handle\n");
        handle_children_affect_rows(modify_nodes);
        break;
      }

      case EXECUTE_STATUS_BEFORE_COMPLETE:
        rebuild_ok_packet();
        status = EXECUTE_STATUS_COMPLETE;

      case EXECUTE_STATUS_COMPLETE:
#ifdef DEBUG
        LOG_DEBUG("MySQLModifyLimitNode ok\n");
#endif
        break;

      default:
        ACE_ASSERT(0);
        break;
    }
  }
}

void MySQLModifyLimitNode::generate_new_sql(LinkedHashMap &modify_nodes) {
  unsigned int each_limit_num = limit / modify_nodes.size();
  LinkedHashMap::iterator iter = modify_nodes.begin();
  for (size_t i = 0; iter != modify_nodes.end(); iter++, i++) {
    MySQLModifyNode *tmp