 = (*iter).first;
    string &exec_sql = modify_sqls[tmp->dataspace];
    if (i == modify_nodes.size() - 1) {
      unsigned int limit_num = each_limit_num + limit % modify_nodes.size();
      (*iter).second = limit_num;
      modify_limit_in_sql(exec_sql, limit_num);
    } else {
      (*iter).second = each_limit_num;
      modify_limit_in_sql(exec_sql, each_limit_num);
    }

    tmp->add_sql(exec_sql.c_str(), exec_sql.length());
  }
}

void MySQLModifyLimitNode::handle_children_affect_rows(
    LinkedHashMap &modify_nodes) {
  handle_response_packet(modify_nodes);
  if (!modify_nodes.empty()) {
    generate_new_sql(modify_nodes);
  } else
    children_modify_end();
  status = EXECUTE_STATUS_WAIT;
  return;
}

void MySQLModifyLimitNode::handle_response_packet(LinkedHashMap &modify_nodes) {
  LinkedHashMap::iterator map_iter = modify_nodes.begin();
  bool all_finish = true;
  for (; map_iter != modify_nodes.end(); map_iter++) {
    if ((*map_iter).second != 0) {
      all_finish = false;
      break;
    }
  }

  if (all_finish == true) {
    map_iter = modify_nodes.begin();
    for (; map_iter != modify_nodes.end();) {
      MySQLModifyNode *tmp = (MySQLModifyNode *)((map_iter++)->first);
      modify_nodes.erase(tmp);
      child_add_sql(tmp, "", 0);
    }
    return;
  } else {
    map<ExecuteNode *,
        AllocList<Packet *, Session *, StaticAllocator<Packet *> > *>::iterator
        iter;
    for (iter = row_map.begin(); iter != row_map.end(); iter++) {
      list<Packet *, StaticAllocator<Packet *> > *pack_list = (*iter).second;
      if (pack_list->empty()) {
        MySQLModifyNode *tmp = (MySQLModifyNode *)((*iter).first);
        child_add_sql(tmp, "", 0);
        continue;
      }
      Packet *packet = pack_list->front();
      pack_list->pop_front();
      if (driver->is_ok_packet(packet)) {
        MySQLOKResponse ok(packet);
        ok.unpack();
        uint16_t warnings = ok.get_warnings();
        if (warnings) {
          LOG_ERROR("Modify node %@ get OK packet with %u warnings.\n", this,
                    (unsigned int)warnings);
        }
        uint64_t affect_rows = ok.get_affected_rows();
        limit -= affect_rows;
        total_affect_rows += affect_rows;
        total_warning_rows += warnings;

        MySQLModifyNode *tmp = (MySQLModifyNode *)((*iter).first);
        unsigned int count;
        if (modify_nodes.find(tmp, count)) {
          if (affect_rows < (uint64_t)(count)) {
            modify_nodes.erase(tmp);
            child_add_sql(tmp, "", 0);
          }
        }
        delete packet;
      }
    }
  }
}

void MySQLModifyLimitNode::clean() {
  MySQLInnerNode::clean();
  while (!children.empty()) {
    MySQLExecuteNode *free_node = children.front();
    children.pop_front();
    free_node->clean();
    delete free_node;
  }
}

void MySQLModifyLimitNode::create_modify_node(LinkedHashMap &modify_nodes) {
  for (size_t i = 0; i < par_ids.size(); i++) {
    DataSpace *ds = table_get_par_dataspace(table, par_ids[i]);
    MySQLModifyNode *node = new MySQLModifyNode(plan, ds);
    modify_nodes.insert(node, 0);
    string adjust_sql = sql;
    table_sql_for_par(table, par_ids[i], adjust_sql);
    modify_sqls[ds] = adjust_sql;
    add_child(node);
  }
}

DataSpace *MySQLModifyLimitNode::table_get_par_dataspace(
    PartitionedTable *par_table, unsigned int id) const {
  return par_table->get_partition(id);
}

void MySQLModifyLimitNode::table_sql_for_par(PartitionedTable *par_table,
                                             unsigned int id,
                                             string &sql) const {
  ACE_UNUSED_ARG(id);
  sql = plan->statement->adjust_stmt_sql_for_shard(par_table, sql.c_str());
}

void MySQLModifyLimitNode::children_modify_end() {
  list<MySQLExecuteNode *>::iterator it;
  for (it = children.begin(); it != children.end(); it++) {
    child_add_sql((MySQLModifyNode *)(*it), "", 0);
  }
}

void MySQLModifyLimitNode::rebuild_ok_packet() {
  MySQLOKResponse ok(total_affect_rows, total_warning_rows);
  Packet *ok_packet = Backend::instance()->get_new_packet(row_packet_size);
  ok.pack(ok_packet);
  handler->deal_autocommit_with_ok_eof_packet(ok_packet);
  try {
    handler->send_to_client(ok_packet);
    delete ok_packet;
  } catch (exception &e) {
    delete ok_packet;
    throw e;
  }
}

/* class   MySQLNormalMergeNode */

MySQLNormalMergeNode::MySQLNormalMergeNode(ExecutePlan *plan,
                                           const char *modify_sql,
                                           vector<ExecuteNode *> *nodes)
    : MySQLInnerNode(plan),
      modify_sql(modify_sql),
      init_column_flag(false),
      select_complete_handled(false) {
  this->name = "MySQLNormalMergeNode";
  field_num = 0;
  if (nodes) {
    vector<ExecuteNode *>::iterator it = nodes->begin();
    for (; it != nodes->end(); it++) {
      this->add_select_child(*it);
    }
  }
  max_sql_len = MAX_PACKET_SIZE - PACKET_HEADER_SIZE - 4096;
  // this node don't need to control the RAM.
  plan->session->set_has_fetch_node(false);
  replace_set_value = false;
  generated_sql_length = insert_select_sql_size - PACKET_HEADER_SIZE;
}

void MySQLNormalMergeNode::clean() {
  if (!select_complete_handled && !session->is_in_explain())
    handle_select_complete();
  MySQLExecuteNode *free_node;
  Packet *packet = NULL;
  while (!select_node_children.empty()) {
    free_node = select_node_children.front();
    select_node_children.pop_front();

    // clean remaining rows
    if (row_map.count(free_node)) {
      while (!row_map[free_node]->empty()) {
        packet = row_map[free_node]->front();
        row_map[free_node]->pop_front();
        delete packet;
      }
      delete row_map[free_node];
      row_map[free_node] = NULL;
    }

    free_node->clean();
    delete free_node;
  }
  // we should ensure that MySQLNormalMergeNode::clean should handle the fetch
  // node first, and ensure the fetch node has free the resource, then handle
  // the clean of modify node.
  MySQLInnerNode::clean();

  while (!modify_node_children_for_explain_stmt.empty()) {
    free_node = modify_node_children_for_explain_stmt.front();
    modify_node_children_for_explain_stmt.pop_front();
    free_node->clean();
    delete free_node;
  }
}

void MySQLNormalMergeNode::select_node_children_execute() {
  list<MySQLExecuteNode *>::iterator it;
  for (it = select_node_children.begin(); it != select_node_children.end();
       ++it) {
    (*it)->execute();
    (*it)->start_thread();
  }
  it = select_node_children.begin();
  if (strcmp((*it)->get_executenode_name(), "MySQLSparkNode")) {
    set_select_node_children_thread_status_start();
    plan->start_all_bthread();
  }
}

void MySQLNormalMergeNode::set_select_node_children_thread_status_start() {
  list<MySQLExecuteNode *>::iterator it;
  for (it = select_node_children.begin(); it != select_node_children.end();
       ++it) {
    (*it)->set_thread_status_started();
  }
}

void MySQLNormalMergeNode::wait_children_select_node() {
  /*Check the modify children nodes's status, if they got error, stop the
   * processing.*/
  list<MySQLExecuteNode *>::iterator it;
  for (it = children.begin(); it != children.end(); it++) {
    if ((*it)->status == EXECUTE_STATUS_COMPLETE) {
      /*If the status is EXECUTE_STATUS_COMPLETE, this modify node must
       * goterror, so invoke notify_parent() to throw the exception.*/
      (*it)->notify_parent();
    }
  }
  if (plan->session->get_keep_conn()) {
#ifdef DEBUG
    if (max_mergenode_ready_rows_size && received_packet_num > 0)
      ACE_ASSERT(max_mergenode_buffer_rows > 0);
#endif
    if (max_mergenode_ready_rows_size &&
        max_mergenode_buffer_rows <= received_packet_num &&
        received_packet_num > 0) {
      LOG_ERROR(
          "MySQLNormalMergeNode in kept_conn state, receive [%d] packets, "
          "larger than config size [%d],"
          "plz config option 'max-mergenode-ready-rows-size'\n",
          received_packet_num, max_mergenode_ready_rows_size);
      throw Error(
          "MySQLNormalMergeNode receive packets larger than config size.");
    }
  }
  bool ready_flag = false;
  unsigned int finished_child = 0;
  while (!ready_flag) {
    finished_child = 0;
    for (it = select_node_children.begin(); it != select_node_children.end();
         ++it) {
      if ((*it)->notify_parent()) {
        ready_flag = true;
        status = EXECUTE_STATUS_SELECT_HANDLE;
      } else if ((*it)->is_finished()) {
        finished_child++;
      }
    }

    /* check if all chilren are finishd */
    if (!ready_flag && finished_child == select_node_children.size()) {
      status = EXECUTE_STATUS_SELECT_COMPLETE;
      break;
    }
  }
}

bool is_column_type_present_as_str(MySQLColumnType type) {
  switch (type) {
    case MYSQL_TYPE_TIMESTAMP:
    case MYSQL_TYPE_DATE:
    case MYSQL_TYPE_TIME:
    case MYSQL_TYPE_DATETIME:
    case MYSQL_TYPE_YEAR:
    case MYSQL_TYPE_NEWDATE:
    case MYSQL_TYPE_VARCHAR:
    case MYSQL_TYPE_ENUM:
    case MYSQL_TYPE_SET:
    case MYSQL_TYPE_TINY_BLOB:
    case MYSQL_TYPE_MEDIUM_BLOB:
    case MYSQL_TYPE_LONG_BLOB:
    case MYSQL_TYPE_BLOB:
    case MYSQL_TYPE_VAR_STRING:
    case MYSQL_TYPE_STRING:
    case MYSQL_TYPE_JSON:
      return true;
    default:
      return false;
  }
  return false;
}

void MySQLNormalMergeNode::init_column_as_str() {
  if (!init_column_flag) {
    list<Packet *> *field_packets =
        select_node_children.front()->get_field_packets();
    list<Packet *>::iterator it_field;
    for (it_field = field_packets->begin(); it_field != field_packets->end();
         it_field++) {
      MySQLColumnResponse col_resp(*it_field);
      col_resp.unpack();
      column_as_str.push_back(
          is_column_type_present_as_str(col_resp.get_column_type()));
    }

    LOG_DEBUG(
        "MySQLNormalMergeNode Init column to check as_str :"
        " columns = %d\n",
        column_as_str.size());
    init_column_flag = true;
  }
}

void MySQLNormalMergeNode::execute() {
  try {
    while (status != EXECUTE_STATUS_COMPLETE) {
      // 1. execute select_node_children, 2. wait_children select node
      // children, 3. assemble one modify sql, 4. children add modify sql, 5.
      // execute children;
      //
      // loop 1->5 until select_node_children all finish
      //
      // 6. wait_children children 7. return ok packets to parent node
      //
      // loop 6->7 until children all finish and all packets are passed

      switch (status) {
        case EXECUTE_STATUS_START: {
          list<MySQLExecuteNode *>::iterator it;
          init_row_map();
          for (it = select_node_children.begin();
               it != select_node_children.end(); ++it) {
            row_map[*it] = new AllocList<Packet *, Session *,
                                         StaticAllocator<Packet *> >();
            // TODO: add init value for row_map_size and
            // turn need_restrict_row_map_size on when need restrict row_map's
            // size.
            row_map[*it]->set_session(plan->session);
          }

          status = EXECUTE_STATUS_SELECT_FETCH_DATA;
          break;
        }
        case EXECUTE_STATUS_SELECT_FETCH_DATA: {
          select_node_children_execute();
          status = EXECUTE_STATUS_SELECT_WAIT;
        }
        case EXECUTE_STATUS_SELECT_WAIT: {
          try {
            wait_children_select_node();
          } catch (ExecuteNodeError &e) {
            children_modify_end();
            LOG_ERROR(
                "MySQLNormalMergeNode wait_children_select_node get error "
                "[%s]\n",
                e.what());
            string msg =
                "MySQLNormalMergeNode wait_children_select_node get error ";
            msg += e.what();
            record_migrate_error_message(plan, msg);
            status = EXECUTE_STATUS_COMPLETE;
            throw e;
          }
          break;
        }
        case EXECUTE_STATUS_SELECT_HANDLE: {
          // for update set, wait for all fetch node finished
          if (!replace_set_value) {
            init_column_as_str();
            handle_select_node_children();
          } else {
            for (auto it = select_node_children.begin();
                 it != select_node_children.end(); ++it) {
              if (row_map[*it]->size() > 1) {
                LOG_ERROR("Subquery returns more than 1 row\n");
                throw ExecuteNodeError("Subquery returns more than 1 row.");
              }
            }
          }
#ifndef DBSCALE_TEST_DISABLE
          /*just for test coverage*/
          Backend *bk = Backend::instance();
          dbscale_test_info *test_info = bk->get_dbscale_test_info();
          if (!strcasecmp(test_info->test_case_name.c_str(),
                          "insert_select_test") &&
              !strcasecmp(test_info->test_case_operation.c_str(),
                          "handle_select_get_error")) {
            throw Error("handle_select_get_error");
          }
#endif
          if (!replace_set_value) children_execute();
          status = EXECUTE_STATUS_SELECT_FETCH_DATA;
          break;
        }
        case EXECUTE_STATUS_SELECT_COMPLETE:
          LOG_DEBUG("Node %@ finish the select part.\n", this);
          if (replace_set_value) {
            init_column_as_str();
            handle_select_node_children();
            children_execute();
          }
          handle_select_complete();
          select_complete_handled = true;
          status = EXECUTE_STATUS_WAIT;
        case EXECUTE_STATUS_FETCH_DATA:
          status = EXECUTE_STATUS_WAIT;
        case EXECUTE_STATUS_WAIT:
          try {
            wait_children();
          } catch (ExecuteNodeError &e) {
            children_modify_end();
            LOG_ERROR("MySQLNormalMergeNode wait_children get error [%s]\n",
                      e.what());
            status = EXECUTE_STATUS_COMPLETE;
            throw e;
          }
          break;
        case EXECUTE_STATUS_HANDLE:
#ifdef DEBUG
          node_start_timing();
#endif
          handle_children();
#ifdef DEBUG
          node_end_timing();
#endif
          if (ready_rows->empty() && all_children_finished) {
            LOG_DEBUG(
                "Modify merge node read_rows is 0 and all children "
                "finished.\n");
            status = EXECUTE_STATUS_COMPLETE;
          } else {
            status = EXECUTE_STATUS_FETCH_DATA;
            LOG_DEBUG("Modify merge node gets ready rows %d.\n",
                      ready_rows->size());
            return;
          }
          break;
        case EXECUTE_STATUS_BEFORE_COMPLETE:
          status = EXECUTE_STATUS_COMPLETE;
        case EXECUTE_STATUS_COMPLETE:
#ifdef DEBUG
          LOG_DEBUG("MySQLNormalMergeNode %@ cost %d ms\n", this,
                    node_cost_time);
#endif
          break;

        default:
          break;
      }
    }
  } catch (exception &e) {
    status = EXECUTE_STATUS_COMPLETE;
    LOG_ERROR("MySQLNormalMergeNode execute get error [%s]\n", e.what());
    string err("MySQLNormalMergeNode execute get error:");
    err.append(e.what());
    record_migrate_error_message(plan, err.c_str());
    throw;
  }
}

void MySQLNormalMergeNode::handle_children() {
  list<MySQLExecuteNode *>::iterator it;
  for (it = children.begin(); it != children.end(); ++it) {
    if (!row_map[*it]->empty()) {
      handle_child(*it);
    }
  }
}

void MySQLNormalMergeNode::handle_child(MySQLExecuteNode *child) {
  Packet *packet = NULL;
  while (!row_map[child]->empty()) {
    packet = row_map[child]->front();
    row_map[child]->pop_front();
    ready_rows->push_back(packet);
  }
}

Packet *MySQLNormalMergeNode::get_error_packet() {
  list<MySQLExecuteNode *>::iterator it;
  for (it = children.begin(); it != children.end(); ++it) {
    if ((*it)->get_error_packet()) {
      return (*it)->get_error_packet();
    }
  }

  for (it = select_node_children.begin(); it != select_node_children.end();
       ++it) {
    if ((*it)->get_error_packet()) {
      return (*it)->get_error_packet();
    }
  }

  return NULL;
}

void MySQLNormalMergeNode::rotate_sql(MySQLModifyNode *node, string *sql,
                                      string *added_sql) {
  child_add_sql(node, sql->c_str(), get_sql_length(sql));
  sql->clear();
  sql->append(modify_sql.c_str());
  if (added_sql) sql->append(added_sql->c_str());
}

void MySQLNormalMergeNode::append_field_to_sql(string *sql, int field_pos,
                                               MySQLRowResponse *row,
                                               bool handle_hex) {
  uint64_t field_length = (uint64_t)0;
  const char *field = NULL;
  bool is_field_as_str = false;
  bool is_null = false;
  is_null = row->field_is_null(field_pos);
  if (!is_null) {
    field = row->get_str(field_pos, &field_length);
    is_field_as_str = column_as_str[field_pos];
    add_str_before_field_value(sql, is_null);

    if (handle_hex) {
      sql->append("0x");
      sql->append(field, field_length);
    } else {
      if (is_field_as_str) {
        sql->append("'");
        string tmp_str(field, field_length);
        CharsetType ctype = session->get_client_charset_type();
        deal_with_str_column_value(&tmp_str, ctype);
        sql->append(tmp_str.c_str());
        sql->append("'");
      } else
        sql->append(field, field_length);
    }
  } else {
    add_str_before_field_value(sql, is_null);
    sql->append("NULL");
  }
}

/* class MySQLModifySelectNode */

MySQLModifySelectNode::MySQLModifySelectNode(
    ExecutePlan *plan, const char *modify_sql, vector<string *> *columns,
    vector<ExecuteNode *> *nodes, bool execute_quick, bool is_replace_set_value)
    : MySQLNormalMergeNode(plan, modify_sql, nodes),
      columns(columns),
      execute_quick(execute_quick) {
  this->name = "MySQLModifySelectNode";
  execute_sql.append(this->modify_sql.c_str());
  migrate_iter = children.begin();
  replace_set_value = is_replace_set_value;
}

void MySQLModifySelectNode::clean() {
  MySQLNormalMergeNode::clean();
  vector<string *>::iterator it = columns->begin();
  for (; it != columns->end(); it++) {
    delete *it;
  }
  columns->clear();
  delete columns;
}

void MySQLModifySelectNode::handle_select_node_child(MySQLExecuteNode *child,
                                                     string *sql) {
  LOG_DEBUG("UpdateSelectNode %@ start to assemble modify sql.\n", this);
  Packet *packet = NULL;

  if (replace_set_value) {
    string replace_value;
    if (column_as_str.size() > 1) {
      LOG_ERROR("Operand should contain 1 column\n");
      throw ExecuteNodeError("Operand should contain 1 column(s)");
    }
    if (row_map[child]->size() > 1) {
      LOG_ERROR("Subquery returns more than 1 row\n");
      throw ExecuteNodeError("Subquery returns more than 1 row.");
    } else if (row_map[child]->empty()) {
      replace_value = "= NULL";
    } else {
      packet = row_map[child]->front();
      row_map[child]->pop_front();
      MySQLRowResponse row(packet);
      bool is_null = row.field_is_null(0);
      if (is_null)
        replace_value = "= NULL";
      else
        append_field_to_sql(&replace_value, 0, &row);
      delete packet;
    }
    size_t pos = sql->find(DBSCALE_TMP_COLUMN_VALUE);
    if (pos != string::npos) {
      sql->replace(pos, strlen(DBSCALE_TMP_COLUMN_VALUE), replace_value);
    }
    return;
  }
  while (!row_map[child]->empty()) {
    packet = row_map[child]->front();
    row_map[child]->pop_front();
    MySQLRowResponse row(packet);
    unsigned int i = 0;
    string tmp(" ");
    tmp.append("(");
    tmp.append(columns->at(i)->c_str());
    append_field_to_sql(&tmp, i, &row);
    i++;
    for (; i < field_num; i++) {
      tmp.append(" and ");
      tmp.append(columns->at(i)->c_str());
      append_field_to_sql(&tmp, i, &row);
    }
    tmp.append(") OR");
    delete packet;
    if (!is_sql_len_valid(sql->length() + tmp.length())) {
      if (execute_quick && is_sql_len_valid(tmp.length()))
        rotate_modify_sql(sql, &tmp);
      else {
        LOG_ERROR(
            "Generated temporary SQL for %s is too large, dbscale unsupport"
            "currently.\n",
            plan->statement->get_sql());
        throw ExecuteNodeError(
            "Unsupport sql for dbscale, due to too large temporary SQL, \
                               please check the log for detail.");
      }
    } else
      sql->append(tmp.c_str());
  }
}

void MySQLModifySelectNode::rotate_modify_sql(string *sql, string *added_sql) {
  if (plan->get_migrate_tool()) {
    MySQLModifyNode *node = get_next_migrate_node();
    rotate_sql(node, sql, added_sql);
  } else {
    rotate_sql((MySQLModifyNode *)children.front(), sql, added_sql);
  }
}
MySQLModifyNode *MySQLModifySelectNode::get_next_migrate_node() {
  migrate_iter++;
  if (migrate_iter == children.end()) {
    migrate_iter = children.begin();
  }
  return (MySQLModifyNode *)*migrate_iter;
}

void MySQLModifySelectNode::handle_select_node_children() {
  if (!field_num) get_filed_num();

  list<MySQLExecuteNode *>::iterator it;
  for (it = select_node_children.begin(); it != select_node_children.end();
       ++it) {
    if (!row_map[*it]->empty() || replace_set_value)
      handle_select_node_child(*it, &execute_sql);
  }
  if (execute_quick && (execute_sql.size() > modify_sql.size())) {
    rotate_modify_sql(&execute_sql, NULL);
  }
  LOG_DEBUG("UpdateSelectNode %@ assemble sql [%s].\n", this,
            execute_sql.c_str());
}

/* class MySQLInsertSelectNode */

MySQLInsertSelectNode::MySQLInsertSelectNode(ExecutePlan *plan,
                                             const char *modify_sql,
                                             vector<ExecuteNode *> *nodes)
    : MySQLNormalMergeNode(plan, modify_sql, nodes) {
  this->name = "MySQLInsertSelectNode";
  modify_sql_exe.clear();
  modify_sql_exe.append(modify_sql);
  migrate_iter = children.begin();
  cross_join_max_rows = (uint64_t)(
      session->get_session_option("max_cross_join_moved_rows").ulong_val);
  select_row_num = 0;
}

void MySQLInsertSelectNode::handle_select_node_child(MySQLExecuteNode *child,
                                                     string *sql) {
  Packet *packet = NULL;
  select_row_num += row_map[child]->size();
  if (plan->statement->is_cross_node_join() &&
      select_row_num > cross_join_max_rows) {
    status = EXECUTE_STATUS_COMPLETE;
    LOG_ERROR(
        "Reach the max rows of [%u] for cross node join max moved rows.\n",
        select_row_num);
    throw ExecuteNodeError(
        "Reach the max row number of cross node join max moved rows.");
  }
  set<int> &hex_pos = plan->statement->get_hex_pos();
  while (!row_map[child]->empty()) {
    packet = row_map[child]->front();
    row_map[child]->pop_front();
    MySQLRowResponse row(packet);
    unsigned int i = 0;
    string tmp("");
    tmp.append("(");
    append_field_to_sql(&tmp, i, &row, hex_pos.count(i));
    i++;
    for (; i < field_num; i++) {
      tmp.append(",");
      append_field_to_sql(&tmp, i, &row, hex_pos.count(i));
    }
    tmp.append("),");
    delete packet;
    if (!is_sql_len_valid(sql->length() + tmp.length()))
      if (is_sql_len_valid(tmp.length())) {
        rotate_insert_sql(sql, &tmp);
      } else {
        LOG_ERROR(
            "Generated temporary SQL for %s is too large, dbscale unsupport"
            " currently.\n",
            plan->statement->get_sql());
        throw ExecuteNodeError(
            "Unsupport sql for dbscale,  due to too large temporary SQL, \
                               please check the log for detail.");
      }
    else
      sql->append(tmp.c_str());
  }
}

void MySQLInsertSelectNode::rotate_insert_sql(string *sql, string *added_sql) {
  if (plan->get_migrate_tool()) {
    MySQLModifyNode *node = get_next_migrate_node();
    rotate_sql(node, sql, added_sql);
  } else {
    rotate_sql((MySQLModifyNode *)children.front(), sql, added_sql);
  }
}
MySQLModifyNode *MySQLInsertSelectNode::get_next_migrate_node() {
  migrate_iter++;
  if (migrate_iter == children.end()) {
    migrate_iter = children.begin();
  }
  return (MySQLModifyNode *)*migrate_iter;
}
void MySQLInsertSelectNode::handle_select_node_children() {
  LOG_DEBUG("InsertSelectNode %@ start to assemble modify sql.\n", this);

  if (!field_num) get_filed_num();

  list<MySQLExecuteNode *>::iterator it;
  for (it = select_node_children.begin(); it != select_node_children.end();
       ++it) {
    if (!row_map[*it]->empty()) handle_select_node_child(*it, &modify_sql_exe);
  }
  if (is_sql_len_enough(modify_sql_exe.length()))
    rotate_insert_sql(&modify_sql_exe, NULL);
  LOG_DEBUG("InsertSelectNode %@ assemble sql [%s].\n", this,
            modify_sql_exe.c_str());
}

/* class MySQLPartitionMergeNode*/

MySQLPartitionMergeNode::MySQLPartitionMergeNode(ExecutePlan *plan,
                                                 const char *modify_sql,
                                                 vector<ExecuteNode *> *nodes,
                                                 PartitionedTable *par_table,
                                                 PartitionMethod *method)
    : MySQLNormalMergeNode(plan, modify_sql, nodes),
      par_table(par_table),
      method(method) {
  this->name = "MySQLPartitionMergeNode";
  if (plan->session->is_in_explain()) {
    unsigned int partition_num = par_table->get_real_partition_num();
    for (unsigned int i = 0; i < partition_num; i++) {
      DataSpace *space = par_table->get_partition(i);
      MySQLModifyNode *modify = new MySQLModifyNode(this->plan, space);
      add_modify_child_for_explain_stmt(modify);
    }
  }
}

unsigned int MySQLPartitionMergeNode::get_par_id_one_row(
    MySQLRowResponse *row) {
  vector<const char *> keys;
  map<unsigned int, string> key_value_string;
  uint64_t field_length = (uint64_t)0;
  const char *field = NULL;
  vector<unsigned int>::iterator it;
  for (it = key_pos_vec.begin(); it != key_pos_vec.end(); it++) {
    field = row->get_str(*it, &field_length);
    key_value_string[*it].clear();
    key_value_string[*it].append(field, field_length);
    keys.push_back(key_value_string[*it].c_str());
  }

  string sql_replace_char = plan->session->get_query_sql_replace_null_char();
  return method->get_partition_id(&keys, sql_replace_char);
}

unsigned int MySQLPartitionMergeNode::get_par_id_one_row(
    MySQLRowResponse *row, int auto_inc_key_pos, int64_t curr_auto_inc_val) {
  vector<const char *> keys;
  map<unsigned int, string> key_value_string;
  uint64_t field_length = (uint64_t)0;
  const char *field = NULL;
  vector<unsigned int>::iterator it;
  for (it = key_pos_vec.begin(); it != key_pos_vec.end(); it++) {
    if ((int)*it == auto_inc_key_pos || *it == field_num) {
      // *it == field_num means has auto_increment field but not specified in
      // column_list.
      char auto_inc_str_val[21];
      snprintf(auto_inc_str_val, sizeof(auto_inc_str_val), "%ld",
               curr_auto_inc_val);
      key_value_string[*it].clear();
      key_value_string[*it].append(auto_inc_str_val, strlen(auto_inc_str_val));
      keys.push_back(key_value_string[*it].c_str());
    } else {
      field = row->get_str(*it, &field_length);
      key_value_string[*it].clear();
      key_value_string[*it].append(field, field_length);
      keys.push_back(key_value_string[*it].c_str());
    }
  }

  string sql_replace_char = plan->session->get_query_sql_replace_null_char();
  return method->get_partition_id(&keys, sql_replace_char);
}

void MySQLPartitionMergeNode::children_add_sql() {
  map<unsigned int, MySQLModifyNode *>::iterator it;
  for (it = modify_node_map.begin(); it != modify_node_map.end(); it++) {
    unsigned int id = it->first;
    if (node_sql_map[id].length() > modify_sql.length()) {
      MySQLModifyNode *node = it->second;
      child_add_sql(node, node_sql_map[id].c_str(),
                    get_sql_length(&node_sql_map[id]));
      node_sql_map[id].clear();
      node_sql_map[id].append(modify_sql.c_str());
    }
  }
}

/* MySQLPartitionModifySelectNode */
MySQLPartitionModifySelectNode::MySQLPartitionModifySelectNode(
    ExecutePlan *plan, const char *modify_sql, vector<ExecuteNode *> *nodes,
    PartitionedTable *par_table, PartitionMethod *method,
    vector<string *> *columns, bool execute_quick)
    : MySQLPartitionMergeNode(plan, modify_sql, nodes, par_table, method),
      columns(columns),
      execute_quick(execute_quick) {
  this->name = "MySQLPartitionModifySelectNode";
  fulfill_key_pos_one_row(&key_pos_vec);
}

void MySQLPartitionModifySelectNode::handle_select_node_child(
    MySQLExecuteNode *child) {
  Packet *packet = NULL;
  unsigned int par_id;
  unsigned int i;
  string *sql;

  while (!row_map[child]->empty()) {
    packet = row_map[child]->front();
    row_map[child]->pop_front();
    MySQLRowResponse row(packet);
    par_id = get_par_id_one_row(&row);
    par_id = par_table->get_real_par_id_from_virtual_id(par_id);
    get_partiton_modify_node(par_id);
    sql = &node_sql_map[par_id];
    string tmp("");
    i = 0;
    tmp.append(" ");

    tmp.append("(");
    tmp.append(columns->at(i)->c_str());
    append_field_to_sql(&tmp, i, &row);
    i++;
    for (; i < field_num; i++) {
      tmp.append(" and ");
      tmp.append(columns->at(i)->c_str());
      append_field_to_sql(&tmp, i, &row);
    }
    tmp.append(") OR");
    delete packet;
    if (!is_sql_len_valid(sql->length() + tmp.length())) {
      if (execute_quick && is_sql_len_valid(tmp.length()))
        rotate_sql(modify_node_map[par_id], sql, &tmp);
      else {
        LOG_ERROR(
            "Generated temporary SQL for %s is too large, dbscale unsupport"
            " currently.\n",
            plan->statement->get_sql());
        throw ExecuteNodeError(
            "Unsupport sql for dbscale,  due to too large temporary SQL, \
                               please check the log for detail.");
      }
    } else
      sql->append(tmp.c_str());
  }
}

void MySQLPartitionModifySelectNode::handle_select_node_children() {
  if (!field_num) get_filed_num();

  list<MySQLExecuteNode *>::iterator it;
  for (it = select_node_children.begin(); it != select_node_children.end();
       ++it) {
    if (!row_map[*it]->empty()) handle_select_node_child(*it);
  }

  if (execute_quick) {
    children_add_sql();
  }
}

/* MySQLPartitionInsertSelectNode */
MySQLPartitionInsertSelectNode::MySQLPartitionInsertSelectNode(
    ExecutePlan *plan, const char *modify_sql, vector<ExecuteNode *> *nodes,
    PartitionedTable *par_table, PartitionMethod *method,
    vector<unsigned int> &key_pos, const char *schema_name,
    const char *table_name, bool is_duplicated)
    : MySQLPartitionMergeNode(plan, modify_sql, nodes, par_table, method),
      is_duplicated(is_duplicated) {
  this->name = "MySQLPartitionInsertSelectNode";
  key_pos_vec = key_pos;
  schema_name_insert.append(schema_name);
  table_name_insert.append(table_name);
  auto_increment_key_pos = plan->statement->get_auto_increment_key_pos();
  need_update_last_insert_id = false;
  need_auto_inc_lock = true;
  stmt_lock = NULL;

  has_init_duplicated_modify_node = false;
  cross_join_max_rows = (uint64_t)(
      session->get_session_option("max_cross_join_moved_rows").ulong_val);
  select_row_num = 0;
}

void MySQLPartitionInsertSelectNode::auto_inc_prepare() {
  if (plan->statement->get_auto_inc_status() != NO_AUTO_INC_FIELD) {
    stmt_lock = par_table->get_stmt_autoinc_lock(
        plan->statement->get_full_table_name());
    if (stmt_lock) stmt_lock->acquire();
    int enable_last_insert_id_session =
        session->get_session_option("enable_last_insert_id").int_val;
    if (enable_last_insert_id_session) {
      need_update_last_insert_id = true;
      plan->statement->set_old_last_insert_id(
          plan->handler->get_session()->get_last_insert_id());
    }
  }
  need_auto_inc_lock = false;
}

int64_t MySQLPartitionInsertSelectNode::get_auto_increment_value(
    MySQLRowResponse *row) {
  if (plan->statement->get_auto_inc_status() == AUTO_INC_NOT_SPECIFIED) {
    return plan->statement->get_auto_inc_value_multi_insert_row(
        par_table, plan, schema_name_insert.c_str(), table_name_insert.c_str(),
        NULL);
  } else {
    uint64_t field_length = 0;
    string field_string;
    if (row->field_is_null(auto_increment_key_pos)) {
      field_string.append("NULL");
    } else {
      const char *field_str =
          row->get_str(auto_increment_key_pos, &field_length);
      field_string.append(field_str, field_length);
    }
    StrExpression field_expr = StrExpression(field_string.c_str(), EXPR_STRING);
    return plan->statement->get_auto_inc_value_multi_insert_row(
        par_table, plan, schema_name_insert.c_str(), table_name_insert.c_str(),
        &field_expr);
  }
}

unsigned int MySQLPartitionInsertSelectNode::get_part_id(
    MySQLRowResponse *row) {
  unsigned int par_id = 0;
  AutoIncStatus auto_inc_status = plan->statement->get_auto_inc_status();
  if (auto_inc_status != NO_AUTO_INC_FIELD &&
      auto_inc_status != AUTO_INC_NO_NEED_MODIFY) {
    par_id = get_par_id_one_row(row, auto_increment_key_pos, curr_auto_inc_val);
  } else {
    par_id = get_par_id_one_row(row);
  }
  par_id = par_table->get_real_par_id_from_virtual_id(par_id);
  return par_id;
}

void MySQLPartitionInsertSelectNode::build_value_list_str(
    string &str, MySQLRowResponse *row) {
  unsigned int i = 0;
  str.append("(");
  AutoIncStatus auto_inc_status = plan->statement->get_auto_inc_status();
  for (; i < field_num; i++) {
    if (auto_inc_status == AUTO_INC_VALUE_NULL &&
        auto_increment_key_pos == (int)i) {
      char auto_inc_str_val[21];
      snprintf(auto_inc_str_val, sizeof(auto_inc_str_val), "%ld",
               curr_auto_inc_val);
      str.append(auto_inc_str_val);
    } else {
      append_field_to_sql(&str, i, row);
    }
    str.append(",");
  }
  if (auto_inc_status == AUTO_INC_NOT_SPECIFIED) {
    char auto_inc_str_val[21];
    snprintf(auto_inc_str_val, sizeof(auto_inc_str_val), "%ld",
             curr_auto_inc_val);
    str.append(auto_inc_str_val);
  } else {
    boost::erase_tail(str, 1);
  }
  str.append("),");
}

void MySQLPartitionInsertSelectNode::update_last_insert_id() {
  AutoIncStatus auto_inc_status = plan->statement->get_auto_inc_status();
  if (auto_inc_status == AUTO_INC_VALUE_NULL ||
      auto_inc_status == AUTO_INC_NOT_SPECIFIED) {
    plan->handler->get_session()->set_last_insert_id(curr_auto_inc_val);
    need_update_last_insert_id = false;
  }
}

void MySQLPartitionInsertSelectNode::handle_select_node_child(
    MySQLExecuteNode *child) {
  Packet *packet = NULL;
  unsigned int par_id;
  string *sql;
  select_row_num += row_map[child]->size();
  if (plan->statement->is_cross_node_join() &&
      select_row_num > cross_join_max_rows) {
    status = EXECUTE_STATUS_COMPLETE;
    LOG_ERROR(
        "Reach the max rows of [%u] for cross node join max moved rows.\n",
        select_row_num);
    throw ExecuteNodeError(
        "Reach the max row number of cross node join max moved rows.");
  }
  while (!row_map[child]->empty()) {
    packet = row_map[child]->front();
    row_map[child]->pop_front();
    MySQLRowResponse row(packet);
    string tmp;
    try {
      if (plan->statement->get_auto_inc_status() != NO_AUTO_INC_FIELD) {
        curr_auto_inc_val = get_auto_increment_value(&row);
      }
      par_id = get_part_id(&row);
      get_partiton_modify_node(par_id);
      sql = &node_sql_map[par_id];

      build_value_list_str(tmp, &row);
      delete packet;
    } catch (...) {
      delete packet;
      if (plan->statement->get_auto_inc_status() != NO_AUTO_INC_FIELD) {
        plan->statement->rollback_auto_inc_params(plan, par_table);
      }
      throw;
    }

    if (need_update_last_insert_id) update_last_insert_id();

    if (!is_sql_len_valid(sql->length() + tmp.length()))
      if (is_sql_len_valid(tmp.length()))
        rotate_sql(modify_node_map[par_id], sql, &tmp);
      else {
        LOG_ERROR(
            "Generated temporary SQL for %s is too large, dbscale unsupport"
            " currently.\n",
            plan->statement->get_sql());
        throw ExecuteNodeError(
            "Unsupport sql for dbscale,  due to too large temporary SQL, \
                               please check the log for detail.");
      }
    else
      sql->append(tmp.c_str());

    if (is_sql_len_enough(sql->length()))
      rotate_sql(modify_node_map[par_id], sql, NULL);
  }
}

void MySQLPartitionInsertSelectNode::handle_select_node_child_duplicated(
    MySQLExecuteNode *child) {
  if (!has_init_duplicated_modify_node) {
    unsigned int num = par_table->get_real_partition_num();
    for (unsigned int i = 0; i < num; i++) {
      DataSpace *space = par_table->get_partition(i);
      if (space->get_virtual_machine_id() > 0) continue;

      get_partiton_modify_node(i);
    }
    has_init_duplicated_modify_node = true;
  }
  Packet *packet = NULL;
  string *sql;
  select_row_num += row_map[child]->size();
  if (plan->statement->is_cross_node_join() &&
      select_row_num > cross_join_max_rows) {
    status = EXECUTE_STATUS_COMPLETE;
    LOG_ERROR(
        "Reach the max rows of [%u] for cross node join max moved rows.\n",
        select_row_num);
    throw ExecuteNodeError(
        "Reach the max row number of cross node join max moved rows.");
  }
  while (!row_map[child]->empty()) {
    packet = row_map[child]->front();
    row_map[child]->pop_front();
    MySQLRowResponse row(packet);
    string tmp;
    build_value_list_str(tmp, &row);
    try {
      map<unsigned int, MySQLModifyNode *>::iterator it =
          modify_node_map.begin();
      for (; it != modify_node_map.end(); it++) {
        sql = &node_sql_map[it->first];
        if (!is_sql_len_valid(sql->length() + tmp.length()))
          if (is_sql_len_valid(tmp.length()))
            rotate_sql(it->second, sql, &tmp);
          else {
            LOG_ERROR(
                "Generated temporary SQL for %s is too large, dbscale unsupport"
                " currently.\n",
                plan->statement->get_sql());
            throw ExecuteNodeError(
                "Unsupport sql for dbscale,  due to too large temporary SQL, \
                                   please check the log for detail.");
          }
        else
          sql->append(tmp.c_str());

        if (is_sql_len_enough(sql->length())) rotate_sql(it->second, sql, NULL);
      }
      delete packet;
    } catch (...) {
      delete packet;
      if (plan->statement->get_auto_inc_status() != NO_AUTO_INC_FIELD) {
        plan->statement->rollback_auto_inc_params(plan, par_table);
      }
      throw;
    }
  }
}

void MySQLPartitionInsertSelectNode::handle_select_node_children() {
  LOG_DEBUG("PartitionInsertSelectNode %@ start to assemble modify sql.\n",
            this);

  if (!field_num) get_filed_num();

  if (need_auto_inc_lock) auto_inc_prepare();

  list<MySQLExecuteNode *>::iterator it;
  for (it = select_node_children.begin(); it != select_node_children.end();
       ++it) {
    if (!row_map[*it]->empty()) {
      if (is_duplicated)
        handle_select_node_child_duplicated(*it);
      else
        handle_select_node_child(*it);
    }
  }
}

/* some global functions */

void handle_max_min(Packet *packet, Packet *field_packet,
                    vector<MySQLRowResponse *> *mysql_rows,
                    unsigned column_index, MySQLColumnType column_type,
                    bool is_max) {
  ACE_UNUSED_ARG(field_packet);
  list<MySQLExecuteNode *>::iterator it;
  MySQLRowResponse *max_row = NULL;
  MySQLRowResponse *row = NULL;
  unsigned int i, n;
  n = mysql_rows->size();
  for (i = 0; i < n; i++) {
    row = (*mysql_rows)[i];
    if (!row->field_is_null(column_index)) {
      max_row = row;
      break;
    }
  }

  if (max_row) {
    SortDesc sort_desc;
    sort_desc.column_index = column_index;
    sort_desc.sort_order = is_max ? ORDER_DESC : ORDER_ASC;
    sort_desc.is_cs = true;
    sort_desc.ctype = CHARSET_TYPE_OTHER;
    for (i++; i < n; i++) {
      row = (*mysql_rows)[i];
      if (!row->field_is_null(column_index)) {
        if (MySQLColumnCompare::compare(max_row, row, sort_desc, column_type) ==
            -1) {
          max_row = row;
        }
      }
    }
  } else {
    max_row = (*mysql_rows)[0];
  }

  char *max_data;
  uint64_t max_data_len;
  uint8_t max_header_len;
  max_row->set_current(column_index);
  max_data = max_row->get_current_data();
  max_data_len = max_row->get_current_length();
  max_header_len = max_row->get_current_header_length();
  max_row->move_next();

  if (packet->size() - (packet->wr_ptr() - packet->base()) <
      1 + max_header_len + max_data_len) {
    uint64_t resize_len =
        1 + max_header_len + max_data_len + packet->wr_ptr() - packet->base();
    LOG_DEBUG("Packet size not enough, resize packet size from %d to %d\n",
              packet->size(), resize_len);
    packet->size(resize_len);
  }
  packet->packdata(max_data - max_header_len, max_header_len + max_data_len);
}

void copy_column_to_packet(MySQLRowResponse *row, unsigned int column_index,
                           Packet *packet) {
  char *start_pos, *end_pos;
  row->set_current(column_index);
  start_pos = row->get_current_data() - row->get_current_header_length();
  end_pos = row->get_current_data() + row->get_current_length();
  if (packet->size() - (packet->wr_ptr() - packet->base()) <
      (unsigned int)(end_pos - start_pos + 1)) {
    uint64_t resize_len =
        end_pos - start_pos + 1 + packet->wr_ptr() - packet->base();
    LOG_DEBUG("Packet size not enough, resize packet size from %d to %d\n",
              packet->size(), resize_len);
    packet->size(resize_len);
  }
  packet->packdata(start_pos, end_pos - start_pos);
  row->move_next();
}

void handle_certain_max(Packet *packet, Packet *field_packet,
                        vector<MySQLRowResponse *> *mysql_rows,
                        unsigned column_index, MySQLColumnType column_type) {
  ACE_UNUSED_ARG(field_packet);
  list<MySQLExecuteNode *>::iterator it;
  MySQLRowResponse *max_row = NULL;
  MySQLRowResponse *row = NULL;
  unsigned int i, rows_count;
  rows_count = mysql_rows->size();
  for (i = 0; i < rows_count; i++) {
    row = (*mysql_rows)[i];
    if (!row->field_is_null(column_index)) {
      max_row = row;
      break;
    }
  }

  if (max_row) {
    SortDesc sort_desc;
    sort_desc.column_index = column_index;
    sort_desc.sort_order = ORDER_DESC;
    sort_desc.is_cs = true;
    sort_desc.ctype = CHARSET_TYPE_OTHER;
    for (i++; i < rows_count; i++) {
      row = (*mysql_rows)[i];
      if (!row->field_is_null(column_index)) {
        if (MySQLColumnCompare::compare(max_row, row, sort_desc, column_type) ==
            -1) {
          max_row = row;
        }
      }
    }
  } else {
    max_row = (*mysql_rows)[0];
  }
  char *data;
  char *max_data;
  uint64_t max_data_len;
  data = max_row->get_row_data();
  max_row->set_current(column_index);
  max_data = max_row->get_current_data();
  max_data_len = max_row->get_current_length();

  if (packet->size() < max_data - data + max_data_len) {
    uint64_t resize_len = 1 + max_data - data + max_data_len;
    LOG_DEBUG("Packet size not enough, resize packet size from %d to %d\n",
              packet->size(), resize_len);
    packet->size(resize_len);
  }
  packet->rewind();
  packet->wr_ptr(PACKET_HEADER_SIZE);
  for (unsigned int i = 0; i <= column_index; i++) {
    copy_column_to_packet(max_row, i, packet);
  }
}

void handle_max(Packet *packet, Packet *field_packet,
                vector<MySQLRowResponse *> *mysql_rows, unsigned column_index,
                MySQLColumnType column_type) {
  return handle_max_min(packet, field_packet, mysql_rows, column_index,
                        column_type, true);
}

void handle_min(Packet *packet, Packet *field_packet,
                vector<MySQLRowResponse *> *mysql_rows, unsigned column_index,
                MySQLColumnType column_type) {
  return handle_max_min(packet, field_packet, mysql_rows, column_index,
                        column_type, false);
}

void handle_sum(Packet *packet, Packet *field_packet,
                vector<MySQLRowResponse *> *mysql_rows, unsigned column_index,
                MySQLColumnType column_type) {
  ACE_UNUSED_ARG(column_type);
  mpf_t sum, tmp_mpf;
  mpf_init2(sum, DECIMAL_STORE_BIT);
  mpf_init2(tmp_mpf, DECIMAL_STORE_BIT);
  MySQLRowResponse *row;
  bool all_sum_is_null = true;
  unsigned int n = mysql_rows->size();
  for (unsigned int i = 0; i < n; i++) {
    row = (*mysql_rows)[i];
    if (!row->field_is_null(column_index)) {
      all_sum_is_null = false;
      row->get_mpf(column_index, tmp_mpf);
      mpf_add(sum, sum, tmp_mpf);
      char str2[200];
      size_t len = gmp_sprintf(str2, "%.Ff", tmp_mpf);
      str2[len] = '\0';
      char str3[200];
      len = gmp_sprintf(str3, "%.Ff", sum);
      str3[len] = '\0';
    }
  }
  if (!all_sum_is_null) {
    char str[200];
    size_t len = gmp_sprintf(str, "%.Ff", sum);
    if (len > 33) {
      if (mpf_sgn(sum) == 0) {
        len = sprintf(str, "%0.2f", 0.00);
      } else {
        if (field_packet) {
          MySQLColumnResponse col_resp(field_packet);
          col_resp.unpack();
          int scale = int(col_resp.get_decimals());
          char formator[10];
          sprintf(formator, "%%.%dFf", scale);
          len = gmp_sprintf(str, formator, sum);
        } else {
          len = gmp_sprintf(str, "%.30Ff", sum);
        }
        str[len] = '\0';
        if (!strcmp(str, "-0.000000000000000000000000000000") ||
            !strcmp(str, "0.000000000000000000000000000000"))
          len = sprintf(str, "%0.2f", 0.00);
      }
    }
    if (packet->size() - (packet->wr_ptr() - packet->base()) < 10 + len) {
      uint64_t resize_len = 10 + len + packet->wr_ptr() - packet->base();
      LOG_DEBUG("Packet size not enough, resize packet size from %d to %d\n",
                packet->size(), resize_len);
      packet->size(resize_len);
    }
    packet->pack_lenenc_int(len);
    packet->packdata(str, len);
  } else {
    char *start_pos, *end_pos;
    row = (*mysql_rows)[0];
    row->set_current(column_index);
    start_pos = row->get_current_data() - row->get_current_header_length();
    end_pos = row->get_current_data() + row->get_current_length();
    packet->packdata(start_pos, end_pos - start_pos);
    row->move_next();
  }
  mpf_clear(sum);
  mpf_clear(tmp_mpf);
}

void handle_count(Packet *packet, Packet *field_packet,
                  vector<MySQLRowResponse *> *mysql_rows, unsigned column_index,
                  MySQLColumnType column_type) {
  ACE_UNUSED_ARG(field_packet);
  ACE_UNUSED_ARG(column_type);
  uint64_t sum = 0;
  MySQLRowResponse *row;
  unsigned int n = mysql_rows->size();
  for (unsigned int i = 0; i < n; i++) {
    row = (*mysql_rows)[i];
    sum += row->get_uint(column_index);
  }

  char str[32];
  size_t len = sprintf(str, "%ld", sum);
  if (packet->size() - (packet->wr_ptr() - packet->base()) < 10 + len) {
    uint64_t resize_len = 10 + len + packet->wr_ptr() - packet->base();
    LOG_DEBUG("Packet size not enough, resize packet size from %d to %d\n",
              packet->size(), resize_len);
    packet->size(resize_len);
  }
  packet->pack_lenenc_int(len);
  packet->packdata(str, len);
}

void handle_normal(Packet *packet, Packet *field_packet,
                   vector<MySQLRowResponse *> *mysql_rows,
                   unsigned column_index, MySQLColumnType column_type) {
  ACE_UNUSED_ARG(field_packet);
  ACE_UNUSED_ARG(column_type);
  MySQLRowResponse *row;

  row = (*mysql_rows)[0];
  copy_column_to_packet(row, column_index, packet);
}

void init_column_handlers(unsigned int column_num,
                          list<AggregateDesc> &aggregate_desc,
                          vector<aggregate_handler> &column_handlers,
                          bool is_certain) {
  unsigned int i;
  list<AggregateDesc>::iterator it;
  for (i = 0; i < column_num; i++) {
    for (it = aggregate_desc.begin(); it != aggregate_desc.end(); it++) {
      if ((unsigned)it->column_index == i) {
        switch (it->type) {
          case AGGREGATE_TYPE_MAX:
            if (is_certain) {
              column_handlers.push_back(handle_certain_max);
              is_certain = false;
            } else
              column_handlers.push_back(handle_max);
            break;
          case AGGREGATE_TYPE_MIN:
            column_handlers.push_back(handle_min);
            break;
          case AGGREGATE_TYPE_COUNT:
            column_handlers.push_back(handle_count);
            break;
          case AGGREGATE_TYPE_SUM:
            column_handlers.push_back(handle_sum);
            break;
          default:
            break;
        }
        break;
      }
    }

    if (it == aggregate_desc.end()) column_handlers.push_back(handle_normal);
  }
}

/* class MySQLAggregateNode */

MySQLAggregateNode::MySQLAggregateNode(ExecutePlan *plan,
                                       list<AggregateDesc> &aggregate_desc)
    : MySQLInnerNode(plan) {
  this->name = "MySQLAggregateNode";
  this->aggregate_desc = aggregate_desc;
  status = EXECUTE_STATUS_START;
  node_can_swap = session->is_may_backend_exec_swap_able();
  result_packet = NULL;
}

void MySQLAggregateNode::init_mysql_rows() {
  max_row_size = 0;
  list<MySQLExecuteNode *>::iterator it;
  for (it = children.begin(); it != children.end(); ++it) {
    if (row_map[*it]->empty()) {
      continue;
    }
    MySQLRowResponse *row = new MySQLRowResponse(row_map[*it]->front());
    mysql_rows.push_back(row);
    if (max_row_size < row_map[*it]->front()->size()) {
      max_row_size = row_map[*it]->front()->size();
    }
  }
}

void MySQLAggregateNode::handle() {
  list<Packet *> *field_packets = get_field_packets();
  init_column_types(field_packets, column_types, column_num, NULL);
  init_column_handlers(column_num, aggregate_desc, column_handlers);
  init_mysql_rows();

  if (max_row_size >= (unsigned int)row_packet_size) {
    result_packet->size((unsigned int)(max_row_size * 1.2));
    LOG_DEBUG("Packet size not enough, resize packet size from %d to %d\n",
              row_packet_size, int(max_row_size * 1.2));
  } else if ((unsigned int)(row_packet_size * 0.9) < max_row_size) {
    result_packet->size((unsigned int)(row_packet_size * 1.2));
    LOG_DEBUG("Packet size not enough, resize packet size from %d to %d\n",
              row_packet_size, row_packet_size * 1.2);
  }

  list<Packet *>::iterator it_field = field_packets->begin();
  unsigned int i;
  for (i = 0; i < column_num; i++) {
    column_handlers[i](result_packet, *it_field, &mysql_rows, i,
                       column_types[i]);
    ++it_field;
  }

  // set the header of the result set
  size_t load_length = result_packet->length() - PACKET_HEADER_SIZE;
  pack_header(result_packet, load_length);

  ready_rows->push_back(result_packet);
  result_packet = NULL;
}

void MySQLAggregateNode::execute() {
  while (status != EXECUTE_STATUS_COMPLETE) {
    switch (status) {
      case EXECUTE_STATUS_START:
        result_packet = Backend::instance()->get_new_packet(row_packet_size);
        result_packet->wr_ptr(PACKET_HEADER_SIZE);
        init_row_map();
        status = EXECUTE_STATUS_FETCH_DATA;
        break;

      case EXECUTE_STATUS_FETCH_DATA:
        children_execute();
        if (node_can_swap && plan->plan_can_swap()) {
          handle_swap_connections();
          return;
        }
        status = EXECUTE_STATUS_WAIT;

      case EXECUTE_STATUS_WAIT:
        try {
          wait_children();
        } catch (ExecuteNodeError &e) {
          status = EXECUTE_STATUS_COMPLETE;
          throw e;
        }
        break;

      case EXECUTE_STATUS_HANDLE:
#ifdef DEBUG
        node_start_timing();
#endif
        handle();
#ifdef DEBUG
        node_end_timing();
#endif
        status = EXECUTE_STATUS_FETCH_DATA;
        return;
        break;

      case EXECUTE_STATUS_BEFORE_COMPLETE:
        status = EXECUTE_STATUS_COMPLETE;

      case EXECUTE_STATUS_COMPLETE:
#ifdef DEBUG
        LOG_DEBUG("MySQLAggregateNode %@ cost %d ms\n", this, node_cost_time);
#endif
        break;

      default:
        ACE_ASSERT(0);
        break;
    }
  }
}

void MySQLAggregateNode::do_clean() {
  MySQLRowResponse *row;
  while (!mysql_rows.empty()) {
    row = mysql_rows.back();
    mysql_rows.pop_back();
    delete row;
  }

  if (result_packet) {
    delete result_packet;
    result_packet = NULL;
  }
}

/* class MySQLWiseGroupNode */

MySQLWiseGroupNode::MySQLWiseGroupNode(ExecutePlan *plan,
                                       list<SortDesc> *group_desc,
                                       list<AggregateDesc> &aggregate_desc)
    : MySQLSortNode(plan, group_desc) {
  this->name = "MySQLWiseGroupNode";
  this->aggregate_desc = aggregate_desc;
  init_column_handler_flag = false;
  max_row_size = 0;
  group_size = 0;
  max_group_buffer_rows = 0;
  max_group_buffer_rows_size = max_wise_group_size * 1024;
}

void MySQLWiseGroupNode::handle_before_complete() {
  group_by();
  if (!group_rows.empty()) {
    Packet *new_row = merge_group();
    ready_rows->push_back(new_row);
  }
}

void MySQLWiseGroupNode::group_by() {
  Packet *packet;
  while (!ready_nodes->empty()) {
    packet = ready_nodes->front();
    if (add_to_group(packet)) {
      ready_nodes->pop_front();
      group_size++;
      if ((group_size & 0x03FF) == 0 || max_group_buffer_rows == 0) {
        max_group_buffer_rows =
            max_group_buffer_rows_size / packet->total_capacity();
        if (!max_group_buffer_rows) max_group_buffer_rows = 1000;
      }
      if (group_size > max_group_buffer_rows) {
        LOG_DEBUG("Wise group size is larger than max_wise_group_size.\n");
        throw Error("Wise group size is larger than max_wise_group_size.");
      }
    } else {
      group_size = 0;
      Packet *new_row = merge_group();
      ready_rows->push_back(new_row);
    }
  }
}

bool MySQLWiseGroupNode::add_to_group(Packet *packet) {
  if (group_rows.empty() ||
      MySQLColumnCompare::compare(group_rows[0]->get_packet(), packet,
                                  &sort_desc, &column_types) == 0) {
    MySQLRowResponse *row = new MySQLRowResponse(packet);
    group_rows.push_back(row);
    if (max_row_size < packet->size()) {
      max_row_size = packet->size();
    }
    return true;
  } else {
    return false;
  }
}

void MySQLWiseGroupNode::handle() {
  init_column_types(get_field_packets(), column_types, column_num,
                    &column_inited_flag);
  check_column_valid();
  if (!init_column_handler_flag) {
    init_column_handlers(column_num, aggregate_desc, column_handlers);
    init_column_handler_flag = true;
  }
  group_by();
}

Packet *MySQLWiseGroupNode::merge_group() {
  MySQLRowResponse *row;
  Packet *result_packet;

  if (group_rows.size() == 1) {
    result_packet = group_rows.back()->get_packet();
    row = group_rows.back();
    group_rows.pop_back();
    delete row;
  } else {
    result_packet = Backend::instance()->get_new_packet(row_packet_size);
    result_packet->wr_ptr(PACKET_HEADER_SIZE);
    if (max_row_size >= (unsigned int)row_packet_size) {
      LOG_DEBUG("Packet size not enough, resize packet size from %d to %d\n",
                row_packet_size, int(max_row_size * 1.2));
      result_packet->size((unsigned int)(max_row_size * 1.2));
    } else if ((unsigned int)(row_packet_size * 0.9) < max_row_size) {
      result_packet->size((unsigned int)(row_packet_size * 1.2));
      LOG_DEBUG("Packet size not enough, resize packet size from %d to %d\n",
                row_packet_size, int(row_packet_size * 1.2));
    }
    for (unsigned int i = 0; i < column_num; i++) {
      column_handlers[i](result_packet, NULL, &group_rows, i, column_types[i]);
    }

    size_t load_length = result_packet->length() - PACKET_HEADER_SIZE;
    pack_header(result_packet, load_length);

    while (!group_rows.empty()) {
      row = group_rows.back();
      group_rows.pop_back();
      delete row->get_packet();
      delete row;
    }
  }

  return result_packet;
}

void MySQLWiseGroupNode::execute() {
  while (status != EXECUTE_STATUS_COMPLETE) {
    switch (status) {
      case EXECUTE_STATUS_START:
        init_row_map();
        ready_nodes = row_map[*(children.begin())];
        status = EXECUTE_STATUS_FETCH_DATA;
        break;

      case EXECUTE_STATUS_FETCH_DATA:
        children_execute();
        if (node_can_swap && plan->plan_can_swap()) {
          handle_swap_connections();
          return;
        }
        status = EXECUTE_STATUS_WAIT;

      case EXECUTE_STATUS_WAIT:
        try {
          wait_children();
        } catch (ExecuteNodeError &e) {
          status = EXECUTE_STATUS_COMPLETE;
          throw e;
        }
        break;

      case EXECUTE_STATUS_HANDLE:
#ifdef DEBUG
        node_start_timing();
#endif
        handle();
#ifdef DEBUG
        node_end_timing();
#endif
        status = EXECUTE_STATUS_FETCH_DATA;
        if (!ready_rows->empty()) return;
        break;

      case EXECUTE_STATUS_BEFORE_COMPLETE:
        handle_before_complete();
        status = EXECUTE_STATUS_COMPLETE;

      case EXECUTE_STATUS_COMPLETE:
#ifdef DEBUG
        LOG_DEBUG("MySQLWiseGroupNode %@ cost %d ms\n", this, node_cost_time);
#endif
        break;

      default:
        ACE_ASSERT(0);
        break;
    }
  }
}

void MySQLWiseGroupNode::do_clean() {
  MySQLRowResponse *row;
  while (!group_rows.empty()) {
    row = group_rows.back();
    group_rows.pop_back();
    delete row->get_packet();
    delete row;
  }
}

/* class MySQLPagesNode */
MySQLPagesNode::MySQLPagesNode(ExecutePlan *plan, list<SortDesc> *group_desc,
                               list<AggregateDesc> &aggregate_desc,
                               int page_size)
    : MySQLWiseGroupNode(plan, group_desc, aggregate_desc) {
  this->name = "MySQLPagesNode";
  this->page_size = page_size;
  rownum = 0;
  count_index = -1;
  list<AggregateDesc>::iterator it = aggregate_desc.begin();
  for (; it != aggregate_desc.end(); ++it) {
    if (it->type == AGGREGATE_TYPE_COUNT) count_index = it->column_index;
  }
}

void MySQLPagesNode::group_by() {
  Packet *packet;
  while (!ready_nodes->empty()) {
    packet = ready_nodes->front();
    ready_nodes->pop_front();
    ++rownum;

    MySQLRowResponse *row = new MySQLRowResponse(packet);
    group_rows.push_back(row);
    if (max_row_size < packet->size()) {
      max_row_size = packet->size();
    }
    ++group_size;
    if ((group_size & 0x03FF) == 0 || max_group_buffer_rows == 0) {
      max_group_buffer_rows =
          max_group_buffer_rows_size / packet->total_capacity();
      if (!max_group_buffer_rows) max_group_buffer_rows = 1000;
    }
    if (group_size > max_group_buffer_rows) {
      LOG_DEBUG("Wise group size is larger than max_wise_group_size.\n");
      throw Error("Wise group size is larger than max_wise_group_size.");
    }

    if (rownum % page_size == 0) {
      Packet *new_row = merge_group();
      ready_rows->push_back(new_row);
    }
  }
}

Packet *MySQLPagesNode::merge_group() {
  MySQLRowResponse *row;
  Packet *result_packet;

  result_packet = Backend::instance()->get_new_packet(row_packet_size);
  result_packet->wr_ptr(PACKET_HEADER_SIZE);
  if (max_row_size >= (unsigned int)row_packet_size) {
    LOG_DEBUG("Packet size not enough, resize packet size from %d to %d\n",
              row_packet_size, int(max_row_size * 1.2));
    result_packet->size((unsigned int)(max_row_size * 1.2));
  } else if ((unsigned int)(row_packet_size * 0.9) < max_row_size) {
    result_packet->size((unsigned int)(row_packet_size * 1.2));
    LOG_DEBUG("Packet size not enough, resize packet size from %d to %d\n",
              row_packet_size, int(row_packet_size * 1.2));
  }
  for (unsigned int i = 0; i < column_num; i++) {
    if (i == (unsigned int)count_index) {
      char str[32];
      size_t len = sprintf(str, "%ld", rownum);
      if (result_packet->size() -
              (result_packet->wr_ptr() - result_packet->base()) <
          10 + len) {
        uint64_t resize_len =
            10 + len + result_packet->wr_ptr() - result_packet->base();
        LOG_DEBUG("Packet size not enough, resize packet size from %d to %d\n",
                  result_packet->size(), resize_len);
        result_packet->size(resize_len);
      }
      result_packet->pack_lenenc_int(len);
      result_packet->packdata(str, len);
    } else {
      column_handlers[i](result_packet, NULL, &group_rows, i, column_types[i]);
    }
  }

  size_t load_length = result_packet->length() - PACKET_HEADER_SIZE;
  pack_header(result_packet, load_length);

  while (!group_rows.empty()) {
    row = group_rows.back();
    group_rows.pop_back();
    delete row->get_packet();
    delete row;
  }
  group_size = 0;

  return result_packet;
}

/* class MySQLGroupNode */

MySQLGroupNode::MySQLGroupNode(ExecutePlan *plan, list<SortDesc> *sort_desc,
                               list<AggregateDesc> &aggregate_desc)
    : MySQLSortNode(plan, sort_desc) {
  this->name = "MySQLGroupNode";
  this->aggregate_desc = aggregate_desc;
  init_column_handler_flag = false;
  this->sort_ready_nodes = &this->ready_nodes;
  max_row_size = 0;
  node_can_swap = session->is_may_backend_exec_swap_able();
}

bool MySQLGroupNode::add_to_group(Packet *packet) {
  if (group_rows.empty() ||
      MySQLColumnCompare::compare(group_rows[0]->get_packet(), packet,
                                  &sort_desc, &column_types) == 0) {
    MySQLRowResponse *row = new MySQLRowResponse(packet);
    group_rows.push_back(row);
    if (max_row_size < packet->size()) {
      max_row_size = packet->size();
    }
    return true;
  } else {
    return false;
  }
}

Packet *MySQLGroupNode::merge_group() {
  MySQLRowResponse *row;
  Packet *result_packet;
#ifdef DEBUG
  LOG_DEBUG("merge group with %d rows.\n", group_rows.size());
#endif
  if (group_rows.size() == 1) {
    result_packet = group_rows.back()->get_packet();
    row = group_rows.back();
    group_rows.pop_back();
    delete row;
  } else {
    result_packet = Backend::instance()->get_new_packet(row_packet_size);
    result_packet->wr_ptr(PACKET_HEADER_SIZE);
    if (max_row_size >= (unsigned int)row_packet_size) {
      LOG_DEBUG("Packet size not enough, resize packet size from %d to %d\n",
                row_packet_size, int(max_row_size * 1.2));
      result_packet->size((unsigned int)(max_row_size * 1.2));
    } else if ((unsigned int)(row_packet_size * 0.9) < max_row_size) {
      result_packet->size((unsigned int)(row_packet_size * 1.2));
      LOG_DEBUG("Packet size not enough, resize packet size from %d to %d\n",
                row_packet_size, int(row_packet_size * 1.2));
    }
    for (unsigned int i = 0; i < column_num; i++) {
      column_handlers[i](result_packet, NULL, &group_rows, i, column_types[i]);
    }

    // set the header of the result set
    size_t load_length = result_packet->length() - PACKET_HEADER_SIZE;
    pack_header(result_packet, load_length);

    while (!group_rows.empty()) {
      row = group_rows.back();
      group_rows.pop_back();
      delete row->get_packet();
      delete row;
    }
  }

  return result_packet;
}

void MySQLGroupNode::group_by() {
  Packet *packet;
  while (!ready_nodes.empty()) {
    packet = ready_nodes.front();

    if (add_to_group(packet)) {
      ready_nodes.pop_front();
    } else {
      Packet *new_row = merge_group();
      ready_rows->push_back(new_row);
    }
  }
}

void MySQLGroupNode::handle_before_complete() {
  last_sort();
  group_by();
  // deal with remaining ready_rows
  if (!group_rows.empty()) {
    Packet *new_row = merge_group();
    ready_rows->push_back(new_row);
  }
}

void MySQLGroupNode::handle() {
  init_column_types(get_field_packets(), column_types, column_num,
                    &column_inited_flag);
  adjust_column_index();
  check_column_valid();
  if (!init_column_handler_flag) {
    if (plan->statement->get_stmt_node()->execute_max_count_certain)
      init_column_handlers(column_num, aggregate_desc, column_handlers, true);
    else
      init_column_handlers(column_num, aggregate_desc, column_handlers);
    init_column_handler_flag = true;
  }
  sort();
  group_by();
}

void MySQLGroupNode::execute() {
  while (status != EXECUTE_STATUS_COMPLETE) {
    switch (status) {
      case EXECUTE_STATUS_START:
        init_row_map();
        init_merge_sort_variables();
        status = EXECUTE_STATUS_FETCH_DATA;
        break;

      case EXECUTE_STATUS_FETCH_DATA:
        children_execute();
        if (node_can_swap && plan->plan_can_swap()) {
          handle_swap_connections();
          return;
        }
        status = EXECUTE_STATUS_WAIT;

      case EXECUTE_STATUS_WAIT:
        try {
          wait_children();
        } catch (ExecuteNodeError &e) {
          status = EXECUTE_STATUS_COMPLETE;
          throw e;
        }
        break;

      case EXECUTE_STATUS_HANDLE:
#ifdef DEBUG
        node_start_timing();
#endif
        handle();
#ifdef DEBUG
        node_end_timing();
#endif
        status = EXECUTE_STATUS_FETCH_DATA;
        if (!ready_rows->empty()) return;
        break;

      case EXECUTE_STATUS_BEFORE_COMPLETE:
        handle_before_complete();
        status = EXECUTE_STATUS_COMPLETE;

      case EXECUTE_STATUS_COMPLETE:
#ifdef DEBUG
        LOG_DEBUG("MySQLGroupNode %@ cost %d ms\n", this, node_cost_time);
#endif
        break;

      default:
        ACE_ASSERT(0);
        break;
    }
  }
}

void MySQLGroupNode::do_clean() {
  MySQLRowResponse *row;
  while (!group_rows.empty()) {
    row = group_rows.back();
    group_rows.pop_back();
    delete row->get_packet();
    delete row;
  }

  Packet *packet;
  while (!ready_nodes.empty()) {
    packet = ready_nodes.back();
    ready_nodes.pop_back();
    if (packet) delete packet;
  }
}

/* class MySQLSingleSortNode */

MySQLSingleSortNode::MySQLSingleSortNode(ExecutePlan *plan,
                                         list<SortDesc> *sort_desc)
    : MySQLSortNode(plan, sort_desc) {
  this->name = "MySQLSingleSortNode";
  this->sort_ready_nodes = &this->ready_nodes;
  node_can_swap = session->is_may_backend_exec_swap_able();
  max_single_sort_buffer_rows = 0;
  max_single_sort_buffer_rows_size =
      session->get_session_option("max_single_sort_rows").ulong_val * 1024;
}

void MySQLSingleSortNode::init_heap() {
  list<MySQLExecuteNode *>::iterator it;

  /* dummy node */
  rows_heap.push_back(NULL);
  heap_size = 0;
}

void MySQLSingleSortNode::max_heapify(unsigned int i) {
  unsigned int left = i << 1;
  unsigned int right = left + 1;
  unsigned int largest;

  if (left <= heap_size &&
      MySQLColumnCompare::compare(rows_heap[left], rows_heap[i], &sort_desc,
                                  &column_types) == 1) {
    largest = left;
  } else {
    largest = i;
  }

  if (right <= heap_size &&
      MySQLColumnCompare::compare(rows_heap[right], rows_heap[largest],
                                  &sort_desc, &column_types) == 1) {
    largest = right;
  }

  if (i != largest) {
    Packet *packet;
    packet = rows_heap[i];
    rows_heap[i] = rows_heap[largest];
    rows_heap[largest] = packet;
    max_heapify(largest);
  }
}

void MySQLSingleSortNode::heap_insert(MySQLExecuteNode *node) {
  unsigned int i;
  Packet *packet;
  while (!row_map[node]->empty()) {
    i = ++heap_size;
    if ((heap_size & 0x03FF) == 0 || max_single_sort_buffer_rows == 0) {
      max_single_sort_buffer_rows = max_single_sort_buffer_rows_size /
                                    row_map[node]->front()->total_capacity();
      if (!max_single_sort_buffer_rows) max_single_sort_buffer_rows = 1000;
    }
    if (heap_size > max_single_sort_buffer_rows) {
      vector<Packet *>::iterator it = rows_heap.begin();
      for (; it != rows_heap.end(); it++) {
        delete (*it);
      }
      rows_heap.clear();

      LOG_ERROR(
          "Reach the max allowed single sort rows with row num %d, refuse this "
          "sql to protect dbscale.\n",
          heap_size);
      LOG_ERROR(
          "To solve this problem, you can change the sql from 'select * from "
          "tbl group by c1 order by c2' to 'select * from (select * from tbl "
          "group by c1) T order by c2'. In other words, move the group by part "
          "into a table subquery.\n");
      throw Error(
          "Reach the max allowed single sort rows. Please check manual and the "
          "error message in the log.");
    }
    rows_heap.push_back(row_map[node]->front());
    while (i > 1 &&
           MySQLColumnCompare::compare(rows_heap[i >> 1], rows_heap[i],
                                       &sort_desc, &column_types) == -1) {
      packet = rows_heap[i];
      rows_heap[i] = rows_heap[i >> 1];
      rows_heap[i >> 1] = packet;
      i = i >> 1;
    }

    row_map[node]->pop_front();
  }
}

void MySQLSingleSortNode::sort() {
  list<MySQLExecuteNode *>::iterator it;
  for (it = children.begin(); it != children.end(); ++it) {
    if (row_map[*it]->size()) {
      heap_insert(*it);
    }
  }
}

void MySQLSingleSortNode::handle_before_complete() {
  while (heap_size) {
    ready_rows->push_back(rows_heap[1]);
    rows_heap[1] = rows_heap[heap_size--];
    rows_heap.pop_back();
    max_heapify(1);
  }
}

void MySQLSingleSortNode::execute() {
  while (status != EXECUTE_STATUS_COMPLETE) {
    switch (status) {
      case EXECUTE_STATUS_START:
        init_row_map();
        init_heap();
        status = EXECUTE_STATUS_FETCH_DATA;
        break;

      case EXECUTE_STATUS_FETCH_DATA:
        children_execute();
        if (node_can_swap && plan->plan_can_swap()) {
          handle_swap_connections();
          return;
        }
        status = EXECUTE_STATUS_WAIT;

      case EXECUTE_STATUS_WAIT:
        try {
          wait_children();
        } catch (ExecuteNodeError &e) {
          status = EXECUTE_STATUS_COMPLETE;
          throw e;
        }
        break;

      case EXECUTE_STATUS_HANDLE:
#ifdef DEBUG
        node_start_timing();
#endif
        init_column_types(get_field_packets(), column_types, column_num,
                          &column_inited_flag);
        adjust_column_index();
        check_column_valid();
        sort();
#ifdef DEBUG
        node_end_timing();
#endif
        status = EXECUTE_STATUS_FETCH_DATA;
        break;

      case EXECUTE_STATUS_BEFORE_COMPLETE:
        handle_before_complete();
        status = EXECUTE_STATUS_COMPLETE;
        break;

      case EXECUTE_STATUS_COMPLETE:
#ifdef DEBUG
        LOG_DEBUG("MySQLAggregateNode %@ cost %d ms\n", this, node_cost_time);
#endif
        break;

      default:
        ACE_ASSERT(0);
        break;
    }
  }
}

void MySQLSingleSortNode::do_clean() {
  Packet *packet;
  while (!ready_nodes.empty()) {
    packet = ready_nodes.back();
    ready_nodes.pop_back();
    if (packet) delete packet;
  }
}

/* class MySQLLoadLocalExternal */
MySQLLoadLocalExternal::MySQLLoadLocalExternal(ExecutePlan *plan,
                                               DataSpace *dataspace,
                                               DataServer *dataserver,
                                               const char *sql)
    : MySQLExecuteNode(plan, dataspace), dataserver(dataserver), sql(sql) {}

void MySQLLoadLocalExternal::execute() {
#ifdef DEBUG
  node_start_timing();
#endif

  int fifo_id = Backend::instance()->create_fifo();
  sprintf(fifo_name, "/tmp/tmp_fifo_%d", fifo_id);

  build_command();
  spawn_command();
  send_file_request_to_client();

  // feed data into FIFO
  Packet packet;
  size_t load_length = 0;
  bool before_file_close = false;
  try {
    do {
      packet.rewind();
      handler->receive_from_client(&packet);
      if (!driver->is_empty_packet(&packet)) {
        if (param.has_got_error() || param.get_external_load_flag() == FINISH) {
          throw ExecuteNodeError(
              "Got error when execute statement, check log for more "
              "information.");
        }
        load_length = packet.unpack3uint();
        LOG_DEBUG("MySQLLoadLocalExternal %@ get packet %@ from client.\n",
                  this, &packet);
        file.write(packet.base() + PACKET_HEADER_SIZE, load_length);
      }
    } while (!driver->is_empty_packet(&packet));
    before_file_close = true;
    file.close();
    ACE_Thread::join(t_handle);
  } catch (...) {
    status = EXECUTE_STATUS_COMPLETE;
    if (!before_file_close) {
      file.close();
      ACE_Thread::join(t_handle);
    }
    throw;
  }

  status = EXECUTE_STATUS_COMPLETE;
#ifdef DEBUG
  node_end_timing();
#endif

  if (param.has_got_error()) {
    LOG_ERROR("Got error when execute statement, %Q rows inserted.\n",
              param.insert_rows);
    throw ExecuteNodeError(
        "Got error when execute statement, check log for more information.");
  } else {
    send_ok_packet_to_client(handler, param.insert_rows, 0);
#ifdef DEBUG
    LOG_DEBUG("MySQLLoadLocalExternal %@ cost %d ms\n", this, node_cost_time);
#endif
  }
}

void MySQLLoadLocalExternal::send_file_request_to_client() {
  stmt_node *st = plan->statement->get_stmt_node();
  const char *filename = st->sql->load_oper->filename;
  Packet *res = Backend::instance()->get_new_packet(row_packet_size);
  res->wr_ptr(res->base() + PACKET_HEADER_SIZE);
  char load_flag;
  load_flag = 0xfb;
  res->packdata((const char *)&load_flag, 1);
  res->packdata(filename, strlen(filename));
  pack_header(res, strlen(filename) + 1);
  handler->send_to_client(res);
  delete res;
}

void MySQLLoadLocalExternal::build_command() {
  stmt_node *st = plan->statement->get_stmt_node();
  table_link *table = st->table_list_head;
  const char *field_terminate = st->sql->load_oper->field_terminate;
  const char *field_enclose = st->sql->load_oper->field_enclose;
  if (strlen(field_terminate) > 1 || strlen(field_enclose) > 1) {
    LOG_ERROR(
        "DBScale does not support FIELDS TERMINATED/ENCLOSED BY with multiple "
        "characters "
        "for external LOAD DATA.\n");
    throw NotImplementedError(
        "external LOAD DATA FIELDS TERMINATED/ENCLOSED BY has multiple "
        "characters");
  }
  const char *schema_name = table->join->schema_name ? table->join->schema_name
                                                     : session->get_schema();
  const char *table_name = table->join->table_name;
  if (!schema_name || schema_name[0] == '\0') {
    status = EXECUTE_STATUS_COMPLETE;
    throw ExecuteNodeError("No database selected.");
  }
  const char *remote_host = dataserver->get_host_direct();
  const char *remote_user = dataserver->get_remote_user();
  const char *remote_password = dataserver->get_remote_password();
  int remote_port = dataserver->get_remote_port();
  const char *external_load_script = dataserver->get_external_load_script();

  ExternalLoadRemoteExecute ep_ssh(external_load_script, schema_name,
                                   table_name, field_terminate, field_enclose,
                                   fifo_name, remote_host, remote_port,
                                   remote_user, remote_password);
  ep_ssh.build_full_command();
  load_local_external_cmd = ep_ssh.get_command();
  LOG_DEBUG("full command [%s].\n", load_local_external_cmd.c_str());
}

void MySQLLoadLocalExternal::spawn_command() {
  fd = popen(load_local_external_cmd.c_str(), "r");
  if (fd == NULL) {
    fprintf(stderr, "execute command failed");
    LOG_ERROR("Fail to execute command %s.\n", load_local_external_cmd.c_str());
    throw HandlerError("Fail to execute command.");
  }

  param.set_got_error(false);
  param.insert_rows = 0;
  param.fd = fd;
  param.set_external_load_flag(UNDEFINE);
  int ret =
      ACE_Thread::spawn((ACE_THR_FUNC)monitor_worker_via_fifo, &param,
                        THR_JOINABLE | THR_SCHED_DEFAULT, &t_id, &t_handle);
  if (ret == -1) {
    LOG_ERROR("Error when execute command %s.\n",
              load_local_external_cmd.c_str());
    throw HandlerError("Error when execute command.");
  }
  file.open(fifo_name);
  while (param.get_external_load_flag() == UNDEFINE) {
    LOG_DEBUG("Waiting for external load script report load file status.\n");
    ACE_OS::sleep(1);
  }
  if (param.get_external_load_flag() == FILE_NOT_OPEN) {
    file.close();
    ACE_Thread::join(t_handle);
    throw ExecuteNodeError(
        "Failed to execute statement, fail to open file, check log for more "
        "information.");
  }
}

void MySQLLoadLocalExternal::clean() {
  for (int i = 0; i < 3; i++) {  // delete fifo, try 3 times.
    if (!remove(fifo_name)) {    // return 0, delete fifo successful.
      break;
    }
    if (i == 2) {  // try 3 times but failed.
      LOG_ERROR("Error deleting fifo file.\n");
    }
  }
}

/* class MySQLLoadDataInfileExternal */

MySQLLoadDataInfileExternal::MySQLLoadDataInfileExternal(ExecutePlan *plan,
                                                         DataSpace *dataspace,
                                                         DataServer *dataserver)
    : MySQLExecuteNode(plan, dataspace), dataserver(dataserver) {}

void MySQLLoadDataInfileExternal::execute() {
#ifdef DEBUG
  node_start_timing();
#endif
  const char *remote_host = dataserver->get_host_direct();
  const char *remote_user = dataserver->get_remote_user();
  const char *remote_password = dataserver->get_remote_password();
  int remote_port = dataserver->get_remote_port();
  const char *external_load_script = dataserver->get_external_load_script();

  stmt_node *st = plan->statement->get_stmt_node();

  const char *file_name = st->sql->load_oper->filename;
  table_link *table = st->table_list_head;
  const char *schema_name = table->join->schema_name ? table->join->schema_name
                                                     : session->get_schema();
  const char *table_name = table->join->table_name;

  const char *field_terminate = st->sql->load_oper->field_terminate;
  const char *field_enclose = st->sql->load_oper->field_enclose;
  if (strlen(field_terminate) > 1 || strlen(field_enclose) > 1) {
    LOG_ERROR(
        "DBScale does not support FIELDS TERMINATED/ENCLOSED BY with multiple "
        "characters "
        "for external LOAD DATA.\n");
    throw NotImplementedError(
        "external LOAD DATA FIELDS TERMINATED/ENCLOSED BY has multiple "
        "characters");
  }

  if (!schema_name || schema_name[0] == '\0') {
    status = EXECUTE_STATUS_COMPLETE;
    throw ExecuteNodeError("No database selected.");
  }

  ExternalLoadResultHandler exp_handler;
  try {
    ExternalLoadRemoteExecute ep_ssh(external_load_script, schema_name,
                                     table_name, field_terminate, field_enclose,
                                     file_name, remote_host, remote_port,
                                     remote_user, remote_password);
    ep_ssh.set_result_handler(&exp_handler);
    ep_ssh.exec_remote_command();
  } catch (dbscale::sql::SQLError &e) {
    status = EXECUTE_STATUS_COMPLETE;
    throw ExecuteNodeError("Table is not exist for external load.");
  } catch (ExecuteFail &e) {
    status = EXECUTE_STATUS_COMPLETE;
    throw ExecuteNodeError(
        "Fail to execute LOAD DATA due to execution failure.");
  } catch (Exception &e) {
    status = EXECUTE_STATUS_COMPLETE;
    throw ExecuteNodeError(e.what());
  }

  const char *inserted_rows = exp_handler.get_inserted_rows();
  uint64_t affect_rows = atoll(inserted_rows);
  LOG_DEBUG("Get affect rows of GOS load %s %d.\n", inserted_rows, affect_rows);
  Packet ok_packet;
  MySQLOKResponse ok(affect_rows, 0);
  ok.pack(&ok_packet);
  handler->deal_autocommit_with_ok_eof_packet(&ok_packet);
  handler->record_affected_rows(&ok_packet);
  handler->send_to_client(&ok_packet);

  status = EXECUTE_STATUS_COMPLETE;
#ifdef DEBUG
  node_end_timing();
#endif
#ifdef DEBUG
  LOG_DEBUG("MySQLLoadDataInfileExternalNode %@ cost %d ms\n", this,
            node_cost_time);
#endif
}

/* class MySQLLoadLocalNode */

MySQLLoadLocalNode::MySQLLoadLocalNode(ExecutePlan *plan, DataSpace *dataspace,
                                       const char *sql)
    : MySQLExecuteNode(plan, dataspace), sql(sql) {
  this->name = "MySQLLoadLocalNode";
  load_data_node = plan->statement->get_stmt_node()->sql->load_oper;
  field_terminate = load_data_node->field_terminate;
  field_escape = load_data_node->field_escape[0];
  has_field_enclose = load_data_node->has_field_enclose;
  if (has_field_enclose) field_enclose = load_data_node->field_enclose[0];
  line_terminate = load_data_node->line_terminate;
  has_line_starting = load_data_node->has_line_starting;
  if (has_line_starting) {
    line_starting = load_data_node->line_starting;
  }
  warning_count = 0;
  warning_packet_list_size = 0;
  affected_row_count = 0;
  has_add_warning_packet = false;
  warning_packet_list = NULL;
}

void MySQLLoadLocalNode::execute() {
#ifdef DEBUG
  node_start_timing();
#endif
  Packet packet;
  MySQLQueryRequest query(sql);
  query.set_sql_replace_char(plan->session->get_query_sql_replace_null_char());
  Packet exec_query;
  query.pack(&exec_query);
  Connection *conn = NULL;
  try {
    conn = handler->send_to_server_retry(
        dataspace, &exec_query, session->get_schema(), session->is_read_only());
    conn->set_load(true);
    // since load data may execuate a long times.
    TimeValue timeout = TimeValue(UINT_MAX, 0);
    handler->receive_from_server(conn, &packet, &timeout);
    if (driver->is_error_packet(&packet)) {
      status = EXECUTE_STATUS_COMPLETE;
      handler->send_to_client(&packet);
      handler->put_back_connection(dataspace, conn);
      conn = NULL;
      session->set_cur_stmt_execute_fail(true);
      return;
    }
    MySQLResultSetHeaderResponse res(&packet);
    res.unpack();
    if (!res.is_columns_null_length()) {
      const char *errmsg = "Unexpected packet received for LOAD DATA response";
      LOG_ERROR("%s\n", errmsg);
      if (session->defined_lock_need_kept_conn(dataspace))
        session->remove_defined_lock_kept_conn(dataspace);
      handler->clean_dead_conn(&conn, dataspace);
      handler->send_to_client(&packet);
      status = EXECUTE_STATUS_COMPLETE;
      throw ExecuteNodeError(errmsg);
    }
    handler->send_to_client(&packet);
    unsigned long packet_num = 0;
    unsigned long load_once_packet_num =
        session->get_session_option("max_load_once_packet_num").ulong_val;
    do {
      packet.rewind();
      handler->receive_from_client(&packet);
      packet_num++;
      if (!driver->is_empty_packet(&packet)) {
        if (load_once_packet_num && packet_num >= load_once_packet_num) {
          size_t incomplete_row_len = check_first_row_complete(
              &packet, field_terminate, line_terminate, has_field_enclose,
              field_enclose, field_escape, 0);
          while (incomplete_row_len == packet.length()) {
            handler->send_to_server(conn, &packet);
            handler->receive_from_client(&packet);
            if (driver->is_empty_packet(&packet)) break;
            incomplete_row_len = check_first_row_complete(
                &packet, field_terminate, line_terminate, has_field_enclose,
                field_enclose, field_escape, 0);
          }
          if (!driver->is_empty_packet(&packet) && incomplete_row_len) {
            Packet *pf = NULL, *pr = NULL;
            divide_packet_by_first_row(&packet, incomplete_row_len, &pf, &pr);
            if (pf && pr) {
              handler->send_to_server(conn, pf);
              redo_load(conn, sql, handler, driver, affected_row_count,
                        warning_count, warning_packet_list_size,
                        &warning_packet_list, has_add_warning_packet);
              handler->send_to_server(conn, pr);
              packet_num = 0;
              delete pf;
              delete pr;
              pf = NULL;
              pf = NULL;
              continue;
            }
          }
        }
      }
      handler->send_to_server(conn, &packet);
    } while (!driver->is_empty_packet(&packet));
    packet.rewind();
    handler->receive_from_server(conn, &packet, &timeout);
    if (driver->is_ok_packet(&packet)) {
      MySQLOKResponse ok(&packet);
      ok.unpack();
      uint64_t warnings = ok.get_warnings();
      uint64_t affected_rows = ok.get_affected_rows();
      affected_row_count += affected_rows;
      warning_count += warnings;
      if (support_show_warning &&
          (warning_packet_list_size < MAX_LOAD_WARNING_PACKET_LIST_SIZE) &&
          warnings)
        store_warning_packet(conn, handler, driver, &warning_packet_list,
                             has_add_warning_packet, warning_packet_list_size);
      ok.set_affected_rows(affected_row_count);
      ok.set_warnings(warning_count);
      ok.pack(&packet);
    }
    handler->deal_autocommit_with_ok_eof_packet(&packet);
    handler->record_affected_rows(&packet);
    handler->send_to_client(&packet);
    if (warning_packet_list) {
      session->add_load_warning_packet_list(warning_packet_list, warning_count);
      warning_packet_list = NULL;
    }
    status = EXECUTE_STATUS_COMPLETE;
  } catch (...) {
    LOG_ERROR("got exception while handling LOAD DATA\n");
    if (session->defined_lock_need_kept_conn(dataspace))
      session->remove_defined_lock_kept_conn(dataspace);
    if (conn) {
      handler->clean_dead_conn(&conn, dataspace);
    }
    status = EXECUTE_STATUS_COMPLETE;
    throw;
  }
  handler->put_back_connection(dataspace, conn);
  session->record_xa_modified_conn(conn);
  conn = NULL;
#ifdef DEBUG
  node_end_timing();
#endif
#ifdef DEBUG
  LOG_DEBUG("MySQLLoadLocalNode %@ cost %d ms\n", this, node_cost_time);
#endif
}
/* class MySQLLoadDataInfile */

MySQLLoadDataInfile::MySQLLoadDataInfile()
    : max_size(1024L * 16L - 1), new_sql(NULL) {
  data_buffer = new char[max_size];
}
MySQLLoadDataInfile::~MySQLLoadDataInfile() { delete[] data_buffer; }
void MySQLLoadDataInfile::sql_add_local(ExecutePlan *plan, const char *sql) {
  new_sql = new string(sql);
  unsigned int pos =
      plan->statement->get_stmt_node()->sql->load_oper->infile_pos;
  new_sql->insert(pos - 1, "LOCAL ");
  LOG_DEBUG("The SQL [%s] has changed into [%s] in LoadDataInfile.\n", sql,
            new_sql->c_str());
}

void MySQLLoadDataInfile::build_error_packet(Packet &packet, const char *file) {
  string error_message = "Can't get stat of '";
  char buffer[PATH_MAX + 1];
  if (realpath(file, buffer)) {
    LOG_DEBUG("can't get the current working directory.\n");
    error_message = error_message + file;
  } else {
    error_message = error_message + buffer;
  }
  error_message = error_message + "' (Errcode: 2)";
  MySQLErrorResponse error_packet(13, error_message.c_str(), "HY000");
  error_packet.pack(&packet);
}
bool MySQLLoadDataInfile::open_local_file(const char *file_path) {
  filestr.open(file_path, ios::binary);
  if (!filestr)
    return false;
  else
    return true;
}
void MySQLLoadDataInfile::init_file_buf() {
  pbuf = filestr.rdbuf();
  size = pbuf->pubseekoff(0, ios::end, ios::in);
  size_remain = size;
  size_temp = 0;
  pbuf->pubseekpos(0, ios::in);
}
void MySQLLoadDataInfile::read_file_into_buf(Packet &buffer) {
  if (size_remain > max_size) {
    size_remain -= max_size;
    size_temp = max_size;
  } else if (size_remain <= max_size && size_remain > 0) {
    size_temp = size_remain;
    size_remain = 0;
  } else {
    size_temp = 0;
  }
  buffer.size(size_temp + PACKET_HEADER_SIZE + 1);
  try {
    filestr.read(buffer.base() + PACKET_HEADER_SIZE, size_temp);
  } catch (...) {
    throw;
  }
}
void MySQLLoadDataInfile::init_file_buf_for_load_insert() {
  pbuf = filestr.rdbuf();
  pbuf->pubseekpos(0, ios::in);
  size_temp = 0;
  size_remain = 1;
}
void MySQLLoadDataInfile::read_file_into_buf_for_load_insert(Packet &buffer) {
  size_temp = 0;
  char *cbuffer = data_buffer;
  int pos = pbuf->sgetc();
  while (pos != EOF) {
    char ch = pbuf->sgetc();
    cbuffer[size_temp] = ch;
    size_temp++;
    if (size_temp == max_size) {
      pbuf->sbumpc();
      break;
    }
    pos = pbuf->snextc();
  }

  buffer.size(size_temp + PACKET_HEADER_SIZE + 1);

  try {
    memcpy(buffer.base() + PACKET_HEADER_SIZE, cbuffer, size_temp);
  } catch (...) {
    throw;
  }
}

}  // namespace mysql
}  // namespace dbscale
